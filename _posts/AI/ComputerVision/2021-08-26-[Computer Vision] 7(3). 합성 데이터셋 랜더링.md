---
layout: single
title: "[Computer Vision] 7(3). 합성 데이터셋 랜더링"
categories: ['AI', 'ComputerVision']
---



<br>

# 합성 데이터셋 랜더링

컴퓨터 비전에서 훈련한 이미지가 전혀 없을 때는 '합성 데이터셋'을 사용한다. 

이번 포스팅에서는 합성 이미지가 무엇인지, 어떻게 생성되는지, 그 제약 사항은 무엇인지에 대해 알아본다. 

<br>

### 개요

---

#### 3D 데이터베이스의 부상

사실 '훈련 이미지가 완전히 없는' 상황은 특히나 산업 분야에서는 보편적이지는 않다. 

그러나 산업 애플리케이션과 그 밖의 경우에 타깃 객체나 장면의 '3D 모델'에 접근하는 것이 점점 더 일반적인 사례가 되고 있다. 3D 모델의 대규모 데이터셋은 웹 상에서 크게 증가하고 있다. 그와 동시에 컴퓨터 그래픽스가 개발되어 점점 더 많은 전문가들이 3D 데이터베이스를 사용해 합성 이미지를 랜더링하고 인식 모델을 훈련할 수 있게 되었다. 

<br>

#### 합성 데이터의 이점

따라서 **합성 이미지**는 3D 모델에서 컴퓨터 그래픽스 라이브러리에 의해 생성된 이미지다. 

타깃 객체와 장면에 대한 자세한 3D 모델이 주어지면 최신 3D 엔진을 사용해 '유사-현실 이미지의 거대한 데이터셋'을 랜더링할 수 있다. 

다양한 랜더링 기법을 사용해 '다양한 유형의 카메라 센서를 시뮬레이션하는 것'도 가능하다. 

<br>

정적 데이터셋의 생성 외에 3D 모델과 게임 엔진은 '대화형 시뮬레이션 환경'을 생성하기 위해서도 사용될 수 있으며, 기업과 연구소는 다양한 애플리케이션을 다루는 다수의 시뮬레이션 프레임워크를 개발해왔다.

이러한 가상 환경에서 사람들은 자신의 모델을 훈련하고 테스트할 수 있다. 각 시간 단계마다 모델이 이 환경으로부터 일부 시각적 입력을 받아 추가 조치를 취하고 시뮬레이션에 다시 영향을 미치는 등의 방식으로 사용할 수 있다. 

<br>

항성 데이터셋과 가상 환경은 실제 훈련 데이터의 부족을 보완하고 복잡하거나 위험한 환경에 미완성의 솔루션을 직접 적용함으로써 발생 할 수 있는 결과를 피하기 위해 사용된다. 

<br>

<br>

### 3D 모델에서 합성 이미지 생성하기

---

**컴퓨터 그래픽스**는 그 자체로 방대하면서 대단히 흥미로운 영역이다. 

다음 단락부터는 애플리케이션을 위해 데이터를 랜더링할 필요가 있는 사람에게 유용한 도구와 즉히 사용할 수 있는 프레임워크를 간단히 설명한다. 

<br>

#### 3D 모델로부터 랜더링하기

3D 모델에서 2D 이미지를 생성하는 일은 여러 단계를 거쳐야 하는 복잡한 프로세스다. 

이는 객체와 관련된 3D 좌표로부터 각 모델의 면을 전체 장면에 관련된 좌표(월드 좌표)에 투영하고 그런 다음 카메라와 관련된 좌표에(카메라 좌표) 투영하고 마지막으로 이미지 공간에 관련된 2D 좌표에 투영한다. 

연산은 다양하고 계산적으로 무겁다. 다행히도 GPU는 원래 이 연산을 효율적으로 수행하기 위해 구성됐고, **OpenGL** 같은 프레임워크는 컴퓨터 그래픽스에서 GPU와 인터페이스를 지원하고 프로세스 중 일부를 간소화하기 위해 개발되었다. 

<br>

대부분의 현대 컴퓨터 언어는 **PyOpenGL**이나 **vispy** 처럼 OpenGL을 기반으로 구성된 라이브러리를 제공한다. **블렌더** 같은 애플리케이션은 3D 장면을 구성하고 랜더링하기 위해 그래픽 인터페이스를 제공한다. 

그렇지만 앞서 언급했듯이 연구소와 기업에서 특별히 머신러닝 애플리케이션을 위해 합성 데이터셋을 랜더링하는 더 높은 차원의 프레임워크를 많이 공유해왔다는 점을 기억하는 것이 좋다. (**Blensor**나 **HoME: A household multimodal** 등)

<br>

직접 전체 랜더링 파이프라인을 구성하거나 특정 시뮬레이션 시스템을 사용하는 두 경우 모두 최종 목표는 실제 정보와 충분한 변형(관찰 위치, 조명 조건, 질감 등)을 갖춘 대용량의 훈련 데이터럴 랜더링하는 것이다.

<br>

#### 합성 이미지 사후 처리

타깃 객체의 3D 모델은 산업 환경에서 종종 사용될 수 있지만 이 객체가 발견될 환경을 3D로 표현하는 경우는 드물다. 

대신 '합성 이미지를 관련된 배경 사진과 병합'하는 것이 일반적이다. 

<br> 일부 '보강 연산'은 랜더링 파이프라인에 의해 처리될 수 있지만, 기타 2D 변환은 여전히 훈련하는 동안 합성 이미지에 적용되는 것이 일반적이다. 이 추가적인 사후 처리는 과적합 위험을 줄이고 모델의 견고성을 증가시키기 위해 다시 한 번 이뤄진다. 

<br>

✋ **텐서플로 그래픽스(Tensorflow Graphics)**

2019년 5월에 **텐서플로 그래픽스**가 출시됐다. 이 모듈은 3D 모델로부터 이미지를 생성하기 위한 컴퓨터 그래픽스 파이프라인을 제공한다. 

이 랜더링 파이프라인은 새로운 미분 가능한 연산으로 구성되므로 신경망과 밀접하게 연결/통합 될 수 있다. 

더 많은 정보와 자세한 튜토리얼은 관련 [깃허브 저장소](https://github.com/tensorflow/graphics)에서 찾아볼 수 있다. 

<br>

<br>

#### 문제점 - 현실성과의 격차

합성 이미지 랜더링이 다양한 컴퓨터 비전 애플리케이션을 가능하게 했지만, 그렇더라도 데이터 부족에 대한 완벽한 해결책은 되지 못했다. 오늘날 컴퓨터 그래픽스 프레임워크는 초현실적인 이미지를 랜더링할 수 있지만 이를 위한 '자세한 3D 모델'이 필요하다. 

그러한 모델을 구성하기 위해 데이터를 모으는 일은 타깃 객체에 대한 실제 이미지의 데이터셋을 직접 구성하는 것 이상은 아니더라도 그만큼 '비용이 많이 드는' 일이다. 

<br>

3D 모델이 때로는 단순화된 기하학적 구조를 갖거나 질감 정보가 부족하기 때문에 현실적인 합성 데이터셋은 그렇게 일반적이지 않다. 이같이 랜더링된 훈련 데이터와 실제 타깃 이미지 사이의 현실성과의 격차는 모델 성능을 훼손한다. 

합성 데이터에 대해 훈련하는 동안 그들이 학습한 시각 신호는 실제 이미지에는 나타나지 않을 수 있다. 

<br>

현재 컴퓨터 비전을 위한 현실성과의 격차를 해결하고자 많은 노력을 기울이고 있다. 

어떤 전문가들은 더 현실적인 3D 데이터베이스를 구축하거나 더 진화된 시뮬레이션 도구를 개발하지만, 다른 전문가들은 **합성 환경에서 얻은 지식을 실제 상황에 전이시킬 수 있는 새로운 머신러닝 모델**을 제안한다. 

후자의 접근 방식을 다음 포스팅에서 다루도록 하겠다. 

























