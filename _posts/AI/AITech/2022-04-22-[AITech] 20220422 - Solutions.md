---
layout: single
title: "[AITech][Data Annotation][P stage] 20220422 - Solutions"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: []
---



<br>

# Solutions

**발표 1 팀**

* Data Set
  * ICDAR 17, ICDAR 19 추가 수집
  * User data 사용
  * 모든 언어 사용
  * Polygon을 사각형으로 변환
  * 최종적으로 18,479장의 이미지 사용
* Data Augmentation
  * PIL 대신 cv2로 train할 image 전체를 미리 load하는 방식 사용 (dir 20%의 시간 절약)
  * 다양한 augmentation 적용
  * allow_partial_occurence = True로 하고 작은 글자들을 학습시켰을 때 private에서 약 4%의 성능 향상
    * False로 할 시 private에서 약 2%의 성능 하락
    * Private에서 작은 글자들이 많이 포함되어 있을 것이라 판단
* Comment
  * Dataloader의 성능 편차를 느꼈는지?
  * 비슷한 가이드로 만들어진 데이터셋인지 봐야 한다! 아니면 데이터를 포함해도 오히려 성능이 떨어질 수 있다. 
  * Train data와 Test data의 분포는 다를 수 밖에 없다! 그럼 어떻게 해야 할까?

**발표 2 팀**

* Data experimetns
  * ICDAR 2017 - others 이미지(ko, en 이외의 언어) 사용 시 큰 성능 향상
  * ICDAR 2019 포함 시 또한 성능 향상
  * AI Hub 한국어 글자체 이미지 사용
    * 성능 하락...
    * 수평수직 직사각형으로만 어노테이션 되어 있어 그렇다고 판단
* Data Augmentation
  * Default augmentation + RGB
  * Custom augmentation
  * Polygon을 Rectangle로 변환 (제외)
* HPO
  * wandb - sweeps (grid, random, uniform search)
* 느낀점
  * Validation dataset 없이 학습을 진행해서 학습이 제대로 되고 있는지 확인하기 어려웠다. 
  * Annotation 의 라벨링 퀄리티가 성능에 큰 영향을 미치는 것을 체감
  * Data가 무조건 많다고 좋은게 아니다.
  * 성능 향상을 위해 데이터 양을 늘렸지만, 학습 시간이 증가되어 실험을 많이 하기 어려웠다. 
  * 라이브러리 사용에 의존하여 적용하고 싶은 기술들을 직접 구현하기 어려웠다. 
* Comments
  * 데이터셋의 어노테이션 방식의 우리 데이터셋의 가이드라인과 얼마나 비슷한지 반드시 유심히 봐야 한다. 
    * 어노테이션 방식이 다르면 다른 데이터라고 봐야 한다!
  * 데이터를 소량으로 사용할 때에는 모델 성능에 큰 편차가 발생할 수 있다. 
  * 실험을 하고 왜 이런 결과가 나왔는지에 대한 생각을 해보자. 
  * 실서비스 모델 구축 시 HPO는 맨 마지막에 적용한다. 
    * 실험 시에는 데이터와 모델 구조에 집중하고, 파라미터 최적화는 모두 정해지고 가장 마지막에 적용해본다. 
  * 모델 간 성능 비교를 할 때에는 매번 끝까지 돌리는 것보다는 경향성을 보고 빠르게 제외할 모델을 제외하여 시간을 아낀다. 
  * 데이터 IO를 개선하는 것은 정말 어렵지만, 잘 개선하면 큰 속도 향상을 얻을 수 있다. 
  * 합성 데이터의 적절한 사용 (특히 OCR의 경우 매우 활발함)

**발표 3 팀**

* Data Augmentation
  * Color(성능 향상), Blur(성능 하락), Rotate(성능 향상), Outline(CLAHE, Emboss, Invert)
  * 목적에 맞는 augmentation을 찾는 것이 중요
* Data Cleansing
  * User data 추가 - 전수 조사
    * 제외된 경우: bbox가 잘못된 경우, 지정되지 않은 경우, 제외 영역이 설정되지 않은 경우
* Train dataset
  * ko, en이 포함된 모든 이미지 사용
  * ICDAR 2017, ICDAR 2019, AIHUB 공공 행정 문서, user data(전수 조사 후 사용), unreal text(언어분류가 되어있지 않아 사용 X), SynthText3D(한국어가 존재하지 않아 사용 X)
  * Text data의 분포를 비슷하게 가져가는 것과 다양한 데이터를 사용하는 것의 중요성
* Comment
  * 학습 데이터와 테스트 데이터의 분포를 비슷해야 한다고 할 때, '분포'의 의미는 무엇일까? 내가 하는 task에서 중요한 분포는 무엇일까? 어떤 분포를 만들어야 할까?
    * '분포'를 정의하는 것이 중요하다. 
  * 최종 metric인 F1-score만 쫓기 보다는 실험 후 recall, precision의 변화 이유를 tracking하는 것이 중요하다. 













<br>

<br>

# 참고 자료

* 
