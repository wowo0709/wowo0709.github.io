---
layout: single
title: "[AITech][Object Detection][P stage] 20220406 - MMDetection"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: []
---



<br>

# MMDetection

`MMDetection`ì€ object detection taskì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” detection model libraryì…ë‹ˆë‹¤. 

ì²˜ìŒ `MMDetection`ì— ëŒ€í•œ ì„¤ëª…ì„ ë“¤ìœ¼ë©´ **config íŒŒì¼ë§Œ ìˆ˜ì •í•˜ë©´ ëœë‹¤**ë¼ëŠ” ë§ì„ ë“£ìŠµë‹ˆë‹¤. MMDetectionì˜ êµ¬ì¡°ë¥¼ íŒŒí—¤ì³ë³´ë©´ì„œ ê·¸ê²ƒì´ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

![image-20220409183828261](https://user-images.githubusercontent.com/70505378/162576635-3e02be22-00c2-4284-8966-f06c42a98172.png)

## MMDetection Structure

[mmdetection ë³´ëŸ¬ ê°€ê¸°](https://github.com/open-mmlab/mmdetection)

mmdetectionì˜ êµ¬ì¡°ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 

![image-20220409183717522](https://user-images.githubusercontent.com/70505378/162576634-33071071-e6df-4d9d-a1be-df755f45a55a.png)

ìœ„ í´ë”ë“¤ ì¤‘ ìš°ë¦¬ê°€ ë§ì´ ì‚¬ìš©í•˜ê²Œ ë˜ëŠ” í´ë”ëŠ” `configs`, `mmdet`, `tools` í´ë”ì…ë‹ˆë‹¤. ê·¸ ì¤‘ì—ì„œë„ ë‹¨ì—° ë§ì´ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ **configs** í´ë”ì…ë‹ˆë‹¤. 

mmdetection ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì„œ import í•˜ì—¬ ì‚¬ìš©í•˜ê±°ë‚˜, repositoryì˜ í´ë”ë“¤ì„ ë¡œì»¬ë¡œ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ ìœ„í•´ì„œëŠ” cloneí•˜ì—¬ ì‚¬ìš©í•˜ê±°ë‚˜, zip fileë¡œ ë‹¤ìš´ë¡œë“œ ë°›ì•„ì„œ ì „ì²´ í´ë”ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ì¢‹ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. 

ì €í¬ ì¡°ì—ì„œëŠ” `level2-object-detection-level2-cv-10`ì´ë¼ëŠ” repositoryë¥¼ íŒŒì„œ ê·¸ ì•ˆì— mmdetection í´ë”ë¥¼ í¬í•¨ì‹œí‚¤ëŠ” ì‹ìœ¼ë¡œ ì‘ì—…í–ˆìŠµë‹ˆë‹¤. í´ë” êµ¬ì¡°ë¥¼ ë³´ë ¤ë©´ ì•„ë˜ ì£¼ì†Œë¥¼ ì°¸ì¡°í•´ì£¼ì„¸ìš”. 

[level2-object-detection-level2-cv-10](https://github.com/boostcampaitech3/level2-object-detection-level2-cv-10/tree/experiment)

ì¶”ê°€ì ìœ¼ë¡œ, mmdetection repositoryë¥¼ clone í–ˆë‹¤ë©´ `.git` í´ë”ë¡œ ë¡œì»¬ê³¼ ë¦¬ëª¨íŠ¸ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ” ìƒíƒœì´ê¸° ë•Œë¬¸ì— ì´ íŒŒì¼ë“¤ì„ ì§€ì›Œì„œ ì—°ê²°ì„ ëŠì–´ì¤ë‹ˆë‹¤. 







<br>

<br>

## config folder

ë¨¼ì € ìš°ë¦¬ê°€ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ê²Œ ë˜ëŠ” `config` í´ë”ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤. 

config í´ë” ì•ˆì—ëŠ” ì—¬ëŸ¬ ëª¨ë¸ì˜ êµ¬ì¡°ê°€ ë¯¸ë¦¬ í´ë”ë³„, íŒŒì¼ë³„ë¡œ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

![image-20220409184745371](https://user-images.githubusercontent.com/70505378/162576636-333a2361-8625-4160-ba6c-3431f1b4eb21.png)

ì €í¬ ì¡°ëŠ” config í´ë” ì•ˆì— ê°ìì˜ ì‹¤í—˜ì„ ìœ„í•œ personal folderë¥¼ í•˜ë‚˜ì”© ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. `_base_`ë¥¼ ì œì™¸í•˜ê³  `_youngwoo_`ì™€ ê°™ì´ ì•ë’¤ë¡œ '_'ê°€ ë¶™ì–´ìˆëŠ” í´ë”ë“¤ì´ ê°ìì˜ ì‹¤í—˜ìš© í´ë”ì…ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ì´ì•¼ê¸°ëŠ” ë’¤ì—ì„œ ì¶”ê°€ì ìœ¼ë¡œ í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

ê¸°ë³¸ì ìœ¼ë¡œ 2-stage modelì˜ êµ¬ì¡°ëŠ” ì•„ë˜ ê·¸ë¦¼ì„ ë”°ë¦…ë‹ˆë‹¤. 2-stage modelì˜ config íŒŒì¼ ì•ˆì—ëŠ” í¬ê²Œ model, backbone, neck, rpn_head, roi_head ê°€ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

![image-20220409185709952](https://user-images.githubusercontent.com/70505378/162576640-057f00c8-3438-46a8-8601-d6cec45f972e.png)

ê·¸ëŸ¼ ëª¨ë¸ í´ë” ì•ˆì—ëŠ” ì–´ë–¤ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” casecade_rcnn í´ë” ë‚´ë¶€ì˜ ëª¨ìŠµì…ë‹ˆë‹¤. 

![image-20220409185115276](https://user-images.githubusercontent.com/70505378/162576638-e94027f4-9a22-4d92-b2d0-1a64275bfb28.png)

ìœ„ íŒŒì¼ë“¤ ì¤‘ ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” íŒŒì¼ì€ `cascade_rcnn_r50_fpn_1x_coco.py` íŒŒì¼ì…ë‹ˆë‹¤. íŒŒì¼ëª…ì€ ì¼ë°˜ì ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ êµ¬ì„±ë©ë‹ˆë‹¤. 

```
{model}_[model setting]_{backbone}_{neck}_[norm setting]_[misc]_[gpu x batch_per_gpu]_{schedule}_{dataset}
```

* `cascade_rcnn`: ì „ì²´ ëª¨ë¸ ëª…
* `r50`: backbone ëª¨ë¸ ëª…. r50ì€ resnet 50ì„ ê°€ë¦¬í‚´. 
* `fpn`: Neck ëª¨ë¸ ëª…. 
* `1x`: í•™ìŠµ epoch ìˆ˜
* `coco`: dataset í¬ë§·. 

ì—¬ê¸°ì— êµ¬ì¡°ì˜ ë³€ê²½ì´ ë“¤ì–´ê°€ê±°ë‚˜, 1-stage ëª¨ë¸ê³¼ ê°™ì´ êµ¬ì¡°ê°€ ë‹¤ë¥¸ ëª¨ë¸ì¼ ê²½ìš° íŒŒì¼ëª…ì€ ê·¸ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. 

`cascade_rcnn_r50_fpn_1x_coco.py` íŒŒì¼ì€ ì•„ë˜ì™ ê°™ì´ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

```python
_base_ = [
    '../_base_/models/cascade_rcnn_r50_fpn.py',
    '../_base_/datasets/coco_detection.py',
    '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'
]
```

ë³„ë‹¤ë¥¸ ì½”ë“œ ì—†ì´, `_base_` ë¼ëŠ” ë³€ìˆ˜ì— ì‚¬ìš©í•  íŒŒì¼ë“¤ë§Œ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë³´í†µ `_base_` í´ë”ì—ëŠ” í¬ê²Œ `models`, `datasets`, `schedules`, `runtime` íŒŒì¼ë“¤ì´ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ `_base_` í´ë” ì•ˆì— ê¸°ë³¸ ëª¨ë¸ì´ ì •ì˜ë˜ì–´ ìˆë‹¤ë©´ `_base_` í´ë”ì˜ íŒŒì¼ì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•˜ê³ , `_base_` í´ë” ì•ˆì— ê¸°ë³¸ ëª¨ë¸ì´ ì •ì˜ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš° ëª¨ë¸ íŒŒì¼ì—ì„œ `_base_` í´ë”ì˜ íŒŒì¼ì„ ê°€ì ¸ì˜¤ì§€ ì•Šê³  ì½”ë“œê°€ ì§ì ‘ ì‘ì„±ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´ **cornernet** ëª¨ë¸ì˜ ê²½ìš° `_base_` í´ë”ì—ì„œëŠ” runtimeê³¼ dataset íŒŒì¼ë§Œ ê°€ì ¸ì˜¤ê³ , modelê³¼ scheduler(optimizer)ëŠ” ì§ì ‘ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

```python
_base_ = [
    '../_base_/default_runtime.py', '../_base_/datasets/coco_detection.py'
]

# model settings
model = dict(
    type='CornerNet',
    backbone=dict(
        type='HourglassNet',
        downsample_times=5,
        num_stacks=2,
        stage_channels=[256, 256, 384, 384, 384, 512],
        stage_blocks=[2, 2, 2, 2, 2, 4],
        norm_cfg=dict(type='BN', requires_grad=True)),
    neck=None,
    bbox_head=dict(
        type='CornerHead',
        num_classes=80,
        in_channels=256,
        num_feat_levels=2,
        corner_emb_channels=1,
        loss_heatmap=dict(
            type='GaussianFocalLoss', alpha=2.0, gamma=4.0, loss_weight=1),
        loss_embedding=dict(
            type='AssociativeEmbeddingLoss',
            pull_weight=0.10,
            push_weight=0.10),
        loss_offset=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1)),
    # training and testing settings
    train_cfg=None,
    test_cfg=dict(
        corner_topk=100,
        local_maximum_kernel=3,
        distance_threshold=0.5,
        score_thr=0.05,
        max_per_img=100,
        nms=dict(type='soft_nms', iou_threshold=0.5, method='gaussian')))
# ...
optimizer = dict(type='Adam', lr=0.0005)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=1.0 / 3,
    step=[180])
runner = dict(type='EpochBasedRunner', max_epochs=210)
```





ì´ì²˜ëŸ¼, ê¸°ë³¸ì ì¸ ë¼ˆëŒ€ íŒŒì¼ì„ `_base_` ë³€ìˆ˜ì— ë‹´ì•„ë‘ê³ (ì—†ë‹¤ë©´ ìƒëµí•˜ê³ ), ì—¬ëŸ¬ê°€ì§€ êµ¬ì¡°ë¥¼ ë³€ê²½í•´ì„œ ìƒˆë¡œìš´ ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ ìœ„ì—ì„œ ì–˜ê¸°í•œ **config íŒŒì¼ë§Œ ìˆ˜ì •í•˜ë©´ ëœë‹¤**ì˜ ì˜ë¯¸ì…ë‹ˆë‹¤. 

ì´ `_base_` í´ë”ì˜ êµ¬ì¡°ê°€ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ëŠ” ì•„ë˜ì—ì„œ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

<br>

ì˜ˆë¥¼ ë“¤ì–´ ê¸°ë³¸ì´ ë˜ëŠ” íŒŒì¼ì¸ `cascade_rcnn_r50_fpn_1x_coco.py` íŒŒì¼ì˜ backboneì„ `resnet 101`ë¡œ ìˆ˜ì •í•œ `cascade_rcnn_r101_fpn_1x_coco.py` íŒŒì¼ì€ ì•„ë˜ì™€ ê°™ì´ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

```python
_base_ = './cascade_rcnn_r50_fpn_1x_coco.py'
model = dict(
    backbone=dict(
        depth=101,
        init_cfg=dict(type='Pretrained',
                      checkpoint='torchvision://resnet101')))
```

ë‹¤ë¥¸ ëª¨ë“  ì„¤ì •ë“¤ì€ cascade_rcnn_r50_fpn_1x_coco.py ì—ì„œ ê°€ì§€ê³  ì˜¤ë˜, modelì˜ backbone ë¶€ë¶„ì„ ìƒˆë¡­ê²Œ ì •ì˜í•˜ì—¬ ì˜¤ë°”ë¼ì´ë”© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 





### ê°œì¸ config í´ë” êµ¬ì„±í•˜ê¸°

ì €í¬ ì¡°ëŠ” ê°ì ì‹¤í—˜ì„ ì§„í–‰í•œ config íŒŒì¼ì„ ê¸°ë¡/ì €ì¥í•˜ê¸° ìœ„í•´ ê°œì¸ config í´ë”(`_youngwoo_`)ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ê°œì¸ config í´ë” ë‚´ë¶€ëŠ” ì•„ë˜ì™€ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (ì‘ì„±ìì˜ íŒŒì¼ì´ ì¤‘ê°„ì— ë‚ ì•„ê°€ë²„ë ¤ì„œ... ì•„ë˜ ì´ë¯¸ì§€ëŠ” ë‹¤ë¥¸ íŒ€ì› ë¶„ì˜ í´ë” êµ¬ì„±ì…ë‹ˆë‹¤)

![image-20220409211631144](https://user-images.githubusercontent.com/70505378/162576641-786d02c8-58df-420b-ab9f-73aabc0c34e9.png)

ìƒìœ„ config í´ë”ì™€ ë§ˆì°¬ê°€ì§€ë¡œ, ê¸°ë³¸ì ì¸ ë¼ˆëŒ€ ì½”ë“œê°€ ë“¤ì–´ìˆëŠ” `_base_` í´ë”ì™€ ì»¤ìŠ¤í…€í•œ ê° ëª¨ë¸ë“¤ì´ ë“¤ì–´ìˆëŠ” ëª¨ë¸ í´ë”(ì—¬ê¸°ì„œëŠ” `dyhead`, `retinanet`, `universenet`)ê°€ ìˆìŠµë‹ˆë‹¤. ê° í´ë” ë‚´ë¶€ êµ¬ì¡°ëŠ” ìƒìœ„ config í´ë”ì— ìˆëŠ” í´ë”ë“¤ì˜ ë‚´ë¶€ êµ¬ì¡°ì™€ ë™ì¼í•©ë‹ˆë‹¤. 

ì•„ê¹Œë¶€í„° ê³„ì† `_base_`  í´ë” ì´ì•¼ê¸°ë¥¼ í–ˆëŠ”ë°, ì´ì œ ì´ í´ë” ë‚´ë¶€ êµ¬ì¡°ëŠ” ì–´ë–»ê²Œ ë˜ì–´ ìˆëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. 

<br>

<br>

## \_base\_ folder

ìœ„ì—ì„œ ë§í–ˆë“¯ì´,  `_base_` í´ë”ì—ëŠ” ê¸°ë³¸ì´ ë˜ëŠ” `models`, `datasets`, `schedules`, `runtime` íŒŒì¼ë“¤ì´ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

![image-20220409211940930](https://user-images.githubusercontent.com/70505378/162576643-ab3e5101-3801-418c-b228-d42a522b2e57.png)

### datasets

![image-20220409212021564](https://user-images.githubusercontent.com/70505378/162576626-3ba8534e-4c2d-40d0-970c-8295f9e70d7a.png)

task, dataset formatì— ë”°ë¼ ë‹¤ë¥¸ dataset íŒŒì¼ë“¤ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ë²ˆ ëŒ€íšŒì—ì„œ ì‚¬ìš©í–ˆë˜ `coco_detection.py` íŒŒì¼ ë‚´ë¶€ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤. 

```python
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/coco/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotations/instances_train2017.json',
        img_prefix=data_root + 'train2017/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotations/instances_val2017.json',
        img_prefix=data_root + 'val2017/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotations/instances_val2017.json',
        img_prefix=data_root + 'val2017/',
        pipeline=test_pipeline))
evaluation = dict(interval=1, metric='bbox')
```

coco dataset formatì˜ detection datasetì„ ì‚¬ìš©í•  ë•Œ ì‚¬ìš©í•˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤. ì½”ë“œëŠ” ìƒë‹¹íˆ ì§ê´€ì ìœ¼ë¡œ ì§œì—¬ì ¸ ìˆìŠµë‹ˆë‹¤. 

ìš°ë¦¬ì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ”, ìœ„ ì½”ë“œì— ëª‡ ê°€ì§€ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ ìˆ˜ì •ëœ `coco_detection.py` íŒŒì¼ì€ ìœ„ì—ì„œ ë³¸ ê°œì¸ config í´ë” ì•ˆì˜ `datasets` í´ë” ì•ˆì— ë„£ìŠµë‹ˆë‹¤. ìˆ˜ì •ëœ ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 

```python
# dataset settings
dataset_type = 'CocoDataset'
data_root = '/opt/ml/detection/dataset/'

# ìš°ë¦¬ ë°ì´í„°ì…‹ì— ë§ë„ë¡ classes ì¶”ê°€
classes = ("General trash", "Paper", "Paper pack", "Metal", "Glass",
            "Plastic", "Styrofoam", "Plastic bag", "Battery", "Clothing")

img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1024, 1024), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    samples_per_gpu=4, # batch size 2 -> 4
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        classes=classes,
        ann_file=data_root + 'train0.json', # fold0
        img_prefix=data_root,
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        classes=classes,
        ann_file=data_root + 'val0.json', # fold0
        img_prefix=data_root,
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        classes=classes,
        ann_file=data_root + 'test.json',
        img_prefix=data_root,
        pipeline=test_pipeline))

evaluation = dict(interval=1, metric='bbox', classwise=True, save_best='bbox_mAP_50')
```

í•„ìˆ˜ì ìœ¼ë¡œ ìˆ˜ì •ì´ í•„ìš”í•œ ë¶€ë¶„ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 

* `data_root`: ìš°ë¦¬ê°€ ì‚¬ìš©í•  ë°ì´í„°ì…‹ì´ ìœ„ì¹˜í•œ ê²½ë¡œ(í´ë”)
* `classes`: ìš°ë¦¬ê°€ ì‚¬ìš©í•  ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤(ë¼ë²¨) ëª©ë¡ ì •ì˜
* `data`: dataset config ì§€ì •
  * train/val/test: classes, ann_file, img_prefix

ìœ„ ì„¸ ê°€ì§€ëŠ” í•„ìˆ˜ì ìœ¼ë¡œ ìš°ë¦¬ ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ì™¸ì˜ ìš”ì†Œë“¤ì€ ì‹¤í—˜ì„ í†µí•´ ì ì ˆíˆ ë³€ê²½í•˜ë©´ ë©ë‹ˆë‹¤. 

ì¶”ê°€ì ì¸ íŒìœ¼ë¡œ, ë§¨ ë§ˆì§€ë§‰ ì¤„ì— ìˆëŠ” `evaluation` ì— classwiseì™€ save_bestë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° keyì˜ ì˜ë¯¸ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 

* classwise: ë§¤ validationë§ˆë‹¤ ê° í´ë˜ìŠ¤ì˜ APë¥¼ ì¶œë ¥í•´ì¤ë‹ˆë‹¤. 
* save_best: ê¸°ì¤€ì´ ë  metricì„ ì „ë‹¬í•˜ë©´ ê·¸ metricì´ ìµœì ì¼ ë•Œ model checkpointë¥¼ ì €ì¥í•´ì¤ë‹ˆë‹¤. 

<br>

### models

`models` í´ë” ì•ˆì—ëŠ” ì¼ë¶€ ë§ì´ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ë“¤ì— ëŒ€í•œ baseline ì½”ë“œ íŒŒì¼ë“¤ì´ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

![image-20220409215209568](https://user-images.githubusercontent.com/70505378/162576627-d9e4fafa-fd7b-4a20-9e88-918c329b8bff.png)

ì˜ˆë¥¼ ë“¤ì–´ `cascade_rcnn_r50_fpn.py` íŒŒì¼ì„ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

```python
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[.0, .0, .0, .0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=80,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0., 0., 0., 0.],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=80,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0., 0., 0., 0.],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=80,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0., 0., 0., 0.],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))
        ]),
    # model training and testing settings
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100)))
```

ê¸°ë³¸ì ì¸ ëª¨ë¸ì˜ ë¼ˆëŒ€ê°€ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Cascade RCNN ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” íŒŒì¼ì˜ ê²½ìš°, ì´ íŒŒì¼ì„ `_base_` ë¦¬ìŠ¤íŠ¸ ë³€ìˆ˜ì— ë„£ê³  ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì„ ì§ì ‘ ì •ì˜í•˜ì—¬ ì˜¤ë²„ë¼ì´ë”©í•˜ë©´ ë©ë‹ˆë‹¤. 





<br>

### schedules

`schedules` í´ë”ì—ëŠ” ê¸°ë³¸ì ì¸ optimizerì™€ schedulerê°€ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

![image-20220409215544608](https://user-images.githubusercontent.com/70505378/162576628-2f90e258-2d28-46fc-be93-b89539a649ac.png)

ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” `schedule_1x.py` íŒŒì¼ ë‚´ë¶€ëŠ” ì•„ë˜ì™€ ê°™ì´ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

```python
# optimizer
optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=12)
```

ë§ˆì°¬ê°€ì§€ë¡œ, ì´ baseline codeë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° í•´ë‹¹ íŒŒì¼ì˜ `_base_` ë¦¬ìŠ¤íŠ¸ ë³€ìˆ˜ì— ì´ íŒŒì¼ëª…ì„ ë„£ê³  ê° ë¶€ë¶„ì„ ìƒˆë¡­ê²Œ ì •ì˜í•˜ì—¬ ì˜¤ë²„ë¼ì´ë”©í•˜ë©´ ë©ë‹ˆë‹¤. (ì•„ë‹ˆë©´ ì•„ì˜ˆ ë‹¤ë¥¸ íŒŒì¼ì— ë³µë¶™í•˜ê³  ìˆ˜ì •í•´ì„œ ìƒˆë¡œìš´ íŒŒì¼ì„ ë§Œë“¤ì–´ë„ ë©ë‹ˆë‹¤)





<br>

### default_runtime.py

ë§ˆì§€ë§‰ìœ¼ë¡œ `default_runtime.py` íŒŒì¼ì…ë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ì€ í´ë” ì•ˆì— ë“¤ì–´ìˆì§€ëŠ” ì•Šê³  ë…ë¦½ì ì¸ íŒŒì¼ë¡œ ì¡´ì¬í•©ë‹ˆë‹¤. 

íŒŒì¼ ë‚´ë¶€ëŠ” ì•„ë˜ì™€ ê°™ì´ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

```python
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
custom_hooks = [dict(type='NumClassCheckHook')]

dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]

# disable opencv multithreading to avoid system being overloaded
opencv_num_threads = 0
# set multi-process start method as `fork` to speed up the training
mp_start_method = 'fork'
```

runtime íŒŒì¼ì˜ ê²½ìš° ìœ„ íŒŒì¼ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤. 

ì¶”ê°€ì ìœ¼ë¡œ, ë‹¤ë¥¸ íŒ€ì›ë¶„ê»˜ì„œ ê³µìœ í•´ì£¼ì‹  ê¿€íŒì„ ì ì–´ë³¼ê¹Œ í•©ë‹ˆë‹¤. ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ë©´ ë§¤ epochë§ˆë‹¤ model checkpoint íŒŒì¼ì´ ì €ì¥ë˜ëŠ”ë°ìš”, ì´ íŒŒì¼ì´ ìŒ“ì´ë‹¤ ë³´ë©´ out of memoryê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **checkpoint_config** ë³€ìˆ˜ ì•ˆì˜ **max_keep_ckpts**ë¥¼ ì§€ì •í•´ì„œ ë§ˆì§€ë§‰ nê°œì˜ checkpoint íŒŒì¼ë§Œ ì €ì¥ë˜ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
checkpoint_config = dict(max_keep_ckpts=3, interval=1) # max number of saving checkpoints
```







<br>

<br>

## train.py

ëª¨ë¸ í•™ìŠµì„ ì‹œí‚¬ ë•ŒëŠ” `tools` í´ë” ì•ˆì— ìˆëŠ” `train.py` íŒŒì¼ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. (tools í´ë”ëŠ” mmdetection í´ë” ì•ˆì— ìˆìŠµë‹ˆë‹¤)

ì½”ë“œëŠ” ë„ˆë¬´ ê¸¸ì–´ì„œ ì˜¬ë¦¬ì§€ëŠ” ì•Šê³ , ì•„ë˜ ì£¼ì†Œì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”. 

[mmdetection - train.py](https://github.com/open-mmlab/mmdetection/blob/master/tools/train.py)

í˜„ì¬ í„°ë¯¸ë„ ìœ„ì¹˜ê°€ mmdetection í´ë”ì— ìˆë‹¤ê³  í•  ë•Œ, ì•„ë˜ ì»¤ë§¨ë“œë¥¼ í†µí•´ ëª¨ë¸ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 

```
python tools/train.py <ì‹¤í–‰í•  config í´ë” ê²½ë¡œ> --work-dir <model checkpointë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ> --resume-from <í•™ìŠµì„ ì¬ê°œí•  model checkpoint íŒŒì¼ ê²½ë¡œ>
```

ì €ëŠ” ë³´í†µ ìœ„ì™€ ê°™ì€ ì»¤ë§¨ë“œë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œëŠ” **ì‹¤í–‰í•  config í´ë” ê²½ë¡œ**ë§Œ ì§€ì •í•˜ë©´ ë˜ê³ , ë‚˜ë¨¸ì§€ëŠ” í•„ìš”í•œ ê²½ìš° ì¶”ê°€ì ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤. 











<br>

<br>

## Random seed

íŒ€ì›ë“¤ê³¼ í˜‘ì—…ì„ ì§„í–‰í•  ë•Œ ì¬í˜„ ê°€ëŠ¥í•œ í•™ìŠµì„ í•˜ê³  ì‹¶ë‹¤ë©´, random seedë¥¼ ê³ ì •í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ë‚´ìš©ì€ ë³„ë„ì˜ í¬ìŠ¤íŒ…ìœ¼ë¡œ ì‘ì„±í–ˆìœ¼ë‹ˆ ì•„ë˜ í¬ìŠ¤íŒ…ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”. 

[MMDetection - PyTorch Randomness ì œì–´í•˜ê¸°](https://wowo0709.github.io/ai/aitech/pytorch/AITech-20220329-MMDetection-PyTorch-Randomness-%EC%A0%9C%EC%96%B4%ED%95%98%EA%B8%B0/)

















<br>

<br>

## mmdet folder

ë§ˆì§€ë§‰ìœ¼ë¡œ ë³¼ ê²ƒì€ `mmdet` í´ë”ì…ë‹ˆë‹¤. mmdet í´ë” ë‚´ë¶€ êµ¬ì„±ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 

![image-20220409221735266](https://user-images.githubusercontent.com/70505378/162576630-3062ca2e-721f-41d7-9928-6b51e1f8c5f3.png)

mmdet í´ë”ì—ì„œëŠ” mmdetectionì— ì–´ë–¤ íŒŒì¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ë¥¼ ë³¼ ìˆ˜ ìˆê³ , ê° íŒŒì¼ì˜ êµ¬í˜„ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ `models/necks` ì— ê°€ë³´ë©´ ê° neckë“¤ì´ êµ¬í˜„ëœ íŒŒì¼ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

![image-20220409222200739](https://user-images.githubusercontent.com/70505378/162576631-68f94485-ccce-40fd-a7aa-479fad55a0bf.png)

### Adding new module

mmdetectionì—ì„œ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë“ˆì„ ì‚¬ìš©í•˜ê³  ì‹¶ì„ ë•Œ ì´ mmdet í´ë”ì˜ íŒŒì¼ë“¤ì„ ìˆ˜ì •í•©ë‹ˆë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´ ì €ëŠ” ì´ë²ˆ ëŒ€íšŒì—ì„œ neckì— BiFPNì„ ì¶”ê°€í•˜ì—¬ ì‚¬ìš©í–ˆëŠ”ë°ìš”, neck ì¶”ê°€ë¥¼ ìœ„í•´ì„œëŠ” `models/necks` ìœ„ì¹˜ì— bifpnì´ êµ¬í˜„ëœ python íŒŒì¼ì„ ì¶”ê°€í•˜ê³ , `__init__.py` íŒŒì¼ì— bifpnì„ ì¶”ê°€í•´ì£¼ë©´ ë©ë‹ˆë‹¤. 

**bifpn.py íŒŒì¼ ì¶”ê°€**

![image-20220409222354829](https://user-images.githubusercontent.com/70505378/162576632-a078527c-37ac-4e3f-99c6-224adc7a06f7.png)

**\_\_init\_\_.py íŒŒì¼ ìˆ˜ì •**

```python
# Copyright (c) OpenMMLab. All rights reserved.
from .bfp import BFP
from .channel_mapper import ChannelMapper
from .ct_resnet_neck import CTResNetNeck
from .dilated_encoder import DilatedEncoder
from .dyhead import DyHead
from .fpg import FPG
from .fpn import FPN
from .fpn_carafe import FPN_CARAFE
from .hrfpn import HRFPN
from .nas_fpn import NASFPN
from .nasfcos_fpn import NASFCOS_FPN
from .pafpn import PAFPN
from .rfp import RFP
from .ssd_neck import SSDNeck
from .yolo_neck import YOLOV3Neck
from .yolox_pafpn import YOLOXPAFPN
from .bifpn import BIFPN

__all__ = [
    'FPN', 'BFP', 'ChannelMapper', 'HRFPN', 'NASFPN', 'FPN_CARAFE', 'PAFPN',
    'NASFCOS_FPN', 'RFP', 'YOLOV3Neck', 'FPG', 'DilatedEncoder',
    'CTResNetNeck', 'SSDNeck', 'YOLOXPAFPN', 'DyHead',
    'BIFPN'
]
```





<br>

ì´ìƒìœ¼ë¡œ mmdetectionì„ ì²˜ìŒ ì‹œì‘í•  ë•Œ í•„ìˆ˜ì ìœ¼ë¡œ ì•Œì•„ì•¼ í•  ë¶€ë¶„ë“¤ì— ëŒ€í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œ ë‹¤ë£¬ ë‚´ìš©ë“¤ì€ ì…ë¬¸ìë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ë‚´ìš©ì´ê³ , mmdetectionì„ ì œëŒ€ë¡œ ì´ìš©í•˜ê³  ì»¤ìŠ¤í…€í•˜ê¸° ìœ„í•´ì„œëŠ” **ëª¨ë¸ ìì²´ì— ëŒ€í•œ ì´í•´**ì™€ **mmcv ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•œ ì´í•´**ê°€ ë™ë°˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. 

ì•ìœ¼ë¡œ mmdetectionì„ ì‚¬ìš©í•˜ëŠ” ë° ìˆì–´ì„œ ì´ í¬ìŠ¤íŒ…ì´ ì¡°ê¸ˆì´ë‚˜ë§ˆ ë„ì›€ì´ ë˜ì—ˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤! ğŸ˜Š







<br>

<br>

# ì°¸ê³  ìë£Œ

* 
