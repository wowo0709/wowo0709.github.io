---

layout: single
title: "[AITech][Image Classification] 20220223 - Model"
categories: ['AI', 'AITech', 'ImageClassification']
toc: true
toc_sticky: true
tag: ['PyTorch', 'Transfer Learning']
---



<br>

**_본 포스팅은 번개장터의 '김태진' 강사 님의 강의를 바탕으로 제작되었습니다._** 

# 학습 내용

## Design Model with PyTorch

### PyTorch

먼저 파이토치의 장점에 대해서 알아봅시다. 

* **Low-level**
* **Pythonic**
* **Flexibility**

파이토치는 Keras와 같은 High-level API와 달리 Low-level입니다. 이는 사용자 입장에서 비교적 복잡하다는 단점이 있겠지만, 사용자가 원하는 대로 코드를 손쉽게 변경할 수 있다는 큰 장점이 있습니다. 바로 이 때문에 파이토치와 같은 low-level API가 flexible하다는 이야기를 하는 것입니다. 

또한, 텐서플로와 파이토치의 가장 큰 차이점은 파이토치는 eager-execution을 한다는 것입니다. 이는 그래프를 만들고 컴파일해야 했던 텐서플로 1.X과 다르게 컴파일하는 입장에서 매우 반갑습니다. 코드를 바로바로 돌려보고, 어디서 문제가 생겼는지 쉽게 알 수 있습니다. 이러한 이점 때문에 텐서플로 2.0부터는 이 eager-execution을 지원합니다. 

아래는 Keras와 PyTorch의 모델 training 코드입니다. 

![image-20220223172047732](https://user-images.githubusercontent.com/70505378/155285599-e4a01985-3303-4634-8875-671484bb7999.png)

### nn.Module

PyTorch 모델의 모든 layer들은 nn.Module 클래스를 상속받아 구현됩니다. 그리고 이는 layer들의 forward/backward propagation 과정을 매우 쉽게 만들어줍니다. 

* **nn.Module을 상속받은 모든 클래스의 공통된 특징**
  * 모든 nn.Module은 forward() 함수를 가진다. 
  * 내가 정의한 모델의 forward()를 한 번만 실행한 것으로, 그 모델의 forward에 정의된 모듈 각각의 foward()가 차례로 실행된다. 

![image-20220223172750960](https://user-images.githubusercontent.com/70505378/155285604-712e928f-f9a3-4aa0-bf8c-676ae3dd314d.png)

### Parameters

모델에 있는 모듈들은 모두 각각의 parameter들을 가집니다. 각 파라미터들은 data, grad, requires_grad 프로퍼티를 가지고 있습니다. 

![image-20220223172608792](https://user-images.githubusercontent.com/70505378/155285603-dfd2ff2d-20aa-4568-8ede-449980e85ee8.png)

이러한 PyTorch의 형식과 구조를 미리 알고 있다면 여러가지 응용이 가능한 뿐더러, 발생할 수 있는 에러들도 핸들링 할 수 있습니다. 

<br>

## Pretrained Model

**모델 일반화**를 위해 매번 수 많은 이미지를 학습시키는 것은 까다롭고 비효율적입니다. 

![image-20220223173111979](https://user-images.githubusercontent.com/70505378/155285608-ee141e84-a8ce-4cdc-98b5-50ce3a406fe0.png)

ImageNet이라는 좋은 품질의 대용량 데이터셋이 만들어지고 난 후, ImageNet으로 미리 학습된 좋은 성능이 검증되어 있는 모델들이 많이 공개되었습니다. 이러한 pretrained model을 사용하는 것이 시간적으로 훨씬 효율적입니다. 

`torchvision.models` 또는 `timm` 등의 모듈(라이브러리)을 통해 간단하게 기학습된 좋은 성능의 모델들을 가져다 쓸 수 있습니다. 







<br>

## Transfer Learning

Pretrained model은 내가 원하는 데이터로 학습된 모델은 아닙니다. 따라서, pretrained model을 사용할 때는 맨 마지막의 분류용(Classification)으로 사용되는 FC 층을 우리가 분류할 클래스에 맞는 FC 층으로 변경해줘야 할 필요성이 있습니다. 

![image-20220223173506204](https://user-images.githubusercontent.com/70505378/155285612-16710139-c141-4fed-a891-0e967199815b.png)

분류층을 적절히 변경해준 후에는 내가 가진 데이터로 재학습시킵니다. 이 때도 몇 가지 경우에 따라 모델을 다르게 학습시키면 좋습니다. 예를 들어 CNN Backbone은 아예 학습을 시키지 않는 Feature extraction 방법이 있고, CNN Backbone도 같은 학습시키는 Fine-Tuning 방법이 있습니다. 또는 매 epoch마다 trainable layer들을 늘려가는 다양한 방법이 있습니다. 

많은 방법들 중 크게 아래의 경우를 고려해 볼 수 있습니다. 

**Case 1. 문제를 해결하기 위한 학습 데이터가 충분하다.**

![image-20220223173901422](https://user-images.githubusercontent.com/70505378/155285614-eb98e48f-e08d-4abf-a479-7f22b787f144.png)



**Case 2. 학습 데이터가 충분하지 않다.**

![image-20220223173912593](https://user-images.githubusercontent.com/70505378/155285595-986dc563-023f-4712-adcd-7d529dcc3814.png)















<br>

<br>

# 참고 자료

* 





<br>
