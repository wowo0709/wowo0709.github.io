---
layout: single
title: "[AITech][Image Classification][P stage] 20220304 - Solutions"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['Image Classification']
---



<br>

# 회고

## Level1 Pstage 회고

2주 간의 level1 p stage가 막을 내렸다. 힘들고 쉽지 않은 과정이었지만, 정~~~~말 배운 것이 많았다😊 역시 이론은 실습으로 이어져야 비로소 빛을 발하는 것 같다. 세부적인 회고 내용은 별도로 [P stage 회고] 포스팅을 통해 작성한다. Level 1을 함께 해준 우리 팀원들, 너무 자랑스럽고 감사하다. 앞으로도 계속해서 관계를 이어나갈 수 있기를 간절히 바란다. 

<br>

## 솔루션 공유

**발표 1팀**

* ViT 모델 사용 => OOM의 발생...

  * ViT Large -> Swin Large 로 파라미터를 줄이면서 더 효율적인 학습

* PyTorch Lightning 베이스라인 코드 사용

  * 효과적인 연산 => AMP(메모리 사용량을 절반으로 감소)

* Loss

  * F1 Loss -> Focal loss보다 더 나은 성능
  * convexity에 대한 불확실성, 그리고 미분 가능성에 대한 고려

* EDA

  * age에 따른 심각한 불균형

  * 기존: 0~29, 30~59, 60~
  * 변경: 0~29, 30~57, 58~

* Dataset

  * 마스크를 제대로 쓴 데이터가 5개씩 있으니 그 중 1개만 쓴다. 
  * Undersampling 에 따른 데이터 부족 문제 발생 => val_ratio를 0.1로 변경
  * 사람 이외의 배경은 삭제: rembg 라이브러리를 이용해 배경 추출,  u2net을 이용해 배경 삭제
  * Annotation을 다시 계산: Image 통계값 => Normalize: mean, std

* Co-work

  * Notion, Github를 이용해 실험 내용을 꾸준히 관리 및 업데이트

**발표 2팀(본인 팀)**

* Augmentation
  * torchvision, albumentations
  * 레이블 별 up sampling, down sampling, 특정 mask/gender/age 별 데이터 증폭 시도
* Model
  * 다양한 Image classification model (efficientnet, swin, resnet, vit, beit...)
  * 다양한 이미지 입력(224, 300, 380, 384...) => 모델이 요구하는 입력 이미지로 넣어주는 것이 중요!!
  * 성능이 가장 좋았던 swin transformer 채택
  * 전체 18개 클래스에 대한 앙상블, multi-label 앙상블, k-fold, test time 앙상블 등 다양한 앙상블 시도
* Loss
  * focal loss, weighted CE, ldam loss => ldam loss가 imbalanced data에 가장 좋은 성능을 보여줌
* HPO
  * Ray tuning
  * 통제 변인: Adam, Swin Transformer, CyclicLR, LDAM loss
  * 조작 변인: learning rate, epoch, batch_size
  * 종속 변인: accuracy, F1 score

**발표 3팀**

* Model
  * Multi labeling: mask, gender, age 따로 분류
  * Cross validation 수행
  * Mask: Cross entropy, gender: cross entropy, age: label smoothing, focal
  * Age Model의 성능 부족 => 주된 관심사
* Age labeling model
  * 기존: 0~29, 30~59, 60~
  * 변경: 0~29, 30~57, 58~
  * resnet18 => 학습이 빠르다. 18개 분류에서는 성능이 좋지 않았는데, binary classification에서는 성능이 좋았다. 
  * Swin Transformer와 ResNet18 모델 앙상블
  * 모델이 집중하는 곳을 확인 => GradCam

**발표 4팀**

Face Detection 성능 실험

* 실험 개요
  * 배경 정보 삭제
  * CenterCrop
  * 얼굴 부분만 정확히 추출
  * mediapipe 라이브러리
* 모델 학습 실험
  * CenterCrop(380, 380)
  * efficientnet_b0
  * input size: (224,224)
  * label smoothing loss
  * epoch: 15
  * learning rate: 1e-5
* 주의 사항
  * Face detection도 인공지능 모델이기 때문에, 마스크를 썼을 때 얼굴을 잘 검출하지 못 해 배경 삭제가 잘 안 될 수 있다. 
  * 정도를 조절해서 하면 잘 검출 가능!
  * 전처리된 이미지로 모델을 학습시켜 자주 틀리는 이미지만 전수 조사

<br>

## 마스터 피드백

* 각자 실험을 하며 결과를 공유하면서 협업
* 데이터가 충분하지 않고 Imbalance하다면 분류하고자 하는 이미지 외의 배경을 삭제하는 것이 도움이 될 수 있음
* multi-labeling model도 좋은 시도
* label smoothing training도 좋은 시도
* PyTorch Lightning 사용 시 코드의 간소화 외에 장점은??
* Main Problem을 Sub task로 쪼개기
* Code level에서 다양한 파라미터 실험을 할 수 있는 환경 구축
* **가설을 세우고 충실히 이행하고 잘 기록하고 팀원들과 공유하기!!!**





<br>

