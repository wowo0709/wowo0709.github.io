---
layout: single
title: "[AITech] 20220128 - 회고"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['마스터클래스', 'Data Centric AI']
---



<br>

## 회고

오늘로써 한 주 동안의 PyTorch에 대한 학습이 끝이 났습니다. 

파이토치 개요부터 기본적 연산들, nn.Module, Dataset과 DataLoader, Transfer learning과 Hyperparameter tuning, Multi-GPU, Trouble shooting 등 다양한 내용들을 다루는 것이 쉽지는 않았지만, 적절한 실습과 개념 문제들이 병행된 것 같아 많은 것을 배울 수 있었던 한 주였습니다. 

이전까지는 파이토치를 거의 사용해 본 경험이 없기 때문에 한 주 동안의 학습만으로는 많은 부분을 커버하기는 어렵겠지만, 앞으로 직접 모델을 만들고 학습 시키고, 성능을 개선하려는 일련의 과정과 노력을 통해 앞으로 더욱 더 익숙해지리라 생각합니다. 

무엇보다 각 내용들을 산발적으로 배우는 것이 아니라, 모델을 만들고 학습시키는 일련의 과정에 따라 순서대로 한 부분 씩 배우는 것이 전체 흐름을 이해하는 데에도 많은 도움이 되었습니다!!😁😁

한 주 간의 파이토치 모델링 과정을 배우면서 그 간의 흐름을 간단히 아래와 같이 정리해보았습니다. 

* **데이터 전처리(Dataset, Transform, Compose)**
* **데이터 불러오기(DataLoader, Sampler)**
* **신경망 구성(nn.Module, pretrained model)**
* **오차함수 및 최적화 기법 선택(Loss, Optimizer, metrics)**
* **학습 및 추론 옵션 설정(transfer learning, hyperparameter tuning, multi-gpu, monitoring)**
* **훈련, 검증(training, validating, troubleshooting)**

다음 주부터 진행될 내용들도 기대가 많이 됩니다 😊

앞으로 계속 지치지 않고 잘 나아갔으면 좋겠습니다 ㅎㅎ

<br>

### 마스터 클래스

#### FAQ

* AI에 대한 지식, 모델 개발 능력도 중요하지만 **'프로그래밍 역량'**이 계속해서 중요해질 것이다. 
* 웹 프로그래밍 
  * 서버-클라이언트 관계, 데이터베이스, 요청-응답 등에 대해 배울 수 있다. 
  * **시스템을 하나 만들어봐라!**
* AI의 길?
  * 엔지니어란 문제를 푸는 데 능력을 쓰는 사람
  * **행복하게 살 수 있는 길을 찾아라!**
* 효율적으로 공부할 수 있는 방법?
  * 효율보다는 일단 '양'을 늘려라. 양을 늘리다 보면 어느 순간 그 내용들이 연결되는 듯한 느낌이 온다. 
  * 그리고 그 느낌이 오면 지식의 습득이 빨라진다. 
  * MLOps: 리눅스(Shell Script), 빅데이터에 대한 공부가 기본!
* **하나의 시스템을 만들어서 인공지능을 삽입하는 연습**
  * 인공지능의 실제 프로덕트에서의 작동 과정에 대해 잘 공부할 수 있음

#### Data Centric AI

* 코딩을 못 하면 ML/DL 어렵나요?
  * 어렵다! 
* ML/DL 세계의 변화
  * using pre-trained model
  * 모델 개발/하이퍼파라미터 튜닝 싸움
* Research ML
  * 데이터는 준비 -> 모델 개발 -> 하이퍼파라미터 튜닝 -> 논문
* Project-Real World ML
  * ML Code 개발은 매우 작은 부분이다. 
  * 모델은 AWS, Google 등에서 제공하는 모델을 쓰고, 데이터 수집과 전처리/시스템 최적화 등에 신경을 쓴다. 
* Issues
  * Data
    * 양질의 데이터 확보가 관건
    * Production time 데이터와 Experiment 데이터가 다른 문제도 발생
    * 끊임없이 데이터를 관리하고 확보하려는 노력이 필요
      * User generated data(기존의 플랫폼 기업): inputs, clicks for recommendation
      * System generated data: logs, metadata, prediction
      * Data Flywheel: 사용자들의 참여로 데이터를 개선
      * Data augmentation: 데이터를 임의로 추가 확보
    * Data drift
      * 시간이 지나면서 데이터는 계속 바뀐다! (OTT 플랫폼)
    * Data Feedback Loop
      * 사용자로부터 오는 데이터를 자동화하여 모델에 피딩해주는 체계가 필요
      * ML/DL 코드 이상의 네트워크 하드웨어부터 데이터 플랫폼까지의 이해
      * 앞으로의 많은 ML/DL 엔지니어가 가져야 할 역량 중 하나
      * 특히 대용량 데이터를 다뤄본 경험이 중요할 것(Multi GPU, 데이터를 다루는 앞뒷단 부분)
  * 앞으로 알아야 할 것을
    * **ML Ops**
    * **당연히 데이터베이스**
    * **Cloud - AWS, GCP, Azure**
    * **Spark (+ Hadoop)**
    * **Linux, Docker**
    * **스케줄링 도구들(쿠브플로우, MLFlow, AirFlow)**
  * RAY, DASK, RAPIDS
  * Model, Algorithms, Metrics, Hyperparameter tuning



















<br>
