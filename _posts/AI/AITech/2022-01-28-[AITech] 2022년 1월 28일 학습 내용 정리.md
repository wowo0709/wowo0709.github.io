---
layout: single
title: "[AITech] 2022ë…„ 1ì›” 28ì¼ í•™ìŠµ ë‚´ìš© ì •ë¦¬"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['íŒŒì´í† ì¹˜', 'ì‹¤ìŠµ','MultiGPU', 'HyperparameterTuning', 'TransferLearning', 'TrobleShooting']
---



<br>

## í•™ìŠµ ë‚´ìš© ì •ë¦¬

### Multi-GPU í•™ìŠµ

#### ê°œë… ì •ë¦¬

* `Single VS Multi`: 1ê°œ VS 2ê°œ ì´ìƒ
* `GPU VS Node`: GPU VS ì»´í“¨í„°
* `Single Node Single GPU`: ì»´í“¨í„° 1ëŒ€ì— GPU 1ê°œ
* `Single Node Multi GPU`: ì»´í“¨í„° 1ëŒ€ì— GPU ì—¬ëŸ¬ ê°œ
* `Multi Node Multi GPU`: ì»´í“¨í„° ì—¬ëŸ¬ ëŒ€ì— GPU ì—¬ëŸ¬ ëŒ€

#### Model Parallel

ë‹¤ì¤‘ GPUì— í•™ìŠµì„ ë¶„ì‚°í•˜ëŠ” ë°©ë²•ì—ëŠ” **ëª¨ë¸ì„ ë‚˜ëˆ„ëŠ” ë°©ë²•**ê³¼ **ë°ì´í„°ë¥¼ ë‚˜ëˆ„ëŠ” ë°©ë²•**ì´ ìˆë‹¤. 

ëª¨ë¸ì„ ë‚˜ëˆ„ëŠ” ê²ƒì€ ë¹„êµì  ì˜ˆì „ë¶€í„° ì‚¬ìš©í•´ì˜¨ ê¸°ë²•(AlexNet)ì´ì§€ë§Œ, ëª¨ë¸ì˜ ë³‘ëª©ì´ë‚˜ íŒŒì´í”„ë¼ì¸ì˜ ì–´ë ¤ì›€ìœ¼ë¡œ ì¸í•´ ëª¨ë¸ ë³‘ë ¬í™”ëŠ” ê³¡ë‚œì´ë„ ê³¼ì œì´ë‹¤. 

![image-20220128111218264](https://user-images.githubusercontent.com/70505378/151489744-cbbf842e-76e7-4dec-9281-932bcd8e3764.png)

* ì˜ˆì‹œ ì½”ë“œ

```python
class ModelParallelResNet50(ResNet):
    def __init__(self, *args, **kwargs):
        super(ModelParallelResNet50, self).__init__(
        	Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs)
        
        self.seq1 = nn.Sequential(
        	self.conv1, self.bn1, self.relu, self.maxpool, self.layer1, self.layer2
        ).to('cuda:0')
        
        self.seq2 = nn.Sequential(
        	self.layer3, self.layer4, self.avgpool,
        ).to('cuda:1')
        
        self.fc.to('cuda:1')
        
    def forward(self, x):
        x = self.seq2(self.seq1(x).to('cuda:1'))
        return self.fc(x.view(x.size(0), -1))
```





#### Data Parallel

Data Parallel ê¸°ë²•ì€ ë°ì´í„°ë¥¼ ë‚˜ëˆ  GPUì— í• ë‹¹í•œ í›„ ê²°ê³¼ì˜ í‰ê· ì„ ì·¨í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. 

![image-20220128112840914](https://user-images.githubusercontent.com/70505378/151489746-44d3d6e0-0f29-449f-b502-ed1e06867d4b.png)

ìœ„ ê·¸ë¦¼ì„ ë³´ë©´ 'Forward ì‹œ ë¶„ë°°ê°€ ì¼ì–´ë‚˜ê³  Backwardê°€ ì™„ë£Œëœ í›„ ì·¨í•©'í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ì¤‘ê°„ì— Forwardì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ GPUê°€ ì·¨í•©í•œ í›„ gradientë¥¼ ê³„ì‚°í•˜ê³ , ë‹¤ì‹œ ë¶„ë°°í•˜ëŠ” ê³¼ì •**ì´ ì¼ì–´ë‚˜ê²Œ ë©ë‹ˆë‹¤. 

ì´ëŠ” **Global Interpreter Lock**ì´ë¼ê³  í•˜ëŠ” íŒŒì´ì¬ì˜ ë©€í‹° í”„ë¡œì„¸ì‹± ìƒì˜ ì œì•½ ì‚¬í•­ ë•Œë¬¸ì´ë¼ê³  í•©ë‹ˆë‹¤. 

ìœ„ì™€ ê°™ì€ Data Parallel ê¸°ë²•ì€ íŒŒì´í† ì¹˜ì—ì„œ ì œê³µí•˜ëŠ” DataParallel í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨íˆ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
parallel_model = torch.nn.DataParallel(model) # ì´ê²Œ ì „ë¶€!!

# Forward ~ Loss Computation
predictions = parallel_model(inputs) # Forward pass on multi-GPUs
loss = loss_function(predictions, labels) # Compute loss function

# Gradient Backward propagation
loss.mean().backward() # Average GPU-losses + backward pass
optimizer.step() # Optimizer step

predictions = parallel_model(inputs) # Forward pass with new parameters
```

ê·¸ëŸ°ë° `DataParallel` í´ë˜ìŠ¤ëŠ” ìœ„ì—ì„œ ë§í–ˆë“¯ì´, ë‹¨ìˆœíˆ ë°ì´í„°ë¥¼ ë¶„ë°°í•œ í›„ í‰ê· ì„ ì·¨í•˜ê³  ë‹¤ì‹œ ë¶„ë°°ë¥¼ í•´ì£¼ëŠ” ë™ì‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 

ì´ëŠ” **GPU ì‚¬ìš© ë¶ˆê· í˜• ë¬¸ì œ**ë‚˜ **Batch ì‚¬ì´ì¦ˆ ê°ì†Œ(ì·¨í•©í•˜ëŠ” í•˜ë‚˜ì˜ GPUì˜ ë³‘ëª©)** ë“±ì˜ ë¬¸ì œë¥¼ ì•¼ê¸°í•©ë‹ˆë‹¤. 

<br>

ì´ë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ `DistributedDataParallel` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê³ , í•´ë‹¹ í´ë˜ìŠ¤ëŠ” **ê° CPUë§ˆë‹¤ ê°œë³„ processë¥¼ ìƒì„±í•˜ì—¬ GPUì— í• ë‹¹**í•¨ìœ¼ë¡œì¨ **ì¤‘ê°„ì— ì·¨í•©í•˜ëŠ” ê³¼ì •ì„ ì—†ì•¨ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ì¡°ê¸ˆ ë” ë³µì¡í•˜ì§€ë§Œ ë›°ì–´ë‚œ ë³‘ë ¬í™” íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
train_sampler = torch.utils.data.distributed.DistributedSampler(train_data)
shuffle = False
pin_memory = True

trainloader = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=True
										pin_memory=pin_memory, num_workers=3,
										shuffle=shuffle, sampler=train_sampler)

def main():
    n_gpus = torch.cuda.device_count()
    torch.multiprocessing.spawn(main_worker, nprocs=n_gpus, args=(n_gpus, ))
    
def main_worker(gpu, n_gpus):
    image_size = 224
    batch_size = 512
    num_worker = 8
    epochs = ...
    
    batch_size = int(batch_size / n_gpus)
    num_worker = int(num_worker / n_gpus)
    # ë©€í‹° í”„ë¡œì„¸ì‹± í†µì‹  ê·œì•½ ì •ì˜
    torch.distributed.init_process_group(
    		backend='ncclâ€™ , init_method='tcp://127.0.0.1:2568â€™ , world_size=n_gpus, rank=gpu)
    
    model = MODEL
    # Distributed data parallel ì •ì˜
    torch.cuda.set_device(gpu)
    model = model.cuda(gpu)
    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu])
```

 âœ‹ íŒŒì´ì¬ì˜ ë©€í‹°í”„ë¡œì„¸ì‹± ì½”ë“œ

```python
from multiprocessing import Pool

def f(x):
	return x*x

if __name__ == '__main__':
    with Pool(5) as p:
        print(p.map(f, [1, 2, 3]))
```

<br>

### Hyperparameter Tuning

ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°ì—ëŠ” í¬ê²Œ ë‹¤ìŒì˜ 3ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. 

1. ëª¨ë¸ì˜ êµ¬ì¡° ê°œì„ : í˜„ì‹¤ì ìœ¼ë¡œ í° ë³€í™”ë¥¼ ë§Œë“¤ê¸° ì–´ë µë‹¤. 
2. ë°ì´í„° ì¦ê°•/ë³´ê°•: ê°€ì¥ ì¤‘ìš”í•˜ë©´ì„œ í° íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤. 
3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹: ì•„ì£¼ í° ì°¨ì´ë¥¼ ì¼ìœ¼í‚¤ì§€ëŠ” ì•Šì§€ë§Œ ì‹œë„í•´ ë³¼ ë§Œ í•˜ë‹¤. 

ì´ ì¤‘ **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**ì€ ì‚¬ì‹¤ ì´ì „ì—ëŠ” ê·¸ ê°’ì— ì˜í•´ ì„±ëŠ¥ì´ í¬ê²Œ ì¢Œìš°ë  ë•Œë„ ìˆì—ˆì§€ë§Œ, ìš”ì¦˜ì€ ê·¸ë ‡ì§€ëŠ” ì•Šë‹¤ê³  í•©ë‹ˆë‹¤. 

í•˜ì§€ë§Œ learning rate, ëª¨ë¸ì˜ í¬ê¸°, batch size, optimizer ë“± ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ íŠœë‹í•˜ëŠ” ë°©ë²•ì€ **ë§ˆì§€ë§‰ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¡°ê¸ˆ ë” ëŒì–´ì˜¬ë¦¬ê³  ì‹¶ì„ ë•Œ** ì‚¬ìš©í•´ ë³¼ ë§Œí•œ ë°©ë²•ì…ë‹ˆë‹¤. 

í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ ë°©ë²•ì—ëŠ” ì „í†µì ìœ¼ë¡œ ì‚¬ìš©ë˜ì–´ ì˜¨ **grid search**ì™€ **random search**ê°€ ìˆìœ¼ë©°, ë³´í†µ random searchë¡œ íŠœë‹ì„ í•˜ë‹¤ê°€ ì„±ëŠ¥ì´ ì¢‹ì€ ë¶€ë¶„ì´ ë°œê²¬ë˜ë©´ ê·¸ ë¶€ë¶„ ë¶€ê·¼ì—ì„œ grid searchë¥¼ ìˆ˜í–‰í•˜ëŠ” ì‹ìœ¼ë¡œ ìˆ˜í–‰ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. 

![image-20220128115041782](https://user-images.githubusercontent.com/70505378/151489753-b580ccda-42df-428a-b598-dbe863baa8ec.png)

ìµœê·¼ì—ëŠ” ë‘ ë°©ë²• ì™¸ì— **ë² ì´ì§€ì•ˆ ê¸°ë²•**ë“¤ì´ ì£¼ë„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ì— ëŒ€í•´ `BOHB(Baesian Optimization Hyper Band) 2018`ì´ë¼ëŠ” ë…¼ë¬¸ì„ ì½ì–´ë³´ë©´ ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤. 

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ì´ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê³¼ì •ì„ ê°„ì†Œí™” ì‹œì¼œì£¼ëŠ” **Ray**ë¼ëŠ” ëª¨ë“ˆì— ëŒ€í•´ ì†Œê°œí•˜ê³  ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ë ¤í•©ë‹ˆë‹¤. 

#### Ray

* Multi-node multi processingë¥¼ ì§€ì›í•˜ë©° ML/DLì˜ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê°œë°œëœ ëª¨ë“ˆ
* ê¸°ë³¸ì ìœ¼ë¡œ í˜„ì¬ì˜ ë¶„ì‚° ë³‘ë ¬ ML/DL ëª¨ë“ˆì˜ í‘œì¤€
* Hyperparameter searchë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ëª¨ë“ˆ ì œê³µ

```python
data_dir = os.path.abspath("./data")
load_data(data_dir)
# 1. configì— search space ì§€ì •
config = {
    "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
    "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
    "lr": tune.loguniform(1e-4, 1e-1),
    "batch_size": tune.choice([2, 4, 8, 16])
}
# 2. í•™ìŠµ ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜ ì§€ì •
scheduler = ASHAScheduler(
                metric="loss", mode="min", max_t=max_num_epochs, grace_period=1,
                reduction_factor=2)
# 3. ê²°ê³¼ ì¶œë ¥ ì–‘ì‹ ì§€ì •
reporter = CLIReporter(metric_columns=["loss", "accuracy", "training_iteration"])
# 4. ë³‘ë ¬ ì²˜ë¦¬ ì–‘ì‹ìœ¼ë¡œ í•™ìŠµ ìˆ˜í–‰
result = tune.run(partial(train_cifar, data_dir=data_dir),
                resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
                config=config, num_samples=num_samples,
                scheduler=scheduler,
                progress_reporter=reporter)
```

Ray ëª¨ë“ˆì€ hyperparameter searchë¥¼ ìˆ˜í–‰í•  ë•Œ ì²˜ìŒì—ëŠ” ëª¨ë“  ê²½ìš°ë¡œ í•™ìŠµì„ ì‹œí–‰í•˜ë‹¤ê°€ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ ê²½ìš°ëŠ” ë” ì´ìƒ í•™ìŠµì„ ì‹œí–‰í•˜ì§€ ì•Šê³ , ì„±ëŠ¥ì´ ì¢‹ì€ ê²½ìš°ë“¤ë¡œë§Œ í•™ìŠµì„ ê³„ì† ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ ì ˆì•½í•©ë‹ˆë‹¤. 

![image-20220128115742600](https://user-images.githubusercontent.com/70505378/151489755-8a135c5e-865f-4a99-98c1-4c29fdab9608.png)



ë˜í•œ ì§€ë‚œ í¬ìŠ¤íŒ…ì—ì„œ ì†Œê°œí•œ wandb ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ê·¸ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê¸° ë”ìš± ì¢‹ê¸° ë•Œë¬¸ì— ë‘ ëª¨ë“ˆì„ í•¨ê»˜ í™œìš©í•˜ë©´ ì–´ë µì§€ ì•Šê²Œ hyperparameter tuningì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€í•©ë‹ˆë‹¤. 

<br>

### PyTorch Troubleshooting

ì´ ì„¹ì…˜ì—ì„œëŠ” ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ê°€ì¥ ë§ì´ ë§Œë‚˜ê²Œ ë˜ëŠ” ì—ëŸ¬ì´ì, í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ `OOM(Out of Memory)` ì—ëŸ¬ì— ëŒ€í•´ ì–˜ê¸°í•´ë³´ê³ ì í•©ë‹ˆë‹¤. 

**OOMì´ í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ ì´ìœ **

* ì™œ, ì–´ë””ì„œ ë°œìƒí–ˆëŠ”ì§€ ì•Œê¸° ì–´ë µë‹¤. 
* Error backtrackingì´ ì´ìƒí•œ ë°ë¡œ ê°„ë‹¤. 
* ë©”ëª¨ë¦¬ì˜ ì´ì „ ìƒí™©ì˜ íŒŒì•…ì´ ì–´ë µë‹¤. 

OOMì„ í•´ê²°í•˜ê¸° ìœ„í•´ ê°€ì¥ ì‰½ê²Œ ì‹œë„í•´ ë³¼ ìˆ˜ ìˆëŠ” ë°©ë²•ìœ¼ë¡œëŠ” **Batch sizeë¥¼ ì¤„ì´ëŠ” ì‹œë„**ê°€ ìˆìŠµë‹ˆë‹¤. ì•„, ê·¸ë¦¬ê³  batch sizeë¥¼ ì¡°ì •í•œ í›„ì—ëŠ” GPU clean(kernel restart) ê³¼ì •ì„ í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”!

#### OOM í•´ê²°ì„ ìœ„í•œ ë°©ë²•ë“¤

**torch.cuda.empty_cache()**

empty_cache() í•¨ìˆ˜ëŠ” ì‚¬ìš©ë˜ì§€ ì•Šê³  ìˆëŠ” GPU ìƒ cacheë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. (ê°€ë¹„ì§€ ì»¬ë ‰í„°ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)

ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ ê°€ìš© ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë©”ëª¨ë¦¬ ì£¼ì†Œì˜ ì°¸ì¡°ë¥¼ ëŠëŠ” del ê³¼ëŠ” êµ¬ë¶„ë©ë‹ˆë‹¤)

empty_cache() í•¨ìˆ˜ëŠ” í•™ìŠµ ì‹œì‘ ì „ì— í•œ ë²ˆ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤ê³  í•©ë‹ˆë‹¤ ^_^

```python
import torch
from GPUtil import showUtilization as gpu_usage

print("Initial GPU Usage")
gpu_usage()
'''
Initial GPU Usage
| ID | GPU | MEM |
------------------
| 0 | 0% | 0% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
GPU Usage after allcoating a bunch of Tensors
'''
tensorList = []
for x in range(10):
	tensorList.append(torch.randn(10000000,10).cuda())
print("GPU Usage after allcoating a bunch of Tensors")
gpu_usage()
'''
GPU Usage after allcoating a bunch of Tensors
| ID | GPU | MEM |
------------------
| 0 | 0% | 40% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
'''
del tensorList
print("GPU Usage after deleting the Tensors")
gpu_usage()
'''
GPU Usage after deleting the Tensors
| ID | GPU | MEM |
------------------
| 0 | 0% | 40% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
'''
torch.cuda.empty_cache()
print("GPU Usage after emptying the cache")
gpu_usage()
'''
GPU Usage after emptying the cache
| ID | GPU | MEM |
------------------
| 0 | 0% | 5% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
'''
```

**training loopì— tensorë¡œ ì¶•ì ë˜ëŠ” ë³€ìˆ˜ í™•ì¸**

tensorë¡œ ì²˜ë¦¬ë˜ëŠ” ë³€ìˆ˜ë“¤ì€ GPU ìƒì—ì„œ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ê³ , í•´ë‹¹ ë³€ìˆ˜ loop ì•ˆì— ì—°ì‚°ì´ ìˆì„ ë•Œ GPUì— computational graphë¥¼ ìƒì„±í•˜ë©´ì„œ ë©”ëª¨ë¦¬ë¥¼ ì ì‹í•´ê°‘ë‹ˆë‹¤. 

ë”°ë¼ì„œ ì´ëŸ° ê²½ìš°ì—ëŠ” 1-d tensorì˜ ê²½ìš° íŒŒì´ì¬ì˜ ê¸°ë³¸ ê°ì²´(int, float, list ë“±)ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬í•  ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤. 

```python
total_loss = 0

for x in range(10):
    # assume loss is computed
    iter_loss = torch.randn(3,4).mean()
    iter_loss.requires_grad = True
    # total_loss += iter_loss ëŒ€ì‹ , 
    iter_loss += iter_loss.item # ë˜ëŠ” float(iter_loss)
```

**del ëª…ë ¹ì–´ì˜ ì ì ˆí•œ ì‚¬ìš©**

í•„ìš”ê°€ ì—†ì–´ì§„ ë³€ìˆ˜ë¥¼ ì ì ˆíˆ ì‚­ì œí•˜ëŠ” ê²ƒë„ ë°©ë²•ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
for i in range(5):
    intermediate = f(input[i])
    result += g(intermediate)
    
del intermediate # del
output = h(result)
del result # del
return output
```

**ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì—¬ë³´ê¸°(1ë¡œ í•´ë³´ê¸°)**

**torch.no_grad()**

ëª¨ë¸ ì¶”ë¡  ì‹œì ì—ëŠ” ì—­ì „íŒŒ ê³¼ì •ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ, `torch.no_grad()` contextë¥¼ ì‚¬ìš©í•˜ì—¬ backward ê³¼ì •ìœ¼ë¡œ ì¸í•´ ì‚¬ìš©ë˜ëŠ” ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
with torch.no_grad(): # torch.no_grad()
    for data, target in test_loader:
        output = network(data)
        test_loss += F.nll_loss(output, target, size_average=False).item()
        pred = output.data.max(1, keepdim=True)[1]
        correct += pred.eq(target.data.view_as(pred)).sum()
```

**tensorì˜ precision ì¤„ì´ê¸°**

tensorì˜ float precisionì„ 8, 16bit ìˆ˜ì¤€ìœ¼ë¡œ ì¤„ì´ëŠ” ê²ƒë„ í•˜ë‚˜ì˜ ë°©ë²•ì…ë‹ˆë‹¤. 

ê·¸ëŸ¬ë‚˜ ì´ ë°©ë²•ì€ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆê³ , ë§¤ìš° í° ëª¨ë¸ì„ ëŒë¦¬ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ë©´ ê¶Œì¥ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— 'ìµœí›„ì˜ ìˆ˜ë‹¨' ì •ë„ë¡œ ìƒê°í•´ ë‘ëŠ” ê²ƒì´ ì¢‹ì„ ë“¯ í•©ë‹ˆë‹¤. 

<br>

ì´ì™¸ì—ë„ **CUDNN_STATUS_NOT_INIT**ì´ë‚˜ **device-side-assert** ë“±ì˜ ì—ëŸ¬ë„ cudaì™€ ê´€ë ¨í•˜ì—¬ OOMì˜ ì¼ì¢…ì´ë¼ê³  í•  ìˆ˜ ìˆê³ , ì—­ì‹œ ì ì ˆí•œ ì½”ë“œì˜ ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ì— ëŒ€í•´ ì°¸ê³ í•  ë§Œí•œ ë‚´ìš©ì€ ì•„ë˜ ì°¸ê³ ìë£Œ _GPU ì—ëŸ¬ ì •ë¦¬_ ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

<br>

### ì‹¬í™” ê³¼ì œ: Transfer Learning & Hyperparameter Tuning

2ì£¼ì°¨ íŒŒì´í† ì¹˜ ì‹¬í™” ê³¼ì œì—ì„œëŠ” **ì „ì´ í•™ìŠµê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**ì— ê´€í•œ ë‚´ìš©ì„ ë‹¤ë£¨ì—ˆëŠ”ë°ìš”, í•µì‹¬ ë‚´ìš©ë“¤ë§Œ ì •ë¦¬í•´ë´…ë‹ˆë‹¤. 

#### Transfer Learning

* ëŒ€ìš©ëŸ‰ì˜ ë°ì´í„°(Source Task)ë¡œ í•™ìŠµëœ ì´ë¯¸ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ì„ ë‚˜ì˜ ëª©ì ì— ë§ëŠ” ë°ì´í„°(Target Task)ë¡œ ì¬í•™ìŠµì‹œì¼œ ëª©ì ì— ë§ëŠ” ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒ
* Source taskì™€ Target taskì— ì •ë‹µ(label) ìœ ë¬´ì— ë”°ë¼ ë‹¤ì–‘í•œ ì „ì´ í•™ìŠµ ë°©ë²•ì´ ìˆëŠ”ë°, ê·¸ ì¤‘ ë‘ taskì—ì„œ ëª¨ë‘ ì •ë‹µì´ ìˆëŠ” ê²½ìš°ì— **Fine-Tuning** ê¸°ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
  * Fine Tuning ë°©ë²•ì—ì„œëŠ” ê°€ì ¸ì˜¨ ëª¨ë¸ì„ ì „ë¶€ ì¬í•™ìŠµ ì‹œí‚¬ ìˆ˜ë„ ìˆê³ , íŠ¹ì§• ì¶”ì¶œ(Feature Extraction) ë¶€ë¶„ì€ ê³ ì •(frozen)ì‹œí‚¤ê³  ë¶„ë¥˜ ë¶€ë¶„ë§Œ í•™ìŠµì‹œí‚¬ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
  * ë˜ëŠ” epochê°€ ì§„í–‰ë˜ë©´ì„œ layerì˜ ê³ ì •ì„ ì¡°ê¸ˆì”© í’€ì–´ì£¼ëŠ” ë°©ë²•ë„ ìˆìŠµë‹ˆë‹¤.  

ì „ì´ í•™ìŠµ ì„¹ì…˜ì—ì„œëŠ” ImageNet ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ResNet18 ëª¨ë¸ì„ Fashion MNIST ë°ì´í„°ì…‹ìœ¼ë¡œ ì „ì´ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤. 

```python
imagenet_resnet18 = torchvision.models.resnet18(pretrained=True)
fashion_train = torchvision.datasets.FashionMNIST(root='./fashion', train=True, download=True)
fashion_test = torchvision.datasets.FashionMNIST(root='./fashion', train=False, download=True)
# ëª¨ë¸ êµ¬ì¡° í™•ì¸
print(imagenet_resnet18)
'''
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1000, bias=True)
)
'''
```

<br>

ì „ì´í•™ìŠµì„ ì‹œí‚¤ê¸° ìœ„í•´ í•„ìˆ˜ì ìœ¼ë¡œ í•´ì•¼ í•˜ëŠ” ê²ƒì´ 2ê°€ì§€ ìˆëŠ”ë°ìš”, ì´ëŠ” **ëª¨ë¸ì˜ ì…ë ¥/ì¶œë ¥ layer ìˆ˜ì •**ê³¼ **ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”**ì…ë‹ˆë‹¤. 

**ëª¨ë¸ ì…ë ¥/ì¶œë ¥ layer ìˆ˜ì •**

ImageNetìœ¼ë¡œ í•™ìŠµëœ ResNet18 ëª¨ë¸ì˜ ì…ë ¥ í¬ê¸°ëŠ” (3, 28, 28)ì´ê³ , ìš°ë¦¬ì˜ ëª©ì ì¸ Fashion MNISTì˜ í¬ê¸°ëŠ” (28, 28) ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ ì±„ë„ ê°œìˆ˜ê°€ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì´ ì¤‘ìš”í•œë°ìš”, ImageNetì˜ ì±„ë„ ê°œìˆ˜ëŠ” 3ì´ê³  Fashion MNISTì˜ ì±„ë„ ê°œìˆ˜ëŠ” 1(grayscale)ì…ë‹ˆë‹¤. 

âœ‹ ëª¨ë¸ì˜ ì…ë ¥ ì±„ë„ ê°œìˆ˜ì™€ ë°ì´í„° ì…‹ì˜ ì…ë ¥ ì±„ë„ ê°œìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
'''CNN ëª¨ë¸ì˜ ì…ë ¥ í¬ê¸° í™•ì¸í•˜ê¸°'''
imagenet_resnet18.conv1.weight.shape # torch.Size([64, 3, 7, 7]) => (batch_size, channel, height, width)
imagenet_resnet18.conv1.weight.shape[1] # ì±„ë„ ê°œìˆ˜: 3
'''Fashion MNIST ë°ì´í„°ì…‹ì˜ ì…ë ¥ í¬ê¸° í™•ì¸í•˜ê¸°'''
fashion_train[0] # (<PIL.Image.Image image mode=L size=28x28 at 0x7F6608B19BD0>, 9)
np.array(fashion_train[0][0]).shape # (28, 28)
```



Convolution ì—°ì‚° ì‹œ kernelì˜ channel ìˆ˜ëŠ” inputì˜ channel ìˆ˜ì™€ ë™ì¼í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì²«ë²ˆì§¸ convolution layerë¥¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤. 

```python
target_model = imagenet_resnet18

FASHION_INPUT_NUM = 1
target_model.conv1 = torch.nn.Conv2d(FASHION_INPUT_NUM, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
```

> [Con2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=conv2d#torch.nn.Conv2d) ëª¨ë“ˆì˜ ì¸í„°í˜ì´ìŠ¤
>
> torch.nn.Conv2d(*in_channels*, *out_channels*, *kernel_size*, *stride=1*, *padding=0*, *dilation=1*, *groups=1*, *bias=True*, *padding_mode='zeros'*, *device=None*, *dtype=None*)

ê·¸ë¦¬ê³  ì¶œë ¥ layerë¥¼ ìš°ë¦¬ ëª©ì ì— ë§ëŠ” layerë¡œ êµì²´í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. 

Pretrained modelì˜ ì¶œë ¥ì¸µ(Linear layer(FC layer))ì˜ ê°€ì¤‘ì¹˜ì˜ ê°œìˆ˜ëŠ” (1000, 512)ë¡œ, (out_features, in_features) ëª¨ì–‘ê¼´ì´ê¸° ë•Œë¬¸ì— ì¦‰ outputì˜ ê°œìˆ˜ëŠ” 1000ê°œ ì…ë‹ˆë‹¤. ì´ë¥¼ in_featuresëŠ” ë™ì¼í•˜ê³  out_featuresëŠ” target task, ì¦‰ Fashion MNISTì˜ classì˜ ê°œìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡ êµì²´í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. 

```python
FASHION_CLASS_NUM = 10
target_model.fc = torch.nn.Linear(in_features=512, out_features=FASHION_CLASS_NUM, bias=True)
```

<br>

**ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”**

ì´ë ‡ê²Œ ëª¨ë¸ì˜ layerë¥¼ ìˆ˜ì •/êµì²´í•´ì£¼ì—ˆìœ¼ë©´ ì´ˆê¸°í™”ë¥¼ í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤. 

ë³´í¸ì ì¸ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ë°©ë²•ìœ¼ë¡œëŠ” weightì˜ ê²½ìš° Xavier Initializationìœ¼ë¡œ, biasì˜ ê²½ìš° in_features í¬ê¸°ë¥¼ nì´ë¼ í–ˆì„ ë•Œ U(-1/root(n), 1/root(n))ì˜ uniform distributionìœ¼ë¡œ í•´ì£¼ëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. 

```python
  torch.nn.init.xavier_uniform(target_model.conv1.weight)
  torch.nn.init.xavier_uniform_(target_model.fc.weight)
  stdv = (1/target_model.fc.in_features)**(1/2)
  torch.nn.init.uniform_(target_model.fc.bias, -stdv, stdv)
```

> [torch.nn.init.xavier_uniform_()](https://pytorch.org/docs/stable/nn.init.html?highlight=uniform#torch.nn.init.xavier_uniform_)ì˜ ì¸í„°í˜ì´ìŠ¤
>
> torch.nn.init.xavier_uniform_(*tensor*, *gain=1.0*)
>
> [torch.nn.init.uniform_()](https://pytorch.org/docs/stable/nn.init.html?highlight=uniform#torch.nn.init.uniform_)ì˜ ì¸í„°í˜ì´ìŠ¤
>
> torch.nn.init.uniform_(*tensor*, *a=0.0*, *b=1.0*)

âœ‹ ì´ì™¸ì—ë„ ì¹´ì´ë° ì´ˆê¸°í™”([torch.nn.init.kaiming_uniform_()](https://pytorch.org/docs/stable/nn.init.html?highlight=uniform#torch.nn.init.kaiming_uniform_)), ì •ê·œ ë¶„í¬ ì´ˆê¸°í™”([torch.nn.init.normal_()](https://pytorch.org/docs/stable/nn.init.html?highlight=normal#torch.nn.init.normal_)), ìƒìˆ˜ ì´ˆê¸°í™”([torch.nn.init.constant_()](https://pytorch.org/docs/stable/nn.init.html?highlight=torch%20init%20nn%20constant_#torch.nn.init.constant_)) ë“± ë§ì€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. 

<br>

**ëª¨ë¸ í•™ìŠµí•˜ê¸°**

ëª¨ë¸ í•™ìŠµì— ëŒ€í•œ ì½”ë“œëŠ” [PyTorch - Transfer Learning for Computer Vision Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor)ì— ìì„¸í•˜ê²Œ ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤. 

ì—¬ê¸°ì„œ ì§šê³  ë„˜ì–´ê°ˆ ê²ƒì€ ì „ì²´ ëª¨ë¸ì˜ ëª¨ë“  layerë¥¼ ì¬í•™ìŠµ ì‹œí‚¬ ìˆ˜ë„ ìˆê³ , feature extraction ë¶€ë¶„ì€ ê³ ì •ì‹œí‚¤ê³  classification ë¶€ë¶„ë§Œ ì¬í•™ìŠµ ì‹œí‚¬ ìˆ˜ë„ ìˆìœ¼ë©°, ì ì°¨ layerì˜ ê³ ì •ì„ í’€ì–´ì£¼ëŠ” ì‹ìœ¼ë¡œ ì¬í•™ìŠµ ì‹œí‚¬ ìˆ˜ë„ ìˆëŠ” ì—¬ëŸ¬ ë°©ë²•ì´ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. 

```python
# ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³ ì •ì‹œí‚¤ê¸°
for param in target_model.parameters():
    param.requires_grad = False
```







<br>

#### Hyperparameter Tuning

í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì„¹ì…˜ì—ì„œëŠ” `ray`ë¼ëŠ” ëª¨ë“ˆì„ ì´ìš©í•˜ì—¬ íŠœë‹ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤. ray ëª¨ë“ˆì€ Distributed applicationì„ ë§Œë“¤ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¡œ, ë¶„ì‚° ì»´í“¨íŒ… í™˜ê²½ì—ì„œ ë§ì´ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ray ëª¨ë“ˆ ì•ˆì— ìˆëŠ” tuneì´ë¼ëŠ” ëª¨ë“ˆì„ ì´ìš©í•˜ì—¬ ê°„ë‹¨í•˜ê²Œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ([Tune Document](https://docs.ray.io/en/master/tune/index.html))

rayë¥¼ ì´ìš©í•œ íŠœë‹ ë°©ë²•ì„ ì½”ë“œ ë ˆë²¨ì—ì„œ ë³´ê¸° ì „ì—, íŠœë‹ì„ í•  ë•ŒëŠ” ë‹¤ìŒ 2ê°€ì§€ì— ëŒ€í•´ ìƒê°í•´ë´…ì‹œë‹¤. 

1. Tuningì˜ ëª©ì (ì¢…ì†ë³€ì¸)
   * ì´ëŠ” ìš°ë¦¬ê°€ íŠœë‹ì„ í•˜ëŠ” ëª©ì ì— í•´ë‹¹í•©ë‹ˆë‹¤. ì¦‰, **ì–´ë–¤ ê°’ì„ ìµœëŒ€í™”(ìµœì†Œí™”)í•  ê²ƒì¸ì§€**ë¥¼ ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 
   * ì—¬ê¸°ì„œëŠ” Fashion MNIST Test datasetì˜ Accuracyì˜ ìµœëŒ€í™”ë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. 
2. Tuningí•  Hyperparameter(ì¡°ì‘ë³€ì¸, í†µì œë³€ì¸)
   * ì¡°ì‘ë³€ì¸ì€ ê°’ì„ ì¡°ì •í•˜ë©° ìµœì  ê°’ì„ íƒìƒ‰í•  ë³€ìˆ˜ì— í•´ë‹¹í•˜ê³ , í†µì œë³€ì¸ì€ ê°’ì„ ê³ ì •ì‹œí‚¬ ë³€ìˆ˜ì— í•´ë‹¹í•©ë‹ˆë‹¤. 
   * ì—¬ê¸°ì„œëŠ” ì¡°ì‘ë³€ì¸ìœ¼ë¡œ **Epoch, Batch size, Learning rate**ë¥¼, í†µì œë³€ì¸ìœ¼ë¡œ **ëª¨ë¸ êµ¬ì¡° ImageNet Pretrained ResNet18, All Not-Freeze Fine Tuning**ì„ ì§€ì •í•©ë‹ˆë‹¤. 

**ray ëª¨ë“ˆ ì„¤ì¹˜í•˜ê¸°**

ì•„ë˜ ì»¤ë§¨ë“œë¥¼ í†µí•´ ray ëª¨ë“ˆì„ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
print("Install ray")
!pip uninstall -y -q pyarrow
!pip install -q -U ray[tune]
!pip install -q ray[debug]
```

**í†µì œë³€ì¸**

```python
# í†µì œ ë³€ì¸
## 1. imagenet_resnet18 ëª¨ë¸
def get_imagenet_pretrained_model():
  imagenet_resnet18 = torchvision.models.resnet18(pretrained=True)
  target_model = imagenet_resnet18
  FASHION_INPUT_NUM = 1
  FASHION_CLASS_NUM = 10
    
  imagenet_resnet18.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  in_features = imagenet_resnet18.fc.in_features
  imagenet_resnet18.fc = torch.nn.Linear(in_features, FASHION_CLASS_NUM, bias=True)
  torch.nn.init.xavier_uniform_(imagenet_resnet18.fc.weight)
  stdv = (1/imagenet_resnet18.fc.in_features)**(1/2)
  torch.nn.init.uniform_(imagenet_resnet18.fc.bias, -stdv, stdv)

  return target_model
```

**ì¡°ì‘ë³€ì¸**

```python
# ì¡°ì‘ ë³€ì¸
## 1. Learning Rate
def get_adam_by_learningrate(model, learning_rate:float):
  return torch.optim.Adam(model.parameters(), lr=learning_rate)
## 2. Epoch ê°œìˆ˜
def get_epoch_by_epoch(epoch:int):
  return epoch
## 3. BatchSize í¬ê¸°ì— ë”°ë¥¸ ë°ì´í„° ë¡œë” ìƒì„±
common_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])
fashion_train_transformed = torchvision.datasets.FashionMNIST(root='./fashion', train=True, download=True, transform=common_transform)
fashion_test_transformed = torchvision.datasets.FashionMNIST(root='./fashion', train=False, download=True, transform=common_transform)

def get_dataloaders_by_batchsize(batch_size:int):
  # Mnist Datasetì„ DataLoaderì— ë¶™ì´ê¸°
  BATCH_SIZE = batch_size
  fashion_train_dataloader = torch.utils.data.DataLoader(fashion_train_transformed, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
  fashion_test_dataloader = torch.utils.data.DataLoader(fashion_test_transformed, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

  dataloaders = {
      "train" : fashion_train_dataloader,
      "test" : fashion_test_dataloader
  }

  return dataloaders
```

**íƒìƒ‰ êµ¬ê°„ê³¼ íƒìƒ‰ê¸° ì •í•˜ê¸°**

rayì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íƒìƒ‰ê¸°ì—ëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ë” ë‹¤ì–‘í•œ íƒìƒ‰ê¸°ë“¤ì— ëŒ€í•œ ë‚´ìš©ì€ [ì—¬ê¸°](Optimizerë“¤ì€ https://docs.ray.io/en/master/tune/api_docs/suggestion.html#bayesopt)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
from ray import tune
# íƒìƒ‰í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° config ì„¤ì •
config_space = {
    "NUM_EPOCH" : tune.choice([4,5,6,7,8,9]),
    "LearningRate" : tune.uniform(0.0001, 0.001),
    "BatchSize" : tune.choice([32,64,128]),
}

from ray.tune.suggest.hyperopt import HyperOptSearch
# íƒìƒ‰ê¸° Optimizer ì„¤ì •
optim = HyperOptSearch(
    metric='accuracy', # hyper parameter tuning ì‹œ ìµœì í™”í•  metricì„ ê²°ì •í•©ë‹ˆë‹¤.
    mode="max", # target objectiveë¥¼ maximize í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ ì„¤ì •í•©ë‹ˆë‹¤
)
```

**Training í•¨ìˆ˜ ì‘ì„±**

```python
def training(
    config # ì¡°ì‘ ë³€ì¸ learning rate, epoch, batchsize ì •ë³´
):
  # í†µì œ ë³€ì¸
  target_model = get_imagenet_pretrained_model() 

  device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") # í•™ìŠµ ë•Œ GPU ì‚¬ìš©ì—¬ë¶€ ê²°ì •. Colabì—ì„œëŠ” "ëŸ°íƒ€ì„"->"ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½"ì—ì„œ "GPU"ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŒ
  target_model.to(device)

  # ì¡°ì‘ ë³€ì¸
  NUM_EPOCH = get_epoch_by_epoch(config["NUM_EPOCH"])
  dataloaders = get_dataloaders_by_batchsize(config["BatchSize"])
  optimizer = get_adam_by_learningrate(target_model, config["LearningRate"])

  ### í•™ìŠµ ì½”ë“œ ì‹œì‘
  ...
    
  # epoch ì¢…ë£Œ
  tune.report(accuracy=best_test_accuracy.item(), loss=best_test_loss)
```

**Tuning ìˆ˜í–‰**

```python
from ray.tune import CLIReporter
import ray

NUM_TRIAL = 10 # Hyper Parameterë¥¼ íƒìƒ‰í•  ë•Œì—, ì‹¤í—˜ì„ ìµœëŒ€ ìˆ˜í–‰í•  íšŸìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.

reporter = CLIReporter( # jupyter notebookì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì¤‘ê°„ ìˆ˜í–‰ ê²°ê³¼ë¥¼ command lineì— ì¶œë ¥í•˜ë„ë¡ í•¨
    parameter_columns=["NUM_EPOCH", "LearningRate", "BatchSize"],
    metric_columns=["accuracy", "loss"])

ray.shutdown() # ray ì´ˆê¸°í™” í›„ ì‹¤í–‰

analysis = tune.run(
    training,
    config=config_space,
    search_alg=optim,
    #verbose=1,
    progress_reporter=reporter,
    num_samples=NUM_TRIAL,
    resources_per_trial={'gpu': 1} # Colab ëŸ°íƒ€ì„ì´ GPUë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ comment ì²˜ë¦¬ë¡œ ì§€ì›Œì£¼ì„¸ìš”
)
```

**ê²°ê³¼ í™•ì¸**

```python
best_trial = analysis.get_best_trial('accuracy', 'max')
print(f"ìµœê³  ì„±ëŠ¥ config : {best_trial.config}")
# ìµœê³  ì„±ëŠ¥ config : {'NUM_EPOCH': 9, 'LearningRate': 0.0009309039165529126, 'BatchSize': 32}
print(f"ìµœê³  test accuracy : {best_trial.last_result['accuracy']}")
# ìµœê³  test accuracy : 0.9143999814987183
```

<br>

ì´ë¡œì¨ pretrained modelì„ ê°€ì ¸ì™€ transfer learningì„ ìˆ˜í–‰í•˜ê³  hyperparameter tuningê¹Œì§€ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì„ ì½”ë“œ ë ˆë²¨ì—ì„œ ê³µë¶€í–ˆìŠµë‹ˆë‹¤. 

























<br>

<br>

## ì°¸ê³  ìë£Œ

* **Multi-GPU**
  * [PyTorch Lightning Multi GPU í•™ìŠµ](https://pytorch-lightning.readthedocs.io/en/stable/advanced/multi_gpu.html)
  * [DDP Tutorial](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
* **Hyperparameter Tuning**
  * [Hyperparameter Tuning with Ray Tune](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)
* **PyTorch Troubleshooting**
  * [Pytorchì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” ì—ëŸ¬ ì§ˆë¬¸ë“¤](https://pytorch.org/docs/stable/notes/faq.html)
  * [OOMì‹œì— GPU ë©”ëª¨ë¦¬ flushí•˜ê¸°](https://discuss.pytorch.org/t/how-to-clean-gpu-memory-after-a-runtimeerror/28781)
  * [GPU ì—ëŸ¬ ì •ë¦¬](https://brstar96.github.io/shoveling/device_error_summary/)





<br>

<br>

## íšŒê³ 

ì˜¤ëŠ˜ë¡œì¨ í•œ ì£¼ ë™ì•ˆì˜ PyTorchì— ëŒ€í•œ í•™ìŠµì´ ëì´ ë‚¬ìŠµë‹ˆë‹¤. 

íŒŒì´í† ì¹˜ ê°œìš”ë¶€í„° ê¸°ë³¸ì  ì—°ì‚°ë“¤, nn.Module, Datasetê³¼ DataLoader, Transfer learningê³¼ Hyperparameter tuning, Multi-GPU, Trouble shooting ë“± ë‹¤ì–‘í•œ ë‚´ìš©ë“¤ì„ ë‹¤ë£¨ëŠ” ê²ƒì´ ì‰½ì§€ëŠ” ì•Šì•˜ì§€ë§Œ, ì ì ˆí•œ ì‹¤ìŠµê³¼ ê°œë… ë¬¸ì œë“¤ì´ ë³‘í–‰ëœ ê²ƒ ê°™ì•„ ë§ì€ ê²ƒì„ ë°°ìš¸ ìˆ˜ ìˆì—ˆë˜ í•œ ì£¼ì˜€ìŠµë‹ˆë‹¤. 

ì´ì „ê¹Œì§€ëŠ” íŒŒì´í† ì¹˜ë¥¼ ê±°ì˜ ì‚¬ìš©í•´ ë³¸ ê²½í—˜ì´ ì—†ê¸° ë•Œë¬¸ì— í•œ ì£¼ ë™ì•ˆì˜ í•™ìŠµë§Œìœ¼ë¡œëŠ” ë§ì€ ë¶€ë¶„ì„ ì»¤ë²„í•˜ê¸°ëŠ” ì–´ë µê² ì§€ë§Œ, ì•ìœ¼ë¡œ ì§ì ‘ ëª¨ë¸ì„ ë§Œë“¤ê³  í•™ìŠµ ì‹œí‚¤ê³ , ì„±ëŠ¥ì„ ê°œì„ í•˜ë ¤ëŠ” ì¼ë ¨ì˜ ê³¼ì •ê³¼ ë…¸ë ¥ì„ í†µí•´ ì•ìœ¼ë¡œ ë”ìš± ë” ìµìˆ™í•´ì§€ë¦¬ë¼ ìƒê°í•©ë‹ˆë‹¤. 

ë¬´ì—‡ë³´ë‹¤ ê° ë‚´ìš©ë“¤ì„ ì‚°ë°œì ìœ¼ë¡œ ë°°ìš°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ëª¨ë¸ì„ ë§Œë“¤ê³  í•™ìŠµì‹œí‚¤ëŠ” ì¼ë ¨ì˜ ê³¼ì •ì— ë”°ë¼ ìˆœì„œëŒ€ë¡œ í•œ ë¶€ë¶„ ì”© ë°°ìš°ëŠ” ê²ƒì´ ì „ì²´ íë¦„ì„ ì´í•´í•˜ëŠ” ë°ì—ë„ ë§ì€ ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤!!ğŸ˜ğŸ˜

í•œ ì£¼ ê°„ì˜ íŒŒì´í† ì¹˜ ëª¨ë¸ë§ ê³¼ì •ì„ ë°°ìš°ë©´ì„œ ê·¸ ê°„ì˜ íë¦„ì„ ê°„ë‹¨íˆ ì•„ë˜ì™€ ê°™ì´ ì •ë¦¬í•´ë³´ì•˜ìŠµë‹ˆë‹¤. 

* **ë°ì´í„° ì „ì²˜ë¦¬(Dataset, Transform, Compose)**
* **ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°(DataLoader, Sampler)**
* **ì‹ ê²½ë§ êµ¬ì„±(nn.Module, pretrained model)**
* **ì˜¤ì°¨í•¨ìˆ˜ ë° ìµœì í™” ê¸°ë²• ì„ íƒ(Loss, Optimizer, metrics)**
* **í•™ìŠµ ë° ì¶”ë¡  ì˜µì…˜ ì„¤ì •(transfer learning, hyperparameter tuning, multi-gpu, monitoring)**
* **í›ˆë ¨, ê²€ì¦(training, validating, troubleshooting)**

ë‹¤ìŒ ì£¼ë¶€í„° ì§„í–‰ë  ë‚´ìš©ë“¤ë„ ê¸°ëŒ€ê°€ ë§ì´ ë©ë‹ˆë‹¤ ğŸ˜Š

ì•ìœ¼ë¡œ ê³„ì† ì§€ì¹˜ì§€ ì•Šê³  ì˜ ë‚˜ì•„ê°”ìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤ ã…ã…

<br>

### ë§ˆìŠ¤í„° í´ë˜ìŠ¤

#### FAQ

* AIì— ëŒ€í•œ ì§€ì‹, ëª¨ë¸ ê°œë°œ ëŠ¥ë ¥ë„ ì¤‘ìš”í•˜ì§€ë§Œ **'í”„ë¡œê·¸ë˜ë° ì—­ëŸ‰'**ì´ ê³„ì†í•´ì„œ ì¤‘ìš”í•´ì§ˆ ê²ƒì´ë‹¤. 
* ì›¹ í”„ë¡œê·¸ë˜ë° 
  * ì„œë²„-í´ë¼ì´ì–¸íŠ¸ ê´€ê³„, ë°ì´í„°ë² ì´ìŠ¤, ìš”ì²­-ì‘ë‹µ ë“±ì— ëŒ€í•´ ë°°ìš¸ ìˆ˜ ìˆë‹¤. 
  * **ì‹œìŠ¤í…œì„ í•˜ë‚˜ ë§Œë“¤ì–´ë´ë¼!**
* AIì˜ ê¸¸?
  * ì—”ì§€ë‹ˆì–´ë€ ë¬¸ì œë¥¼ í‘¸ëŠ” ë° ëŠ¥ë ¥ì„ ì“°ëŠ” ì‚¬ëŒ
  * **í–‰ë³µí•˜ê²Œ ì‚´ ìˆ˜ ìˆëŠ” ê¸¸ì„ ì°¾ì•„ë¼!**
* íš¨ìœ¨ì ìœ¼ë¡œ ê³µë¶€í•  ìˆ˜ ìˆëŠ” ë°©ë²•?
  * íš¨ìœ¨ë³´ë‹¤ëŠ” ì¼ë‹¨ 'ì–‘'ì„ ëŠ˜ë ¤ë¼. ì–‘ì„ ëŠ˜ë¦¬ë‹¤ ë³´ë©´ ì–´ëŠ ìˆœê°„ ê·¸ ë‚´ìš©ë“¤ì´ ì—°ê²°ë˜ëŠ” ë“¯í•œ ëŠë‚Œì´ ì˜¨ë‹¤. 
  * ê·¸ë¦¬ê³  ê·¸ ëŠë‚Œì´ ì˜¤ë©´ ì§€ì‹ì˜ ìŠµë“ì´ ë¹¨ë¼ì§„ë‹¤. 
  * MLOps: ë¦¬ëˆ…ìŠ¤(Shell Script), ë¹…ë°ì´í„°ì— ëŒ€í•œ ê³µë¶€ê°€ ê¸°ë³¸!
* **í•˜ë‚˜ì˜ ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ì„œ ì¸ê³µì§€ëŠ¥ì„ ì‚½ì…í•˜ëŠ” ì—°ìŠµ**
  * ì¸ê³µì§€ëŠ¥ì˜ ì‹¤ì œ í”„ë¡œë•íŠ¸ì—ì„œì˜ ì‘ë™ ê³¼ì •ì— ëŒ€í•´ ì˜ ê³µë¶€í•  ìˆ˜ ìˆìŒ

#### Data Centric AI

* ì½”ë”©ì„ ëª» í•˜ë©´ ML/DL ì–´ë µë‚˜ìš”?
  * ì–´ë µë‹¤! 
* ML/DL ì„¸ê³„ì˜ ë³€í™”
  * using pre-trained model
  * ëª¨ë¸ ê°œë°œ/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¸ì›€
* Research ML
  * ë°ì´í„°ëŠ” ì¤€ë¹„ -> ëª¨ë¸ ê°œë°œ -> í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ -> ë…¼ë¬¸
* Project-Real World ML
  * ML Code ê°œë°œì€ ë§¤ìš° ì‘ì€ ë¶€ë¶„ì´ë‹¤. 
  * ëª¨ë¸ì€ AWS, Google ë“±ì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë¸ì„ ì“°ê³ , ë°ì´í„° ìˆ˜ì§‘ê³¼ ì „ì²˜ë¦¬/ì‹œìŠ¤í…œ ìµœì í™” ë“±ì— ì‹ ê²½ì„ ì“´ë‹¤. 
* Issues
  * Data
    * ì–‘ì§ˆì˜ ë°ì´í„° í™•ë³´ê°€ ê´€ê±´
    * Production time ë°ì´í„°ì™€ Experiment ë°ì´í„°ê°€ ë‹¤ë¥¸ ë¬¸ì œë„ ë°œìƒ
    * ëŠì„ì—†ì´ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ê³  í™•ë³´í•˜ë ¤ëŠ” ë…¸ë ¥ì´ í•„ìš”
      * User generated data(ê¸°ì¡´ì˜ í”Œë«í¼ ê¸°ì—…): inputs, clicks for recommendation
      * System generated data: logs, metadata, prediction
      * Data Flywheel: ì‚¬ìš©ìë“¤ì˜ ì°¸ì—¬ë¡œ ë°ì´í„°ë¥¼ ê°œì„ 
      * Data augmentation: ë°ì´í„°ë¥¼ ì„ì˜ë¡œ ì¶”ê°€ í™•ë³´
    * Data drift
      * ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ë°ì´í„°ëŠ” ê³„ì† ë°”ë€ë‹¤! (OTT í”Œë«í¼)
    * Data Feedback Loop
      * ì‚¬ìš©ìë¡œë¶€í„° ì˜¤ëŠ” ë°ì´í„°ë¥¼ ìë™í™”í•˜ì—¬ ëª¨ë¸ì— í”¼ë”©í•´ì£¼ëŠ” ì²´ê³„ê°€ í•„ìš”
      * ML/DL ì½”ë“œ ì´ìƒì˜ ë„¤íŠ¸ì›Œí¬ í•˜ë“œì›¨ì–´ë¶€í„° ë°ì´í„° í”Œë«í¼ê¹Œì§€ì˜ ì´í•´
      * ì•ìœ¼ë¡œì˜ ë§ì€ ML/DL ì—”ì§€ë‹ˆì–´ê°€ ê°€ì ¸ì•¼ í•  ì—­ëŸ‰ ì¤‘ í•˜ë‚˜
      * íŠ¹íˆ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë‹¤ë¤„ë³¸ ê²½í—˜ì´ ì¤‘ìš”í•  ê²ƒ(Multi GPU, ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ì•ë’·ë‹¨ ë¶€ë¶„)
  * ì•ìœ¼ë¡œ ì•Œì•„ì•¼ í•  ê²ƒì„
    * **ML Ops**
    * **ë‹¹ì—°íˆ ë°ì´í„°ë² ì´ìŠ¤**
    * **Cloud - AWS, GCP, Azure**
    * **Spark (+ Hadoop)**
    * **Linux, Docker**
    * **ìŠ¤ì¼€ì¤„ë§ ë„êµ¬ë“¤(ì¿ ë¸Œí”Œë¡œìš°, MLFlow, AirFlow)**
  * RAY, DASK, RAPIDS
  * Model, Algorithms, Metrics, Hyperparameter tuning



















<br>
