---
layout: single
title: "[AITech][Object Detection][P stage] 20220408 - More Tips"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['Solution']
---



<br>

# More Tips

## CV fold

본 대회에서 저희 팀은 `StratifiedGroupKFold`를 사용했습니다. Group은 Image로 설정했고, train-val set에서 category 비율 분포가 비슷하게 나눴습니다. 

![image-20220409131112647](https://user-images.githubusercontent.com/70505378/162576610-60f46219-1795-46b3-aea0-3ae0ddf70d3c.png)

대회 막바지에는 detection task에서 중요한 category를 포함하여 bbox size, bbox ratio 등까지 group으로 지정하여 비율 분포를 비슷하게 나눠주는 `multi-label stratified group k fold`도 시도했습니다. 

이외에도 주어진 데이터셋에 적절한 CV set을 찾는 것이 중요합니다. 코드 자체는 많이 공개되어 있어서 코드를 보기 보다는 각각의 K Fold 방식을 이해하고 적절히 선택하는 것이 중요합니다. 

Validation에 관련한 내용은 아래 포스팅을 참고해주세요. 

* [Object Detection Competition - Validation set 찾기](https://wowo0709.github.io/ai/aitech/AITech-20220401-Object-Detection-Competition/#validation-set-%EC%B0%BE%EA%B8%B0)

코드는 아래에서 확인할 수 있습니다. 

* [Stratified Group K Fold](https://github.com/boostcampaitech3/level2-object-detection-level2-cv-10/blob/experiment/cross_validation.ipynb)





<br>

<br>

## Ensemble

Detection task에서 앙상블은 너무나 강력한 기법입니다. 

각 모델의 추론 결과를 취합해서 최종 결과를 선택하는 image classification task에서의 앙상블과 달리, detection에서는 모델이 많을수록 bbox 예측이 많아지고, 각 모델의 confidence score가 높은 bbox들을 취합한다면 다양하고 좋은 예측들을 모두 사용할 수 있기 때문입니다. 

여러 앙상블 기법이 있지만 그 중에서도 이번 대회에서 주로 사용한 WBF(Weighted Box Fusion)은 기존의 NMS 방법보다 더 강력한 성능을 보여줍니다. 각각의 bbox를 개별적으로 봤던 NMS와 달리, WBF에서는 각 bbox에 weight를 부여하여 좌표를 평균내서 새로운 bbox 예측을 만들어냅니다. Hard voting/Soft voting과 유사하다고 할 수 있을 것 같습니다. 

Detection task에서의 ensemble에 대한 내용은 아래 포스팅을 참고해주세요. 

* [Object Detection Competition - Ensemble&TTA](https://wowo0709.github.io/ai/aitech/AITech-20220401-Object-Detection-Competition/#ensemble--tta)

코드는 아래에서 확인할 수 있습니다. 

* [Ensemble - NMS/Soft NMS/WBF](https://github.com/boostcampaitech3/level2-object-detection-level2-cv-10/blob/experiment/utils/_ensemble_.ipynb)





















<br>

<br>

## Competition Solutions

마지막으로 이번 대회에서 가장 좋은 성적을 낸 상위 두 팀의 solution을 공개합니다. 

**발표 1팀**

* Introduction
  * 협업에 진심
  * Github
    * main, develop, feature branch
    * Commit/Issue/Pull request template
    * Slack과 연동 - Github 이벤트 시 slack에 알림
    * 한 명이 메인으로 merge, 이슈 있을 시 리뷰 요청
  * Weight&Biases
    * 실험 결과 공유
  * Notion
    * Canban board
* EDA
  * 클래스 별 bbox 분포
  * bbox area: small, medium, large
  * Augmentation using Albumentations(21 out of 47)
    * Augmentation의 영향 정리
* Model Search
  * Kaggle, Dacon, DrivenData 등 AI competition 상위권에 든 모델 조사
  * 다양한 모델로 앙상블
    * One stage vs Two-stage
    * Anchor-based vs Anchor-free
    * CNN vs Transformer
* Experiments
  * resolution: 1024 -> 너무 오래 걸림
    * 512 -> Offline rescaling(load 과정에서 하는 것이 아닌 미리 rescaling된 데이터를 바로 이용)
  * Casecade RCNN+Swin-L, YOLO, DetectoRS
  * Mosaic&Mix-up (mmdetection 존재, p=0.5로 코드 수정)
  * Pseudo labeling
    * 낮은 threshold로 박스를 잡아내고 높은 image의 평균 confidence threshold
    * 박스는 많이 생성, 불안정한 이미지는 제거
  * TTA, Multi-scale training, Scheduler
* Ensemble
  * IOU threshold <-> Skip box threshold - trade-off
  * Grid search를 통해 최적의 hp 값 탐색
  * Multi stage ensemble
  * model/fold ensemble

**발표 2팀**

* mmdetection performance leaderboard 참고
* Backbone: Swin-B, Swin-L
* Data handling
  * 배터리 업샘플링
  * 각 augmentation의 의미 파악 -> Cutmix 제거, CLAHE 적용
  * Mosaic -> Faster RCNN 성능 하락, YOLO 성능 향상
* Multi-scale Train&Test
* 성능 향상이 없었던 실험들
  * cutmix
  * neck
  * CIOU loss
* Ensemble
  * WBF
    * weights, iou_threshold, conf_type
  * 더 좋은 모델을 사용했는데 앙상블 성능은 하락..?
* 위기
  * validation 방법 통일 실패
  * 다른 backbone 모델 학습
  * 데이터 용량 초과 학습 중단(새벽에 GPU 중지)
  * kfold dataset 통일 실패
  * 실험 결과에 대한 분석 오류
  * Pseudo labeling 실패
  * **명확한 그라운드 룰 설정**
* 협업
  * Notion - 실험 결과 DB, 앙상블 결과 DB
  * Slack, KakaoTalk - 자세한 이야기
  * Weight&Biases - 실험 결과 공유
  * Github - Convention, Project
  * Google Drive - 대용량 파일

**공통점**

* 협업 툴 적극 활용(Github, Slack/Kakaotalk 연동, W&B/MLflow, Notion)
* Augmentation 자세한 파악 및 적용
* 다양한 모델 앙상블&HPO
* Kfold, Pseudo labeling
* 실험 체계화
* 다양한 기법 조사(대회, 논문 등)











<br>

<br>

# 참고 자료

* 
