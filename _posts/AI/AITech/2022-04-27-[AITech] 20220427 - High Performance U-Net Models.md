---
layout: single
title: "[AITech][Semantic Segmentation] 20220427 - High Performance U-Net Models"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['U-Net', 'U-Net++', 'U-Net 3+']
---



<br>

_**ë³¸ í¬ìŠ¤íŒ…ì€ KAISTì˜ 'ê¹€í˜„ìš°' ë§ˆìŠ¤í„° ë‹˜ì˜ ê°•ì˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.**_

# High Performance U-Net Models

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” U-Netì„ í¬í•¨í•´ U-Netì˜ êµ¬ì¡°ë¥¼ ì°¨ìš©í•´ ë°œì „ëœ ëª¨ë¸ë“¤ì— ëŒ€í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

U-Netì€ ê·¸ ë…¼ë¬¸ì˜ ì¸ìš©ìˆ˜ê°€ í˜„ì‹œì ì—ì„œ 40,000íšŒ ì´ìƒì„ ê¸°ë¡(YOLOê°€ ì•½ 24,000íšŒ)í•  ì •ë„ë¡œ segmentationì—ì„œ í° ì¡±ì ì„ ë‚¨ê¸´ ëª¨ë¸ì…ë‹ˆë‹¤. 

![image-20220427151845643](https://user-images.githubusercontent.com/70505378/165674432-85ad2e7a-9c18-4ae8-9d39-88de5bed3846.png)

## U-Net

`U-Net`ì€ ì˜ë£Œë¶„ì•¼ segmentation taskì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë‚˜ì˜¨ ëª¨ë¸ì´ì§€ë§Œ, ê·¸ êµ¬ì¡°ì™€ ì„±ëŠ¥ì˜ ê°•ë ¥í•¨ìœ¼ë¡œ ì—¬ëŸ¬ ë¶„ì•¼ì˜ segmentation ëª¨ë¸ë“¤ì—ì„œ ì°¨ìš©ëœ ëª¨ë¸ì…ë‹ˆë‹¤. 

ì˜ë£Œ ë¶„ì•¼ëŠ” íŠ¹íˆë‚˜ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì˜ ìˆ˜ê°€ ì ê³ , ë¼ë²¨ë§ë„ ì¼ë°˜ì¸ì´ í•˜ê¸°ì—ëŠ” ì–´ë µë‹¤ëŠ” ì  ë•Œë¬¸ì— ë§ì€ í•™ìŠµ ë°ì´í„°ë¥¼ í™•ë³´í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. íŠ¹íˆ, cell segmentation ì‘ì—…ì˜ ê²½ìš° ê°™ì€ í´ë˜ìŠ¤ê°€ ì¸ì ‘í•´ ìˆëŠ” ì…€ ì‚¬ì´ì˜ ê²½ê³„ë¥¼ êµ¬ë¶„í•  í•„ìš”ê°€ ìˆëŠ”ë° ì´ ë¬¸ì œëŠ” ì¼ë°˜ì ì¸ semantic segmentationìœ¼ë¡œëŠ” ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. 

ë”°ë¼ì„œ U-Netì—ì„œëŠ” ëŒ€ì¹­ í˜•íƒœë¥¼ ì´ë£¨ëŠ” Contracting Path(Encoder)ì™€ Expanding Path(Decoder)ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ì´ëŸ¬í•œ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë“±ì¥í•˜ì˜€ìŠµë‹ˆë‹¤. 

![image-20220427152414840](https://user-images.githubusercontent.com/70505378/165674436-c2054a87-05c4-4502-b983-9991160ee64b.png)

êµ¬ì¡°ì  íŠ¹ì§•ì— ëŒ€í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

* íŒŒë€ìƒ‰ í™”ì‚´í‘œ
  * 3x3 Conv - (BN) - ReLU
  * zero paddingì„ ì ìš©í•˜ì§€ ì•Šì•„ feature mapì˜ í¬ê¸°ê°€ ê°ì†Œ
  * ê° levelì˜ ì²«ë²ˆì§¸ íŒŒë€ìƒ‰ í™”ì‚´í‘œ: Contracting pathì—ì„œëŠ” ì±„ë„ì˜ ìˆ˜ê°€ 2ë°°ë¡œ ì¦ê°€ (ì…ë ¥ë¶€ ì œì™¸), Expanding pathì—ì„œëŠ” ì±„ë„ì˜ ìˆ˜ê°€ 2ë°°ë¡œ ê°ì†Œ
* íšŒìƒ‰ í™”ì‚´í‘œ
  * ê°™ì€ ê³„ì¸µ(level)ì˜ Encoder ì¶œë ¥ë¬¼ê³¼ Decoderì˜ up-conv ê²°ê³¼ë¥¼ concatenate
  * Resolutionì´ ì„œë¡œ ë™ì¼í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— encoderì˜ ì¶œë ¥ë¬¼ì„ center cropí•˜ì—¬ resolutionì„ ë§ì¶°ì¤Œ
  *  ì´ëŸ¬í•œ ë¬¸ì œ ë•Œë¬¸ì— êµ¬í˜„ì²´ì— ë”°ë¼ padding=1ë¡œ ì§€ì •í•˜ì—¬ resolutionì„ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ëŠ” ê²½ìš°ë„ ìˆìŒ
* ë¹¨ê°„ìƒ‰ í™”ì‚´í‘œ
  * maxpoolingìœ¼ë¡œ feature mapì˜ resolutionì„ 2ë°°ë¡œ ê°ì†Œ
* ì´ˆë¡ìƒ‰ í™”ì‚´í‘œ
  * up-conv(transposed conv)ë¡œ feature mapì˜ resolutionì„ 2ë°°ë¡œ ì¦ê°€
* ì²­ë¡ìƒ‰ í™”ì‚´í‘œ
  * 1x1 convë¥¼ ì ìš©í•˜ì—¬ ìµœì¢… score map ì¶œë ¥

<br>

U-Netì˜ contributionì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 

1. Encoderê°€ í™•ì¥ë¨ì— ë”°ë¼ ì±„ë„ì˜ ìˆ˜ë¥¼ 1024ê¹Œì§€ ì¦ê°€ì‹œì¼œ ì¢€ ë” ê³ ì°¨ì›ì—ì„œ ì •ë³´ë¥¼ ë§¤í•‘

2. ê°ê¸° ë‹¤ë¥¸ ê³„ì¸µì˜ encoderì˜ ì¶œë ¥ì„ decoderì™€ ê²°í•©ì‹œì¼œì„œ ì´ì „ ë ˆì´ì–´ì˜ ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©

3. Random Elastic deformationì„ í†µí•´ augmentation ìˆ˜í–‰

   * Modelì´ invarianceì™€ robustnessë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²•
   * ì˜ë£Œ ë¶„ì•¼ë¼ëŠ” íŠ¹ìˆ˜ì„± ë•Œë¬¸ì— ì‚¬ìš©

   ![image-20220427154159475](https://user-images.githubusercontent.com/70505378/165674437-ff0462b9-c768-4fa2-9b20-3a9a94bff195.png)

4. Pixel-wise loss weightë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ weight map ìƒì„±

   * ê°™ì€ í´ë˜ìŠ¤ë¥¼ ê°€ì§€ëŠ” ì¸ì ‘í•œ ì…€ì„ ë¶„ë¦¬í•˜ê¸° ìœ„í•´ í•´ë‹¹ ê²½ê³„ ë¶€ë¶„ì— ê°€ì¤‘ì¹˜ë¥¼ ì œê³µ

   ![image-20220427154215370](https://user-images.githubusercontent.com/70505378/165674440-f1c8179c-b611-4d8d-a918-b271a6e545ea.png)

<br>

ë‹¤ìŒìœ¼ë¡œ U-Netì˜ í•œê³„ì ì— ëŒ€í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

1. U-Netì€ ê¸°ë³¸ì ìœ¼ë¡œ ê¹Šì´ê°€ 4ë¡œ ê³ ì •
   * ë°ì´í„°ì…‹ë§ˆë‹¤ ìµœê³ ì˜ ì„±ëŠ¥ì„ ë³´ì¥í•˜ì§€ ëª» í•¨
   * ìµœì  ê¹Šì´ íƒìƒ‰ ë¹„ìš© ì¦ê°€
2. ë‹¨ìˆœí•œ Skip Connection
   * ë™ì¼í•œ ê¹Šì´ë¥¼ ê°€ì§€ëŠ” encoderì™€ decoderë§Œ ì—°ê²°ë˜ëŠ” ì œí•œì ì¸ êµ¬ì¡°











<br>

<br>

## U-Net++

`U-Net++`ì€ U-Netì˜ ë‘ê°€ì§€ í•œê³„ì ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ í˜•íƒœì˜ ì•„í‚¤í…ì³ë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤. 

![image-20220427155320850](https://user-images.githubusercontent.com/70505378/165674441-5428d5e5-3f3d-443f-8fbd-bf2c8f7a6e7b.png)

* Encoderë¥¼ ê³µìœ í•˜ëŠ” ë‹¤ì–‘í•œ ê¹Šì´ì˜ U-Netì„ ìƒì„±
  * Encoder<sub>depth=1</sub> ~ Encoder<sub>depth=4</sub>
* Skip connectionì„ ë™ì¼í•œ ê¹Šì´ì—ì„œì˜ Feature mapë“¤ì´ ëª¨ë‘ ê²°í•©ë˜ë„ë¡ ìœ ì—°í•œ feature map ìƒì„±

U-Net++ì˜ íŠ¹ì§•ì ì¸ ì•„ì´ë””ì–´ë¡œëŠ” 3ê°€ì§€ë¥¼ ë§í•  ìˆ˜ ìˆëŠ”ë°ìš”, ê°ê°ì— ëŒ€í•´ ì‚´í´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

### Dense Skip Connection

 ![image-20220428104216423](https://user-images.githubusercontent.com/70505378/165674443-4155082c-4237-4397-9536-daf23e7ab38c.png)

ê° levelì˜ feature mapë“¤ì€ dense connectionì„ í†µí•´ ê°™ì€ levelì— ì „ë‹¬ë©ë‹ˆë‹¤. Skip connection ì‹œì—ëŠ” ë‹¨ìˆœíˆ feature mapë“¤ì„ concatí•©ë‹ˆë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´ X<sup>0, 4</sup>ëŠ” ì•„ë˜ì™€ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (HëŠ” convolutionì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤)

![image-20220428104553155](https://user-images.githubusercontent.com/70505378/165674445-9a04fc5b-3731-4d34-ad78-efd75b522d99.png)

### Ensemble

ê·¸ë¦¬ê³  ì—¬ëŸ¬ depthì˜ feature mapë“¤ì„ ì§ì ‘ ì¶”ë¡  ê²°ê³¼ë¡œ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì„ ì•™ìƒë¸”í•˜ëŠ” íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

![image-20220428104748346](https://user-images.githubusercontent.com/70505378/165674447-82e106f1-56be-4ea6-b291-ba6970ecc8e4.png)





### Deep Supervision

ë˜í•œ ê° depthì˜ feature mapë“¤ì€ ì¶”ë¡ ì— ì‚¬ìš©í•˜ëŠ” ê²ƒ ë¿ ì•„ë‹ˆë¼ loss ê³„ì‚° ì‹œì—ë„ ì‚¬ìš©ë˜ì–´ Deep supervision í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. 

ê° depthì— ëŒ€í•œ ì†ì‹¤í•¨ìˆ˜ ê°’ì„ ê³„ì‚°í•œ í›„ ì´ë¥¼ í‰ê· ì„ ì·¨í•´ ìµœì¢… ì†ì‹¤ ê°’ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. 

![image-20220428105101667](https://user-images.githubusercontent.com/70505378/165674450-1d7d94c2-ca81-4c47-b481-a404458949c6.png)

ìœ„ Loss ìˆ˜ì‹ì˜ L(Y, P)ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. Pixel-wise cross entropy(ë¹¨ê°„ìƒ‰)ì™€ Soft dice coefficient(ì´ˆë¡ìƒ‰)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. 

![image-20220428105352039](https://user-images.githubusercontent.com/70505378/165674452-58d666d2-0687-4773-96ff-40aa21e00e10.png)

* ğ‘ : Batch size ë‚´ì˜ í”½ì…€ ê°œìˆ˜
* ğ¶ : class ê°œìˆ˜
* ğ‘¦<sub>n, c</sub> :targetlabel
* ğ‘<sub>n, c</sub> : predict label  



<br>

ì´ëŸ¬í•œ U-Net++ì˜ í•œê³„ì ìœ¼ë¡œëŠ” ì•„ë˜ì™€ ê°™ì€ ì ë“¤ì´ ìˆìŠµë‹ˆë‹¤. 

* ë³µì¡í•œ connectionìœ¼ë¡œ ì¸í•œ parameter ì¦ê°€
* ë§ì€ connectionìœ¼ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ì¦ê°€
* Encoder-Decoder ì‚¬ì´ì—ì„œì˜ connectionì´ ë™ì¼í•œ í¬ê¸°ë¥¼ ê°–ëŠ” feature mapì—ì„œë§Œ ì§„í–‰ë¨
  * ì¦‰, full scaleì—ì„œ ì¶©ë¶„í•œ ì •ë³´ë¥¼ íƒìƒ‰í•˜ì§€ ëª»í•´ ìœ„ì¹˜ì™€ ê²½ê³„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í•™ìŠµí•˜ì§€ ëª» í•¨







<br>

<br>

## U-Net 3+

![image-20220428111015879](https://user-images.githubusercontent.com/70505378/165674453-3f1412f0-23f9-4196-89ae-b5d5a744986c.png)

ë§ˆì°¬ê°€ì§€ë¡œ `U-Net 3+`ì˜ ì•„ì´ë””ì–´ë„ í¬ê²Œ 3ê°€ì§€ë¡œ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

### Full-scale Skip Connection

U-Netê³¼ U-Net++ì—ì„œ ì¡´ì¬í–ˆë˜ skip connectionì—ì„œì˜ feature map scaleì˜ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ U-Net 3+ì—ì„œëŠ” ì´ë¥¼ **(conventional + inter + intra) skip connection**ìœ¼ë¡œ ë‹¤ì–‘í•˜ê²Œ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤. 

* Conventional skip connection
  * Encoder layerë¡œë¶€í„° same-scaleì˜ feature mapì„ ì „ë‹¬ë°›ìŒ
* Inter skip connection
  * Encoder layerë¡œë¶€í„° smaller-scaleì˜ low-level feature map ì„ ì „ë‹¬ë°›ìŒ
    * ì—¬ê¸°ì„œ smaller scaleì´ë€ resolutionì´ ì‘ë‹¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í•˜ë‚˜ì˜ pixelì´ ë‹´ê³  ìˆëŠ” ê³µê°„ ì •ë³´ê°€ ì ë‹¤ëŠ” ê²ƒ
  * í’ë¶€í•œ ê³µê°„ ì •ë³´ë¥¼ í†µí•´ ê²½ê³„ ê°•ì¡°
* Intra skip connection
  * Decoder layerë¡œë¶€í„° larger-scaleì˜ high-level feature map ì„ ì „ë‹¬ë°›ìŒ
    * ë§ˆì°¬ê°€ì§€ë¡œ larger-scaleì´ë€ í•˜ë‚˜ì˜ pixelì´ ë‹´ê³  ìˆëŠ” ê³µê°„ ì •ë³´ê°€ ë§ë‹¤ëŠ” ê²ƒ
  * ì–´ë””ì— ìœ„ì¹˜í•˜ëŠ” ì§€ ìœ„ì¹˜ ì •ë³´ êµ¬í˜„

ì˜ˆë¥¼ ë“¤ì–´ X<sub>De</sub><sup>3</sup>ê°€ ë§Œë“¤ì–´ì§€ëŠ” ê³¼ì •ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 

![image-20220428111505521](https://user-images.githubusercontent.com/70505378/165674456-2066aeef-4c59-447a-9cdd-a6a90465a735.png)

ë˜í•œ, U-Net 3+ì—ì„œëŠ” íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ëª¨ë“  decoder layerì˜ channel ìˆ˜ë¥¼ 320ìœ¼ë¡œ í†µì¼í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µì¼í•˜ê¸° ìœ„í•´ skip connection ì‹œ 64 channel(# of kernels), 3x3 convë¥¼ ë™ì¼í•˜ê²Œ ì ìš©í•˜ì—¬ concat(64x5=320)í•©ë‹ˆë‹¤. 

U-Net 3+ì€ Full-scale skip connectionì„ í†µí•´ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¤„ì´ë©´ì„œë„ ì„±ëŠ¥ í–¥ìƒì„ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 

![image-20220428112231052](https://user-images.githubusercontent.com/70505378/165674457-7cef7770-d60b-4916-95f8-2b6fddcb0e0f.png)

<br>

### Classification-guided Module (GCM)

Low-level layerì— ë‚¨ì•„ìˆëŠ” backgroundì˜ noiseê°€ ë°œìƒí•˜ì—¬ ë‹¤ìˆ˜ì˜ false-positive ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

U-Net 3+ì—ì„œëŠ” ì •í™•ë„ë¥¼ ë†’ì´ê³ ì, extra classification taskë¥¼ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. 

* High-level feature mapì¸ **X<sub>De</sub><sup>5</sup>**ë¥¼ í™œìš©
  * Dropout, 1x1 conv, AdaptiveMaxPool, Sigmoid í†µê³¼
    * í™•ë¥ ê°’ì— ëŒ€í•œ Binary cross entropy loss ê°’ ê³„ì‚°
  * Argmaxë¥¼ í†µí•´ Organ(ë¬¼ì²´)ì´ ì—†ìœ¼ë©´ 0, ìˆìœ¼ë©´ 1ë¡œ ì¶œë ¥
  * ìœ„ì—ì„œ ì–»ì€ ê²°ê³¼ì™€ ê° low-layerë§ˆë‹¤ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ê³±
    * 0ìœ¼ë¡œ ë¶„ë¥˜ ì‹œ ëª¨ë“  false positive ì œê±°

![image-20220428113028203](https://user-images.githubusercontent.com/70505378/165674458-933b315d-ca68-4537-9959-7b3f50c4c87f.png)







<br>

### Full-scale Deep Supervision (Loss funciton)

ìµœì¢…ì ìœ¼ë¡œ ê²½ê³„ ë¶€ë¶„ì„ ì˜ í•™ìŠµí•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ Lossë¥¼ ê²°í•©í•©ë‹ˆë‹¤. 

![image-20220428113305821](https://user-images.githubusercontent.com/70505378/165674459-60f1b7a4-20cd-44da-ad08-7da5fe09882a.png)

* Focal loss: í´ë˜ìŠ¤ì˜ ë¶ˆê· í˜• í•´ì†Œ
* ms-ssim Loss: Boundary ì¸ì‹ ê°•í™”
* IoU: í”½ì…€ì˜ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ìƒìŠ¹

ìµœì¢…ì ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì€ SOTA ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 

![image-20220428113602870](https://user-images.githubusercontent.com/70505378/165674461-d76d884d-29dd-4097-aaff-dd7e493730b7.png)

<br>

<br>

## Another version of the U-Net

ë§ˆì§€ë§‰ìœ¼ë¡œ U-Netì„ ê°œì„ í•œ ë˜ ë‹¤ë¥¸ ì„¸ ê°€ì§€ ëª¨ë¸ë“¤ì— ëŒ€í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

### Residual U-Net

`Residual U-Net`ì€ encoderì™€ decoder ë¶€ë¶„ì˜ blockë§ˆë‹¤ **residual unit with identity mapping**ì„ ì ìš©í•˜ì—¬ ë§Œë“  ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤. 

![image-20220428114053631](https://user-images.githubusercontent.com/70505378/165674464-adfbacf6-d880-4995-b38b-5a687b770faf.png)







<br>

### Mobile U-Net

`Mobile U-Net`ì€ backbone ë¶€ë¶„ì— mobile networkë¥¼ ì ìš©í•˜ì—¬ ì†ë„ë¥¼ ê°œì„ í•œ ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤. 

![image-20220428114147121](https://user-images.githubusercontent.com/70505378/165674467-9bb3bc91-be93-4af6-9db4-fb67dced2501.png)









<br>

### Eff-UNet

`Eff-UNet`ì€ Encoderë¡œ EfficientNetì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•œ ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤. 

Encoder ë¶€ë¶„ì—ì„œëŠ” MBConv(Mobile inverted Bottleneck Convolution)ë¼ëŠ” ì—°ì‚°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. 

![image-20220428114326638](https://user-images.githubusercontent.com/70505378/165674470-296a6314-a889-4219-bf58-76f7895167b8.png)

ì•„ë˜ëŠ” ì „ì²´ êµ¬ì¡°ì…ë‹ˆë‹¤. 

![image-20220428114522463](https://user-images.githubusercontent.com/70505378/165674474-f2593b64-220f-4e89-9c73-063aabf8efd6.png)



<br>

<br>

## ì‹¤ìŠµ) U-Net, U-Net++

### U-Net

![image-20220428120146710](https://user-images.githubusercontent.com/70505378/165674476-dd16edbe-915b-4ee0-a7e1-37e40a57eac1.png)

```python
import torch
import torch.nn as nn

class UNet(nn.Module):
    def __init__(self, num_classes=11):
        super(UNet, self).__init__()
        def CBR2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):
            layers = []
            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,
                                 kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)]
            layers += [nn.BatchNorm2d(num_features=out_channels)]
            layers += [nn.ReLU()]

            cbr = nn.Sequential(*layers)
            return cbr

        # Contracting path 
        self.enc1_1 = CBR2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)
        self.enc1_2 = CBR2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)     
        self.pool1 = nn.MaxPool2d(kernel_size=2)

        self.enc2_1 = CBR2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)
        self.enc2_2 = CBR2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)
        self.pool2 = nn.MaxPool2d(kernel_size=2)
 
        self.enc3_1 = CBR2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)
        self.enc3_2 = CBR2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)
        self.pool3 = nn.MaxPool2d(kernel_size=2)    

        self.enc4_1 = CBR2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=True)
        self.enc4_2 = CBR2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1, bias=True)
        self.pool4 = nn.MaxPool2d(kernel_size=2)    

        self.enc5_1 = CBR2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=True)
        self.enc5_2 = CBR2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=True)
        self.unpool4 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2, padding=0, bias=True)

        self.dec4_2 = CBR2d(in_channels=1024, out_channels=512, kernel_size=3, stride=1, padding=1, bias=True) 
        self.dec4_1 = CBR2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1, bias=True) 

        self.unpool3 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2, padding=0, bias=True)

        self.dec3_2 = CBR2d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True) 
        self.dec3_1 = CBR2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True) 

        self.unpool2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2, padding=0, bias=True)

        self.dec2_2 = CBR2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)  
        self.dec2_1 = CBR2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)  

        self.unpool1 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2, padding=0, bias=True)

        self.dec1_2 = CBR2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True) 
        self.dec1_1 = CBR2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True) 
        self.score_fr = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1, stride=1, padding=0, bias=True) # Output Segmentation map 

    def forward(self, x):
        enc1_1 = self.enc1_1(x)
        enc1_2 = self.enc1_2(enc1_1)
        pool1 = self.pool1(enc1_2)

        enc2_1 = self.enc2_1(pool1)
        enc2_2 = self.enc2_2(enc2_1)
        pool2 = self.pool2(enc2_2)

        enc3_1 = self.enc3_1(pool2)
        enc3_2 = self.enc3_2(enc3_1)
        pool3 = self.pool3(enc3_2)

        enc4_1 = self.enc4_1(pool3)
        enc4_2 = self.enc4_2(enc4_1)
        pool4 = self.pool4(enc4_2)

        enc5_1 = self.enc5_1(pool4)
        enc5_2 = self.enc5_2(enc5_1)

        unpool4 = self.unpool4(enc5_2)
        cat4 = torch.cat((unpool4, enc4_2), dim=1) 
        dec4_2 = self.dec4_2(cat4)
        dec4_1 = self.dec4_1(dec4_2)

        unpool3 = self.unpool3(dec4_1)
        cat3 = torch.cat((unpool3, enc3_2), dim=1) 
        dec3_2 = self.dec3_2(cat3)
        dec3_1 = self.dec3_1(dec3_2)

        unpool2 = self.unpool2(dec3_1)
        cat2 = torch.cat((unpool2, enc2_2), dim=1) 
        dec2_2 = self.dec2_2(cat2)
        dec2_1 = self.dec2_1(dec2_2)

        unpool1 = self.unpool1(dec2_1)
        cat1 = torch.cat((unpool1, enc1_2), dim=1) 
        dec1_2 = self.dec1_2(cat1)
        dec1_1 = self.dec1_1(dec1_2)

        output = self.score_fr(dec1_1) 
        return output
```

<br>

### U-Net++

![image-20220428120307676](https://user-images.githubusercontent.com/70505378/165674478-6b93de4d-a124-41ee-a91c-d0f98db9cb71.png)

```python
# ì¶œì²˜ : https://jinglescode.github.io/2019/12/02/biomedical-image-segmentation-u-net-nested/
import torch
import torch.nn as nn

class conv_block_nested(nn.Module):
    def __init__(self, in_ch, mid_ch, out_ch):
        super(conv_block_nested, self).__init__()
        self.activation = nn.ReLU(inplace=True)
        self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1, bias=True)
        self.bn1 = nn.BatchNorm2d(mid_ch)
        self.conv2 = nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1, bias=True)
        self.bn2 = nn.BatchNorm2d(out_ch)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.activation(x)

        x = self.conv2(x)
        x = self.bn2(x)
        output = self.activation(x)
        return output

class UNetPlusPlus(nn.Module):

    def __init__(self, in_ch=3, out_ch=1, n1=64, height=512, width=512, supervision=True):
        super(UNetPlusPlus, self).__init__()

        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Up = nn.ModuleList([nn.Upsample(size=(height//(2**c), width//(2**c)), mode='bilinear', align_corners=True) for c in range(4)])
        self.supervision = supervision

        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0])
        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])
        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])
        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])
        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])

        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])
        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])
        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])
        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])

        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])
        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])
        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])

        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])
        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])

        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])

        self.seg_outputs = nn.ModuleList([nn.Conv2d(filters[0], out_ch, kernel_size=1, padding=0) for _ in range(4)])

    def forward(self, x):
        seg_outputs = []
        x0_0 = self.conv0_0(x)
        x1_0 = self.conv1_0(self.pool(x0_0))
        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up[0](x1_0)], 1))
        seg_outputs.append(self.seg_outputs[0](x0_1))

        x2_0 = self.conv2_0(self.pool(x1_0))
        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up[1](x2_0)], 1))
        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up[0](x1_1)], 1))
        seg_outputs.append(self.seg_outputs[1](x0_2))

        x3_0 = self.conv3_0(self.pool(x2_0))
        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up[2](x3_0)], 1))
        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up[1](x2_1)], 1))
        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up[0](x1_2)], 1))
        seg_outputs.append(self.seg_outputs[2](x0_3))

        x4_0 = self.conv4_0(self.pool(x3_0))
        x3_1 = self.conv3_1(torch.cat([x3_0, self.Up[3](x4_0)], 1))
        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.Up[2](x3_1)], 1))
        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.Up[1](x2_2)], 1))
        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.Up[0](x1_3)], 1))
        seg_outputs.append(self.seg_outputs[3](x0_4))

        if self.supervision: 
            return seg_outputs
        else:
            return seg_outputs[-1]
```













<br>

<br>

# ì°¸ê³  ìë£Œ

* 
