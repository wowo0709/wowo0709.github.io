---
layout: single
title: "[AITech][Image Classification][P stage] 20220306 - Retrospect"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['Image Classification']
---



<br>

# Retrospect

**나는 내 학습 목표를 달성하기 위해 무엇을 어떻게 했는가?**

본인을 포함한 팀의 Level 1 P-stage 학습 목표는 **‘배운 것에 대한 적용과 이해’**였다. Level 1 U-stage를 거치며 많은 내용을 배웠다. 그 중에는 알고 있었던 내용도, 처음 안 내용도 있었다. 그러한 내용들을 수강하며, 중요한 내용과 처음 안 내용에 대한 정리를 꾸준히 실천하였다. 

필요한 것은 **적용**이었다. 모든 학문이 그러하겠지만, 특히 소프트웨어 산업에서는 비단 이론을 알고 있다고 해서 그것이 본인의 실력을 대변해주지 않는다. **그것을 어떻게 사용하고, 어떤 결과를 도출해 낼 수 있는지에 대해 고민하는 과정을 통해 해당 지식/기술을 내 것으로 만들어야 진정으로 ‘안다’라고 할 수 있다.** 그러한 관점에서, 그간 정리한 포스팅들을 하나씩 반추하며 직접 코드로 옮기고, 실행하고 결과까지 확인할 수 있었던 과정이었다. 

<br>

**나는 어떤 방식으로 모델을 개선했는가?**

본인이 모델 개선을 위해 사용한 방식으로는 **Data sampling, Data augmentation, HPO(Hyperparameter Tuning), Ensemble(K-fold, Ensemble training, Test time ensemble 등), Multi-label training** 등이 있다. 



| 시도한 기법          | 회고                                                         |
| -------------------- | ------------------------------------------------------------ |
| Data sampling        | 이번 대회의 task 였던 마스크 착용 여부/성별/나이 에 있어서는 Training과 Validation 시 같은 사람에 해당하는 이미지를 사용하는 것이 과도한 Validation accuracy를 도출해낸다는 것을 알았다. 이전까지는 그저 파일 별로 train/val set을 나누는 데 그쳤다면, 이를 통해 데이터의 특성에 따라 train/val을 적절히 나누어 신뢰할 만한 validation 결과를 얻는 것이 중요하다는 것을 알았다. 또한 EDA를 통해 각 클래스 별 데이터의 개수를 확인하고, 적절히 up-sampling, down-sampling을 하는 것도 중요하다는 것을 알았다. |
| Data augmentation    | 데이터의 일반화를 위해 다양하고 많은 augmentation을 수행하는 것이 정답인 줄로만 알았다. 그러나 이번 대회를 통해 데이터가 적거나 train-test set 간 데이터 차이가 크지 않은 경우 과도한 augmentation은 오히려 성능 저하를 일으킬 수 있다는 것을 알았다. 또한 torchvision, Albumentations 등 다양한 augmentation library를 사용해 볼 수 있었다. |
| HPO                  | 강의에서는 모델이 결정된 상황에서 해당 모델에 변화를 줄 수 있는 하이퍼파라미터들을 위주로 설명하고, 들이는 시간에 비해 성능 향상이 크지는 않다는 내용을 들었다. 하지만 대회에서는 다양한 hyper parameter들 뿐 아니라 model에 대한 search도 진행해 보았다. 이것이 가능하다는 것을 깨달았고, 직접 코드로 구현할 수 있는 능력을 기를 수 있었다. 다음 대회에서는 시작부터 다양한 HPO 과정을 수행해보는 것이 큰 도움이 될 수 있음을 알았다. HPO를 쉽게 수행할 수 있는 ray.tune 모듈을 익힐 수 있었고, 많은 시행 착오 속에서 많은 것을 얻을 수 있었다. |
| Ensemble             | 다양한 앙상블 기법을 시도해보았고, 이것이 실제로 코드 레벨에서는 어떻게 구현되는지, 또 torchensemble이라는 라이브러리가 있다는 것과 사용 방법까지 익힐 수 있었다. 또한 직접 모델 성능이 더 좋아진다는 것을 확인할 수 있었다. |
| Multi-label training | Multi label classification task에 있어 이를 모델 하나로 분류하는 것 뿐 아니라, 하위 task로 쪼개서 여러 다른 모델들을 각 task를 분류하는 데 사용할 수 있다는 것을 배웠다. 또한 각 label에 있어 model ensemble을 수행하고, 전체 class에 있어 한 번 더 ensemble을 수행하는 등의 기법으로 모델의 성능을 한층 더 끌어올릴 수 있다는 것을 직접 확인했다. |

<br>

**내가 한 행동의 결과로 어떤 지점을 달성하고, 어떠한 깨달음을 얻었는가?**

본인이 주로 맡았던 작업은 **HPO**인데, 이를 통해 최고의 성능을 내는 모델의 hyper parameter를 찾을 수 있었다. 현업에서는 그 효과가 크지 않을지 몰라도, 이런 대회에 있어서는 초반에 방향성을 잡는 목적으로 사용하면 큰 이득을 볼 수 있다는 것을 깨달았다. 

**코드 리펙토링** 또한 주요 업무였다. 처음에는 밑바닥부터 본인이 설계한 코드로 해보려 했지만, 여러 어려움을 맞닥뜨리며 좌절을 맛보았다. 결국 AI Tech에서 제공한 baseline code를 토대로 진행했는데, 오피스 아워 때 조교님께서 이야기한 Top-down 방식을 애용하라는 말이 많이 와닿았다. 그간에는 무언가를 하려면 기초부터 탄탄히 해야 한다는 생각이 강해서, 거의 강박관념이라고 할 만큼 그에 대한 기초부터 공부했던 것 같다. 하지만, 일을 함에 있어서 효율적인 일 처리와 함께 일에 재미를 잃지 않는 것이 매우 중요하기 때문에, 앞으로는 Bottom-up에 대한 강박관념을 조금은 버리고, **Top-down 방식의 접근과 친해져보려 한다.** 

<br>

**전과 비교해서, 내가 새롭게 시도한 변화는 무엇이고, 어떤 효과가 있었는가?**

이전에는 단순히 data augmentation, model selection 등과 같은 쉽고 보편적인 방법들 만을 시도했을 뿐이었다. 하지만 지금까지의 교육을 통해 다양한 지식을 습득할 수 있었고, 이를 적용하여 내 것으로 만들자는 마음가짐을 통해 내 것으로 체득할 수 있었으며, 모델 차원에서도 큰 성능의 향상을 이루었다. 그러한 과정이 없었다면 최종 2등이라는 성과는 얻지 못 했을 것이다. 

또한 개인이 하는 프로젝트가 아닌 팀 차원에서 진행했던 만큼, 팀원 들 간의 소통과 공유를 위해 노력했다. 알고 있는 지식을 공유하고 이를 통해 한 차원 더 발전하는 것이 얼마나 멋진 일인지 깨달았고, 그것의 힘을 체험했다. 

<br>

**마주한 한계는 무엇이며, 아쉬웠던 점은 무엇인가?**

단일 모델의 사용만으로는 성능의 한계가 존재한다는 사실을 깨달았다. 이를 넘기 위해 위에서 기술한 다양한 기법들을 시도했었다. 다만, 최종 제출한 모델에 있어서는 시간 부족으로 앙상블 기법을 적용하지 못 한 단일 모델의 결과를 제출해서, 더 좋은 성능을 이끌어내지 못했다는 점이 아쉬움으로 남는다. 

또한 팀원들과의 소통과 공유를 중요시했지만, 대다수가 구두로 이루어지고 플랫폼의 활용은 코드 수준에서 그쳤다는 것이 아쉽고, 개선해 나가야 할 부분이다. 다른 팀들을 보며 **협업을 위해 다양한 플랫폼을 활용하고, 무엇을 공유하는 지**에 대한 인사이트를 얻을 수 있었다. 마지막으로 다른 조들이 **배경을 삭제**하거나 **나이 기준에 변화**를 주는 등의 기법을 시도한 것을 보았는데, 그러한 시도를 미처 해보지 못했다는 것이 아쉽다. 

<br>

**한계/교훈을 바탕으로 다음 프로젝트에서 스스로 새롭게 시도해볼 것은 무엇인가?**

이번 프로젝트를 통해 어떻게 모델 성능을 향상시킬 수 있는지, 협업은 어떻게 무엇을 해야 하는지, 이미지 분류에서 집중하고자 하는 부분 외의 배경 등과 같은 부분은 삭제한다는 등의 아이디어를 많이 얻을 수 있었다. 이를 잘 정리하여, 다음 번에는 미처 시도해보지 못 했던 기법들을 시도해보고, 내 것으로 만들겠다는 다짐을 한다. 

























<br>

