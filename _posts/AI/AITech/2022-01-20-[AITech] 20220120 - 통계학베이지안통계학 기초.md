---
layout: single
title: "[AITech] 20220120 - 통계학&베이지안 통계학 기초"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['모수', '최대가능도', '조건부확률', '인과관계']
---



<br>

## 강의 복습 내용

### 통계

#### 모수

* **통계적 모델링은 적절한 가정 위에서 확률분포를 추정**하는 것이 목표이며, 기계학습과 통계학이 공통적으로 추구하는 목표이다. 

* 그러나 유한한 개수의 데이터에서 모집단의 분포를 정확하게 알아내는 것은 불가능하므로, **근사적으로 확률분포를 추정**해야 한다. 

  * 예측 모형의 목적인 분포를 정확하게 맞추는 것보다 **데이터와 추정 방법의 불확실성을 고려해서 위험을 최소화**하는 것이다. 

* **데이터가 특정 확률분포를 따른다고 선험적으로 가정한 후 그 분포를 결정하는 모수를 추정**하는 방법을 **모수적 방법론**이라 한다. 

* **특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 바뀌면** **비모수 방법론**이라 한다. 

  * 기계학습의 많은 방법론은 비모수 방법론에 속한다. 

* 기계적으로 확률분포를 가정해서는 안 되며, **데이터를 생성하는 원리**를 먼저 고려해야 한다.

  * 모수를 추정한 후에는 반드시 검정 과정이 필요하다. 

* 예를 들어, 정규분포의 모수는 평균 μ와 분산 σ<sup>2</sup>으로 이를 추정하는 통계량은 다음과 같다. 

  * 표본 분산을 구할 때 N이 아니라 N-1로 나누는 이유는 불편(unbiased) 추정량을 구하기 위해서이다. 

  ![image-20220120221103646](https://user-images.githubusercontent.com/70505378/150361250-2f69f80b-68bc-407f-92bb-e0a300096a3b.png)

  * **통계량(평균, 분산 등)의 확률 분포**를 **표집분포**라 한다. 

    * 표집분포는 표본분포와 다릅니다!!
    * 표본평균의 표집분포는 N이 커질수록 정규분포 N(μ, σ<sup>2</sup>/N)를 따른다. 이를 **중심극한정리**라 하며, 모집단의 분포가 정규분포를 따르는지와의 여부는 상관없다. 

    ![image-20220120221404354](https://user-images.githubusercontent.com/70505378/150361256-980085e5-b413-4c35-9643-75c3bcf96990.png)

#### 최대가능도 추정법

* 표본평균이나 표본분산은 중요한 통계량이지만 **확률분포마다 사용하는 모수가 다르므로 적절한 통계량이 달라진다.**

* 이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나는 **최대가능도 추정법**이다. 

  * 확률 밀도(질량) 함수가 모수가 주어졌을 때 x에 대한 함수라면, 최대가능도 함수는 x가 주어졌을 때 모수에 대한 함수이다. 
  * 가능도 함수는 모수 _theta_를 따르는 분포가 _x_를 관찰할 가능성을 뜻하지만, 확률로 해석해서는 안 된다. 

  ![image-20220120221745254](https://user-images.githubusercontent.com/70505378/150361258-766ecdc1-cf13-44b8-b902-85ed616fb8dc.png)

* 데이터 집합 X가 **독립적으로 추출되었을 경우 로그 가능도**를 최적화한다. 

  ![image-20220120221912176](https://user-images.githubusercontent.com/70505378/150361262-ac0153b3-cf57-4c30-9b97-ac398f643569.png)

  * 데이터의 숫자가 매우 많을 때, 컴퓨터의 precision으로는 0~1 사이의 값을 여러번 곱하는 연산은 큰 오차를 갖게 된다. 
  * 데이터가 독립일 경우, 로그를 사용하면 가능도의 곱셈을 로그가능도의 덧셈으로 바꿀 수 있기 때문에 컴퓨터로 연산이 가능하다. 
  * 미분 연산 시 로그 가능도를 사용하면 연산량을 O(n^2)에서 O(n)으로 줄일 수 있다. 
  * 대개의 손실함수의 경우 **음의 로그가능도**를 최적화(최소화)한다. 

#### 예제1: 정규분포

* 정규분포를 따르는 확률변수 X(연속확률변수)로부터 독립적인 표본 \{x1, ..., xn\}을 얻었을 때 최대가능도 추정법을 이용하여 모수를 추정한다. 

![image-20220120222932223](https://user-images.githubusercontent.com/70505378/150361264-13bd442f-2a9f-44f4-9bb9-52813be21fd5.png)

#### 예제2: 카테고리 분포

* 카테고리 분포를 따르는 확률변수 X(이산확률변수)로부터 독립적인 표본 \{x1, ..., xn\}을 얻었을 때 최대가능도 추정법을 이용하여 모수를 추정한다. 
  * **p<sub>k</sub>**는 k번째 차원에서 1일 확률이며, 모수입니다. 

![image-20220120225334321](https://user-images.githubusercontent.com/70505378/150361186-6a6a77ee-ff39-4a78-90ff-4019a904e41e.png)

#### 두 확률분포 사이의 거리

* 최대 가능도 추정법을 이용해 기계학습 모델을 학습할 수 있다. 
* 딥러닝 모델의 가중치를 θ = (W(1), ..., w(L))이라 표기했을 때 분류 문제에서 **소프트맥스 벡터는 카테고리 분포의 모수 (p1, ..., pk)**를 모델링한다. 
* 원핫벡터로 표현한 **정답 레이블 y = (y1, ..., yk)를 관찰데이터**로 이용해 **확률분포인 소프트맥스 벡터의 로그가능도를 최적화**합니다. 

![image-20220120230950310](https://user-images.githubusercontent.com/70505378/150361193-f8f36621-bc61-4fa0-8887-6f8fef898496.png)

* 기계학습에서 사용되는 손실함수들은 **모델이 학습하는 확률분포와 데이터에서 관찰되는 확률분포의 거리를 통해 유도한다.**

  * 데이터 공간에 두 개의 확률분포 P(x), Q(x)가 있을 경우 **두 확률분포 사이의 거리**를 계산할 때 다음과 같은 함수들을 이용한다. 

    * 총변동 거리(Total Variation Deistance, TV)
    * 쿨백-라이블러 발산(Kullback-Leibler Divergence, KL)
    * 바슈타인 거리(Wasserstein Distance)

  * 쿨백-라이블러 발산은 다음과 같이 정의하며, 

    ![image-20220120231424581](https://user-images.githubusercontent.com/70505378/150361195-527d9f60-37d4-4f68-8716-ab10c2232f40.png)

  * 다음과 같이 분해할 수 있다. 

    ![image-20220120231449046](https://user-images.githubusercontent.com/70505378/150361200-eae86f55-621a-4163-a354-d5245a2bd834.png)

  * 분류 문제에서 정답 레이블을 P, 모델 예측을 Q라 하면 **최대가능도 함수를 최적화하는 것은 쿨백-라이블러 발산을 최소화**하는 것과 같다. 

    * 즉, 손실 함수를 최소화한다는 것은 데이터의 분포와 모델이 예측한 분포 간 거리를 최소화한다는 것과 같다. 

<br>

### 베이지안 통계학

#### 조건부 확률

* **베이즈 정리**는 조건부 확률을 이용하여 **정보를 갱신하는 방법**을 알려준다. 

  ![image-20220120232125534](https://user-images.githubusercontent.com/70505378/150361203-5b67aabc-4716-4514-9186-155231a60612.png)

* **사후확률**을 구할 때는 적어도 **사전확률**과 **가능도**가 주어져야 한다. 가능도에는 P(D | θ)와 P(D | ¬θ)가 있다. 

  * 두 가능도를 알 때, **Evidence**는 다음과 같이 구할 수 있다. 

  ![image-20220120232535181](https://user-images.githubusercontent.com/70505378/150361208-0a03eab5-d979-4872-8f4b-711196615bf1.png)

* 조건부 확률의 시각화
  * 데이터의 성격에 따라 1종오류와 2종오류 중 어떤 것의 감소가 중요한 지 결정한다. 
  * 예를 들어, 의료 데이터에서는 2종 오류(0이라고 예측했을 때 틀린 경우)는 매우 심각한 문제이므로, 2종 오류를 줄이기 위해 노력한다. 

![image-20220120232938536](https://user-images.githubusercontent.com/70505378/150361210-e47c713b-eb18-42d8-89df-5252f9ddcb51.png)

#### 베이즈 정리를 통한 정보의 갱신

* 베이즈 정리를 통해 새로운 데이터가 들어왔을 때 **앞서 계산한 사후 확률을 사전 확률로 사용**하여 **갱신된 사후확률을 계산**할 수 있다. 

![image-20220120233356864](https://user-images.githubusercontent.com/70505378/150361214-4edf9c47-611f-40f2-9944-43c38e7a9421.png)

![image-20220120233514235](https://user-images.githubusercontent.com/70505378/150361216-feb9acbb-b63d-4a28-85da-4b1d68c64b25.png)

#### 인과관계

* 조건부 확률은 유용한 통계적 해석을 제공하지만 **인과관계**를 추론할 때 함부로 사용해서는 안 된다. 
  * 데이터가 많아져도, 조건부 확률만 가지고 인과관계를 추론하는 것은 불가능하다. 
* 인과관계는 **데이터 분포의 변화에 강건한 예측모형**을 만들 때 필요하다. 

![image-20220120233658999](https://user-images.githubusercontent.com/70505378/150361218-3538e844-3130-40c6-b19f-a81176fdcda6.png)

* 인과관계를 알아내기 위해서는 **중첩요인의 효과를 제거**하고, 원인에 해당하는 변수만의 인과관계를 계산해야 한다. 



<br>

<br>
