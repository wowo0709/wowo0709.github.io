---
layout: single
title: "[AITech][Semantic Segmentation][P stage] 20220519 - 최종 프로젝트 4일차"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: []
---



<br>

# 최종 프로젝트 4일차

어제 옷의 feature를 사용해서 실험을 해보기로 했었는데, 코드를 뜯어보다 `threshold`라는 파라미터가 중요한 역할을 한다는 것을 발견해서 이 threshold 값을 변경하며 먼저 실험을 진행해봤다. 

기본 default 값은 0.44로 되어 있으며, 이 경우에 다른 얼굴을 같은 얼굴로 판단하는 빈도가 꽤 있었다. 

```python
    def compare_with_known_persons(self, face, persons):
        if len(persons) == 0:
            return None

        # see if the face is a match for the faces of known person
        encodings = [person.encoding for person in persons]
        distances = face_recognition.face_distance(encodings, face.encoding) # 기존 face들과 현재 face 간의 l2 norm
        index = np.argmin(distances)  # 거리가 가장 작은 값의 인덱스
        min_value = distances[index] # 가장 작은 값
        if min_value < self.similarity_threshold: # 가장 작은 값이 threshold보다도 작으면, -> 해당 face에 추가
            # face of known person
            persons[index].add_face(face)
            # re-calculate encoding
            persons[index].calculate_average_encoding()
            face.name = persons[index].name
            return persons[index]
```

threshold는 **다른 얼굴과 같은 인물로 판단할 것인지, 아닌지** 판단의 준거가 된다. 두 얼굴 사이의 거리를 구한 뒤, 거리가 threshold보다 작으면 같은 인물로 판단한다. 이 때 거리는 두 얼굴이 '다른 정도'이다. 

<br>

3개의 영상 데이터에 대해 실험을 진행했을 때, **threshold=0.36**일 때 가장 일반적이고 좋은 clustering 성능을 보였다. 

![image-20220519183315424](https://user-images.githubusercontent.com/70505378/169265219-a511e1e3-bf22-4c64-ad24-5d039103dee4.png)



위 그림처럼 같은 인물끼리만 clustering해내는 것을 알 수 있다. 

<br>

하지만 여전히 완벽한 수준은 아닌 것이, unknown으로 분류된 cluster(두 번 이상 등장하지 않은 인물)를 보면 아래와 같다. 

![image-20220519183502624](https://user-images.githubusercontent.com/70505378/169265209-7d1c9ece-ba7f-4a31-b03a-9c8124b2b7e9.png)

제대로 된 clustering이 되지 않는 경우를 분류해보면 아래와 같다. 

* 화질이 나쁜 경우
* 얼굴 일부가 가려진 경우
* 측면을 보고 있는 경우 (또는 얼굴을 숙인 경우, 너무 웃고 있는 경우)

그래서 추가적으로 옷의 feature를 사용할 수 있을 것 같다. 옷의 위치는 얼굴 위치를 기반으로 영상의 특징을 고려하여 정하였다. 

이에 대한 실험도 진행해보았는데, baseline 코드 작성을 완료했으며 feature extraction을 위한 모델은 일단 임시로 ImageNet으로 pretrained된 ResNet 모델을 사용하였다. 

해당 feature를 사용해 분류했을 때 성능이 좋지는 않아서, 피어세션 때 이야기를 나누면서 **패션 데이터로 학습된 모델을 사용**하는 것이 좋을 것 같다는 의견을 나눴다. 

* [https://github.com/MorSlomi/DeepFashion](https://github.com/MorSlomi/DeepFashion)
* [https://github.com/levindabhi/cloth-segmentation](https://github.com/levindabhi/cloth-segmentation)
* [https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/data](https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/data)

또한 face feature와 cloth feature를 같이 어떻게 활용할지에 대한 이야기도 나눴다. 두 feature를 fusion해서 동시에 사용하는 방법도 있을 것이고, face feature로 1차 clustering 후에 cloth feature로 2차 clustering을 하는 방법도 있을 것이다. 



<br>

## **결론**

* threshold=0.36으로 설정하면 비교적 깨끗하게 clustering되는데, unknown cluster의 수가 많아진다. 이에 cloth feature를 활용해보자!
* Fashion dataset으로 pretrained된 모델을 사용하여 cloth feature를 추출하자. 
* Face feature와 cloth feature를 어떻게 합칠지?
* 유사도 계산 시 l2 distance 대신 다른 distance 사용?



















<br>

<br>

# 참고 자료

* 
