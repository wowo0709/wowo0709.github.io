---
layout: single
title: "[AITech] 2022년 1월 19일 학습 내용 정리"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['넘파이','벡터/행렬','경사하강법']
---



<br>

## 강의 복습 내용

### 1. Numpy

**어떻게 벡터와 행렬을 코드로 표현할 것인가?** ➡ **numpy**

* Numerical Python
* 파이썬의 **고성능 과학 계산용 패키지**
* **Matrix와 Vector 같은 Array 연산의 사실 상 표준**
* **일반 List에 비해 빠르고, 메모리 효율적**
* **반복문 없이 데이터 배열에 대한 처리를 지원**
* 선형대수와 관련된 다양한 기능을 제공
* C, C++, 포트란 등의 언어와 통합 가능

#### ndarray

* 넘파이는 np.array 함수를 사용하여 배열을 생성(ndarray)
* 넘파이는 **하나의 데이터 type**만 배열에 넣을 수 있음(**Dynamic typing not supported**)
* C의 Array를 사용하여 배열을 생성

```python
test_array = np.array([1,4,5,8],float) # 배열 생성 시 데이터 타입을 지정(int8, float16, float32 등)
print(test_array)
print(type(test_array[3]))
'''
[1. 4. 5. 8.]
<class 'numpy.float64'>
'''
```

* 넘파이는 배열 생성 시 **새로운(독립적인) 메모리 공간에 따로 수들을 순서대로 저장**

  * 메모리 효율적
  * 일반 List는 값이 저장되어 있는 메모리 주소가 static하게 할당되어 있고, 그 메모리 주소를 저장하는 방식
    * 2번의 참조가 필요

  ![image-20220119210842379](https://user-images.githubusercontent.com/70505378/150142997-fb76f5ad-8476-4a3a-acb5-0452d3dac000.png)

```python
# List
a = [1,2,3,4,5]
b = [5,4,3,2,1]
print(a[0] is b[-1])
# Numpy array
a = np.array(a)
b = np.array(b)
print(a[0] is b[-1])
'''
True
False
'''
```

* `ndarray.shape`: numpy array의 dimension 구성을 반환(형상)

```python
tensor = [[[1,2,3,8],[1,2,3,8],[1,2,3,8]],
         [[1,2,3,8],[1,2,3,8],[1,2,3,8]],
         [[1,2,3,8],[1,2,3,8],[1,2,3,8]],
         [[1,2,3,8],[1,2,3,8],[1,2,3,8]]]

np.array(tensor,int).shape
# (4, 3, 4)
```

![image-20220119212046981](https://user-images.githubusercontent.com/70505378/150143002-d1c08779-4b78-4cab-bf96-f0922581cea6.png)

* `ndarray.dtype`: numpy array의 데이터 type을 반환

```python
test_array = np.array([1, 4, 5, "8"], float) # String Type의 데이터를 입력해도
print(test_array)
print(type(test_array[3])) # Float Type으로 자동 형변환을 실시
print(test_array.dtype) # Array(배열) 전체의 데이터 Type을 반환함
print(test_array.shape) # Array(배열) 의 shape을 반환함
'''
[1. 4. 5. 8.]
<class 'numpy.float64'>
float64
(4,)
'''
```

* `ndarray.ndim`: 차원의 개수
* `ndarray.size`: data의 총 개수

```python
tensor = [[[1,2,3,8],[1,2,3,8],[1,2,3,8]],
         [[1,2,3,8],[1,2,3,8],[1,2,3,8]],
         [[1,2,3,8],[1,2,3,8],[1,2,3,8]],
         [[1,2,3,8],[1,2,3,8],[1,2,3,8]]]

tensor = np.array(tensor,int)
print(tensor.ndim, tensor.size)
# 3 48
```

* `ndarray.nbytes`: ndarray object의 메모리 크기를 반환

```python
a = np.array([[1,2,3],[4.5,"5","6"]], dtype=np.float32) # 32bits = 4bytes -> 6*4 bytes
b = np.array([[1,2,3],[4.5,"5","6"]], dtype=np.int8)    # 8bits = 1bytes -> 6*1bytes
c = np.array([[1,2,3],[4.5,"5","6"]], dtype=np.float64) # 64bits = 8bytes -> 6*8bytes

print(f"a: {a.nbytes} bytes")
print(f"b: {b.nbytes} bytes")
print(f"c: {c.nbytes} bytes")
'''
a: 24 bytes
b: 6 bytes
c: 48 bytes
'''
```

<br>

#### Handling shape

* `ndarray.reshape(*args)`: Array의 shape의 크기를 변경. element의 수는 동일. 

```python
test_matrix = np.array([[1,2,3,4],[1,2,5,8]],int)
print(test_matrix, test_matrix.shape)

test_matrix = test_matrix.reshape(8,)
print(test_matrix, test_matrix.shape)

'''
[[1 2 3 4]
 [1 2 5 8]] (2, 4)
[1 2 3 4 1 2 5 8] (8,)
'''

print(test_matrix.reshape(-1,2),test_matrix.reshape(-1,2).shape)
# print(test_matrix.reshape(4,2),test_matrix.reshape(4,2).shape)
'''
[[1 2]
 [3 4]
 [1 2]
 [5 8]] (4, 2)
'''
```

* `ndarray.flatten()`: 다차원 array를 1차원 array로 변환

```python
test_matrix = np.array([[1,2,3,4],[1,2,5,8]],int)
print(test_matrix, test_matrix.shape)
print(test_matrix.flatten(),test_matrix.flatten().shape)
'''
[[1 2 3 4]
 [1 2 5 8]] (2, 4)
[1 2 3 4 1 2 5 8] (8,)
'''
```

<br>

#### Indexing & Slicing

* List와 달리 이차원 배열에서 **[0,0] 표기법**을 지원
  * 앞은 row, 뒤는 column

```python
test_example = np.array([[1,2,3],[4.5,5,6]],int)
print(test_example[0][0],test_example[0,0])

test_example[0,0] = 12
print(test_example)
'''
1 1
[[12  2  3]
 [ 4  5  6]]
'''
```

* List와 달리 **행과 열 부분을 나눠서 slicing**이 가능함
  * matrix의 부분 집합을 추출할 때 유용

```python
a = np.array([[1,2,3,4,5],[6,7,8,9,10]],int)
print(a)
print(a[:,2:])
print(a[1,1:3])
print(a[1:3])
'''
[[ 1  2  3  4  5]
 [ 6  7  8  9 10]]
[[ 3  4  5]
 [ 8  9 10]]
[7 8]
[[ 6  7  8  9 10]]
'''
# step을 지정할 수 있음
a = np.array([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]],int)
print(a)
print(a[:,::2])
print(a[::2,::3])
'''
[[ 1  2  3  4  5]
 [ 6  7  8  9 10]
 [11 12 13 14 15]]
[[ 1  3  5]
 [ 6  8 10]
 [11 13 15]]
[[ 1  4]
 [11 14]]
'''
```

![image-20220119214020429](https://user-images.githubusercontent.com/70505378/150143004-dc2423a9-80de-429d-9786-9f801251a8d3.png)

<br>

#### Creation function

* `np.arange(start, end, step)`: array의 범위를 지정하여, 값의 list를 생성하는 명령어

```python
print(np.arange(10))
print(np.arange(0,5,0.5))
print(np.arange(10).reshape(2,5)) # reshape와 함께 자주 사용
'''
[0 1 2 3 4 5 6 7 8 9]
[0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5]
[[0 1 2 3 4]
 [5 6 7 8 9]]
'''
```

* `np.zeros(shape,dtype), np.ones(shape,dtype), np.empty(shape,dtype)`
  * 각각 0으로, 1로, 햘당되지 않은 메모리로 채워진 행렬을 반환
* `np.zeros_like(ndarray,dtype), np.ones_like(ndarray,dtype), np.empty(ndarray,dtype)`
  * 각각 인자로 전달받은 ndarray와 같은 형상인 0, 1, 할당되지 않은 메모리로 채워진 행렬을 반환
* `np.identity(n, dtype)`: 단위 행렬 생성
* `np.eye(N, M, k, dtype)`: 대각선이 1인 행렬, k값의 시작 index 변경 가능

```python
print(np.eye(3))
print(np.eye(3,5,k=2))
'''
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
[[0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1.]]
'''
```

* `np.diag(ndarray, k)`: 대각 행렬의 값을 추출, k값의 시작 인덱스 변경 가능

```python
matrix = np.arange(9).reshape(3,3)
print(matrix)
print(np.diag(matrix))
print(np.diag(matrix, k=1))
'''
[[0 1 2]
 [3 4 5]
 [6 7 8]]
[0 4 8]
[1 5]
'''
```

* `np.random.uniform(from, to, n), np.random.normal(from, to, n)`: 데이터 분포에 따른 sampling으로 array를 생성

```python
print(np.random.uniform(0,1,10).reshape(2,5))
print(np.random.normal(0,1,10).reshape(2,5))
'''
[[0.35006331 0.24951611 0.49920446 0.61727984 0.82651679]
 [0.04549254 0.17509728 0.52278906 0.12011707 0.7854978 ]]
[[-0.07886817  1.05551477 -0.09244039  0.32329219 -1.3036152 ]
 [-0.22816616  0.25514229  1.3512013   1.59589969  0.0897062 ]]
'''
```

<br>

#### Operation functions

* `ndarray.sum(axis)`: axis를 기준으로 ndarray의 element 간의 합을 구함

```python
third_order_tensor = np.array([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],
                                 [[1,2,3,4],[5,6,7,8],[9,10,11,12]],
                                 [[1,2,3,4],[5,6,7,8],[9,10,11,12]]])

print(third_order_tensor.sum(axis=2))
print(third_order_tensor.sum(axis=1))
print(third_order_tensor.sum(axis=0))
'''
[[10 26 42]
 [10 26 42]
 [10 26 42]]
[[15 18 21 24]
 [15 18 21 24]
 [15 18 21 24]]
[[ 3  6  9 12]
 [15 18 21 24]
 [27 30 33 36]]
'''
```

![image-20220119215349932](https://user-images.githubusercontent.com/70505378/150143010-0d2049e5-51f0-45e2-8f6f-dc954ad0f17b.png)

* `ndarray.mean(axis), ndarray.std(axis)`: ndarray의 element 간 평균 또는 표준 편차
* 그 외에도 다양한 수학 연산자를 제공
  * `np.exp(ndarray), np.sqrt(ndarray), np.sin(ndarray), np.sinh(ndarray), np.arcsin(ndarray)...`

##### **Concatenate**

* `np.vstack((ndarray1,ndarray2)), hstack((ndarray1, ndarray2))`

```python
a = np.array([1,2,3])
b = np.array([2,3,4])
print(np.vstack((a,b)))

a = np.array([[1],[2],[3]])
b = np.array([[2],[3],[4]])
print(np.hstack((a,b)))
'''
[[1 2 3]
 [2 3 4]]
[[1 2]
 [2 3]
 [3 4]]
'''
```

![image-20220119220423961](https://user-images.githubusercontent.com/70505378/150143012-e3ed8111-6f18-468d-bce9-fac315e7b40d.png)

* `np.concatenate((ndarray1, ndarray2), axis)`

```python
a = np.array([1,2,3])
b = np.array([2,3,4])
print(np.concatenate((a,b), axis=0))

a = np.array([[1,2],[3,4]])
b = np.array([[5],[6]])
print(np.concatenate((a,b), axis=1))
'''
[1 2 3 2 3 4]
[[1 2 5]
 [3 4 6]]
'''
```

<br>

#### Array operations

* numpy는 array 간의 기본적인 사칙 연산을 지원함

```python
test_a = np.array([[1,2,3],[4,5,6]], float)
print(test_a+test_a)
print(test_a-test_a)
print(test_a*test_a) # element wise multiplication(Hadamard multiplication)
print(test_a.dot(test_a.T)) # matrix multiplication
print(test_a.transpose(), test_a.T) # transpose
'''
[[ 2.  4.  6.]
 [ 8. 10. 12.]]
[[0. 0. 0.]
 [0. 0. 0.]]
[[ 1.  4.  9.]
 [16. 25. 36.]]
[[14. 32.]
 [32. 77.]]
[[1. 4.]
 [2. 5.]
 [3. 6.]] 
[[1. 4.]
 [2. 5.]
 [3. 6.]]
'''
```

##### **Broadcasting**

* Shape이 다른 배열 간 연산을 지원

![image-20220119221237272](https://user-images.githubusercontent.com/70505378/150143014-3793beb7-010d-4c1b-937f-2806bbaf8a56.png)

```python
test_matrix = np.array([[1,2,3],[4,5,6]],float)
scalar = 3

print(test_matrix + scalar)
print(test_matrix - scalar)
print(test_matrix * scalar)
print(test_matrix / scalar)
print(test_matrix // scalar)
print(test_matrix ** scalar)
'''
[[4. 5. 6.]
 [7. 8. 9.]]
[[-2. -1.  0.]
 [ 1.  2.  3.]]
[[ 3.  6.  9.]
 [12. 15. 18.]]
[[0.33333333 0.66666667 1.        ]
 [1.33333333 1.66666667 2.        ]]
[[0. 0. 1.]
 [1. 1. 2.]]
[[  1.   8.  27.]
 [ 64. 125. 216.]]
'''
```

* Scalar 외에도 vector - matrix 간 연산도 지원

![image-20220119221509193](https://user-images.githubusercontent.com/70505378/150143017-d5ba9046-43c2-4886-9452-0f9cc456f10c.png)

##### Numpy performance

* 일반적으로 속도는 **for loop < list comprehension < numpy** 순
* 100,000,000 번의 loop이 돌 때, 약 4배 이상의 성능 차이를 보임
* Numpy는 C로 구현되어 있어, 성능을 확보하는 대신 파이썬의 가장 큰 특징인 dynamic typing을 포기함
* 대용량 계산에서는 가장 흔히 사용됨
* Concatenate처럼 계산이 아닌, 할당에서는 연산 속도의 이점이 없음

<br>

#### Comparisons

* `np.any(condition), np.all(condition)`: Array의 데이터 전부 혹인 일부가 조건에 만족 여부 반환

```python
a = np.arange(10)
print(a)
print(a>5)
print(np.any(a>5))
print(np.all(a>5))
'''
[0 1 2 3 4 5 6 7 8 9]
[False False False False False False  True  True  True  True]
True
False
'''
```

* `np.logical_and(bool_ndarray1, bool_ndarray2), np.logical_or(bool_ndarray1, bool_ndarray2), np.logical_not(bool_ndarray)`

```python
a = np.array([1,3,0], float)
print(a > 0, a < 3)
print(np.logical_and(a > 0, a < 3))
print(np.logical_or(a > 0, a < 3))
print(np.logical_not(a > 0))
'''
[ True  True False] [ True False  True]
[ True False False]
[ True  True  True]
[False False  True]
'''
```

* `np.where(condition, TRUE, FALSE)`
  * 인자로 condition만 전달 시 True인 값의 인덱스 리스트를 반환
  * 인자로 condition, TRUE, FALSE 모두 전달 시 True인 값은 TRUE로, False인 값은 FALSE로 치환된 리스트 반환

```python
a = np.array([1,3,0], float)
print(a > 0)
print(np.where(a > 0))
print(np.where(a > 0,3,2))
'''
[ True  True False]
(array([0, 1], dtype=int64),)
[3 3 2]
'''
```

* `np.isnan(ndarray), np.isfinite(ndarray)`

```python
a = np.array([1,np.NaN,np.Inf], float)
print(np.isnan(a))
print(np.isfinite(a))
'''
[False  True False]
[ True False False]
'''
```

<br>

#### argmax, argmin, argsort

* `np.argmax(ndarray, axis), np.argmin(ndarray, axis)`: array 내 최댓값 또는 최솟값의 index를 반환
* `np.argsort(ndarray, axis)`: 오름차순으로 정렬했을 때 기존 array 원소의 index를 반환

```python
a = np.array([[1,2,4,7], [9,88,6,45], [9,76,3,4]])
print(a)
print(np.argmax(a,axis=1))
print(np.argmin(a, axis=0))
'''
[[ 1  2  4  7]
 [ 9 88  6 45]
 [ 9 76  3  4]]
[3 1 1]
[0 0 2 2]
[[0 0 2 2]
 [1 2 0 0]
 [2 1 1 1]]
'''
```

<br>

#### Boolean & Fancy indexing

**Boolean index**

* 특정 조건에 따른 값을 매열 형태로 추출
* Comparison operation 함수들도 모두 사용 가능

```python
test_array = np.array([1,4,0,2,3,8,9,7], float)
condition = test_array > 3
print(condition)
print(test_array[condition]) # 조건이 True인 index의 element만 추출
'''
[False  True False False False  True  True  True]
[4. 8. 9. 7.]
'''
```

**Fancy index**

* numpy는 array를 index value로 사용해서 값 추출
* `ndarray.take(ndarray)`: fancy index(bracket index)과 같은 효과

```python
a = np.array([2,4,6,8], float)
b = np.array([0,0,1,3,2,1], int)
print(a[b]) # bracket index, b 배열의 값을 index로 하여 a의 값들을 추출
print(a.take(b)) # take 함수: bracket index와 같은 효과
'''
[2. 2. 4. 8. 6. 4.]
[2. 2. 4. 8. 6. 4.]
'''
```

* matrix 형태의 데이터도 가능

```python
a = np.array([[1,4],[9,16]], float)
b = np.array([0,0,1,1,0], int)
c = np.array([0,1,1,1,1], int)
print(a[b,c])
# [ 1.  4. 16. 16.  4.]
```

<br>

#### Numpy data i/o

* text type의 데이터를 읽고, 저장하는 기능

```python
# 파일 저장
np.save("npy_test_object", arr=a_int_3)
# 파일 호출
a_test = np.load(file="npy_test_object.npy")
```



<br>

### 2. 벡터

* **벡터**는 숫자를 원소로 가지는 리스트 또는 배열이다. 
  
  * **벡터의 차원**은 벡터가 가진 원소의 개수이다. 
  
* **벡터**는 n차원 공간에서 한 점을 나타낸다. 
  * 벡터에 숫자를 곱해주면 길이만 변한다. (스칼라곱)
  * 벡터는 같은 모양을 가지면 덧셈, 뺄셈, 성분곱(Hadamard product)을 계산할 수 있다. 
    * 벡터 덧셈은 다른 벡터로부터 상대적 위치 이동을 표현합니다. 
    * 벡터 뺄셈은 벡터의 방향을 뒤집은 덧셈입니다. 
  
  ```python
  import numpy as np
  
  x = np.array([1,7,2])
  y = np.array([5,2,1])
  
  # 벡터 덧셈
  print(x+y)
  # 벡터 뺄셈
  print(x-y)
  # 벡터 내적
  print(x*y)
  '''
  [6 9 3]
  [-4  5  1]
  [ 5 14  2]
  '''
  ```

* **벡터의 노름**은 **원점에서부터의 거리**를 말합니다. 

  ![노름(norm)](https://t1.daumcdn.net/cfile/tistory/99D721445BD00C6E1A)

  ```python
  def l1_norm(x):
      x_norm = np.abs(x)
      x_norm = np.sum(x_norm)
      return x_norm
  
  def l2_norm(x):
      x_norm = x*x
      x_norm = np.sum(x_norm)
      x_norm = np.sqrt(x_norm)
      return x_norm
  
  x = np.array([1,2,3])
  print(f"l1 norm: {l1_norm(x)}")
  print(f"l2 norm: {l2_norm(x)}")
  '''
  l1 norm: 6
  l2 norm: 3.7416573867739413
  '''
  ```

* 서로 다른 노름이 중요한 이유

  * 노름의 종류에 따라 **기하학적 성질**이 달라진다. 
  * 머신러닝에선 각 성질들이 필요할 대가 있으므로 둘 다 사용한다. 

  ![image-20220119112430894](https://user-images.githubusercontent.com/70505378/150055194-34fd93f3-c1e7-445e-bae5-10ab8320cb10.png)

  * L1, L2 노름을 이용해 **두 벡터 사이의 거리**를 계산할 수 있다. 
  * L2 노름을 이용해 **두 벡터 사이 각도**를 계산할 수 있다. 

  ```python
  def angle(x,y):
      v = np.inner(x,y) / (l2_norm(x)*l2_norm(y))
      theta = np.arccos(v)
      return theta # Pi 기준 표시
  
  x, y = np.array([1,10,3]), np.array([-1,-10,-3])
  print(angle(x,y))
  # 3.141592653589793
  ```

* **내적**은 **정사영된 벡터의 길이**와 관련 있다. 

  * 내적은 두 벡터의 **유사도**를 측정하는 데 사용 가능하다. 

  ![image-20220119113026170](https://user-images.githubusercontent.com/70505378/150055199-3e4817d2-36ed-48a9-8ece-35b3a388a8a4.png)

<br>

### 3. 행렬

* **행렬**은 벡터를 원소로 가지는 **2차원 배열**이다. 

  * 행렬은 **행**과 **열**이라는 인덱스를 가진다. 

  ![image-20220119113221006](https://user-images.githubusercontent.com/70505378/150055203-94431aca-0f80-443a-9bfe-bd3284897dac.png)

  * **전치 행렬**은 행과 열의 인덱스가 바뀐 행렬이다. 

  ![image-20220119113259537](https://user-images.githubusercontent.com/70505378/150055206-fde116e1-e729-4adc-badd-c85201a60274.png)

  * 행렬끼리 같은 모양을 가지면 덧셈, 뺄셈, 성분곱, 스칼라곱을 계산할 수 있다. 
  * **행렬 곱셈**은 **i번째 행벡터와 j번재 열벡터 사이의 내적**을 계산하고, **행렬 내적**은 **i번째 행벡터와 j번째 행벡터 사이의 내적(XY<sup>T</sup>**을 계산한다. 
    * 수학에서 말하는 내적과는 다르므로 주의!

  ```python
  X = np.array([[1,-2,3],
                [7,5,0],
                [-2,-1,2]])
  Y = np.array([[0,1,10],
                [1,-1,7],
                [-2,1,0]])
  
  # 행렬곱
  print(X @ Y)
  # 행렬 내적
  print(np.inner(X,Y)) # = X @ Y.T
  '''
  [[ -8   6  -4]
   [  5   2 105]
   [ -5   1 -27]]
  [[28 24 -4]
   [ 5  2 -9]
   [19 13  3]]
  '''
  ```

  

* **행렬을 이해하는 방법 1**

  * 벡터가 공간에서 한 점을 나타낸다면, 행렬을 **여러 점들**을 나타낸다. 
  * 행렬의 행벡터 xi는 i번째 데이터를 의미한다. 
  * 행렬의 xij는 i번째 데이터의 j번째 변수의 값을 말한다. 

   

* **행렬을 이해하는 방법 2**

  * 행렬은 **벡터 공간에서 사용되는 연산자**로 이해한다. 
  * 행렬 곱을 통해 벡터를 **다른 차원의 공간**으로 보낼 수 있다. 
  * 행렬 곱을 통해 **패턴을 추출**할 수도 있고, **데이터를 압축**할 수도 있다. 
    * 모든 선형변환은 행렬곱으로 계산할 수 있다!

  ![image-20220119114208634](https://user-images.githubusercontent.com/70505378/150055207-b575bca8-e772-4339-bf0f-5ac106ff97be.png)

  * 역행렬 이해하기

    * 어떤 행렬 A의 연산을 거꾸로 되돌리는 행렬을 **역행렬**이라 부르고 A<sup>-1</sup>라 표기한다. (AA<sup>-1</sup> = A<sup>-1</sup>A = I)

      ![image-20220119114654455](https://user-images.githubusercontent.com/70505378/150055214-792166a7-7145-4145-b5c2-f70a3590f1de.png)

      ![image-20220119114636254](https://user-images.githubusercontent.com/70505378/150055212-79f4a05c-5c8d-4b73-b20b-97c6dc9bc695.png)

      

    * 역행렬은 **행과 열 숫자가 같고 행렬식이 0이 아닌 경우**에만 계산할 수 있다. 

    * 만일 역행렬을 계산할 수 없다면 **유사 역행렬** 또는 **무어-펜로즈 역행렬** A<sup>+</sup>을 이용한다. 

      ![image-20220119114552134](https://user-images.githubusercontent.com/70505378/150055211-3e39b636-a6f3-4af6-ab75-ff475b0b37a2.png)

      ![image-20220119114535231](https://user-images.githubusercontent.com/70505378/150055210-7aa5dd1b-d297-4648-8564-466deb0d19c1.png)

    ```python
    X = np.array([[1,-2,3],
                  [7,5,0],
                  [-2,-1,2]])
    
    # 역행렬
    print(np.linalg.inv(X))
    print(X @ np.linalg.inv(X))
    # 유사 역행렬
    print(np.linalg.pinv(X))
    print(X @ np.linalg.pinv(X))
    '''
    [[ 0.21276596  0.0212766  -0.31914894]
     [-0.29787234  0.17021277  0.44680851]
     [ 0.06382979  0.10638298  0.40425532]]
    [[ 1.00000000e+00 -1.38777878e-17  0.00000000e+00]
     [-2.22044605e-16  1.00000000e+00 -5.55111512e-17]
     [-2.77555756e-17  0.00000000e+00  1.00000000e+00]]
    [[ 0.21276596  0.0212766  -0.31914894]
     [-0.29787234  0.17021277  0.44680851]
     [ 0.06382979  0.10638298  0.40425532]]
    [[ 1.00000000e+00 -2.08166817e-16  5.55111512e-16]
     [-1.66533454e-16  1.00000000e+00  3.33066907e-16]
     [ 1.66533454e-16  8.32667268e-17  1.00000000e+00]]
    '''
    ```

**응용**

* 연립 방정식 풀기

  * `np.linalg.pinv`를 이용하면 연립방정식의 해를 구할 수 있다. 

  ![image-20220119115006710](https://user-images.githubusercontent.com/70505378/150055217-5a13cccc-ce7e-49b1-9d4b-d69e60d4f494.png)

  * `np.linalg.pinv`를 이용하면 데이터를 선형 모델로 해석하는 **선형 회귀식**을 찾을 수 있다. 

  ![image-20220119115141877](https://user-images.githubusercontent.com/70505378/150055221-bff6b7cf-f2bb-4b15-8d61-6c43c88dc21c.png)

  ```python
  # Scikit Learn을 활용한 회귀분석
  from sklearn.linear_model import LinearRegression
  model = LinearRegression()
  model.fit(X, y)
  y_test = model.predict(x_test)
  
  # Moore-Penrose 역행렬
  X_ = np.array([np.append(x,[1]) for x in X])
  beta = np.linalg.pinv(X_) @ y
  t_test = np.append(x,[1]) @ beta
  ```

  

<br>

### 4. 경사하강법 (순한맛)

**미분**

* **미분**은 **변수의 움직임에 따른 함수값의 변화를 측정하기 위한 도구**로 최적화에서 제일 많이 사용하는 기법이다. 

  ```python
  import sympy as sym
  from sympy.abc import x
  
  sym.diff(sym.poly(x**2 + 2*x + 3),x)
  # Poly(2𝑥+2,𝑥,𝑑𝑜𝑚𝑎𝑖𝑛=ℤ)
  ```

* 미분은 함수 f의 주어진 점 (x, f(x))에서의 **접선의 기울기**를 구한다. 

  * 한 점에서 접선의 기울기를 알면 어느 방향으로 점을 움직여야 함수값이 증가/감소하는지 알 수 있다. 
  * **미분값을 더하면 '경사상승법'**이라 하며, 함수의 **극댓값**의 위치를 구할 때 사용한다. (목적함수 최대화)

  ![image-20220119134819687](https://user-images.githubusercontent.com/70505378/150077661-2655dee2-debc-4cdc-bcff-dc71318ad39d.png)

  * **미분값을 빼면 '경사하강법'**이라 하며 함수의 **극솟값**의 위치를 구할 때 사용한다. (목적함수 최소화)

  ![image-20220119134943930](https://user-images.githubusercontent.com/70505378/150077664-9418387e-8c0c-4ee8-930a-b8373ca1198e.png)

  * **극값에서는 미분값이 0**이므로 더 이상 업데이트가 일어나지 않는다. 

* 경사하강법: 알고리즘

```python
# pseudo code
# Input: gradient, init, lr, eps, Output: var
var = init
grad = gradient(var)
while(bas(grad) > eps): # 종료 조건
    var = var - lr * grad # x 값 갱신
    grad = gradient(var)
```

```python
# python code
def func(val):
    fun = sym.poly(x**2 + 2*x + 3)
    return fun.subs(x, val), fun

def func_gradient(fun, val):
    _, function = fun(val)
    diff = sym.diff(function, x)
    return diff.subs(x, val), diff

def gradient_descent(fun, init_point, lr_rate = 1e-2, epsilon = 1e-5):
    cnt = 0
    val = init_point
    diff, _ = func_gradient(fun, init_point)
    while np.abs(diff) > epsilon:
        val = val - lr_rate*diff
        diff, _ = func_gradient(fun, val)
        cnt += 1
        
    print(f"함수: {fun(val)[1]}, 연산횟수: {cnt}, 최소점: ({val},{fun(val)[0]})")
    
    
gradient_descent(fun=func, init_point=np.random.uniform(-2,2))
# 함수: Poly(x**2 + 2*x + 3, x, domain='ZZ'), 연산횟수: 632, 최소점: (-0.999995083760464,2.00000000002417)
```

**변수가 벡터라면?**

* 벡터가 입력인 다변수 함수의 경우 **편미분**을 사용한다. 

  ```python
  import sympy as sym
  from sympy.abc import x, y
  
  sym.diff(sym.poly(x**2 + 2*x*y + 3) + sym.cos(x + 2*y), x)
  # 2𝑥+2𝑦−sin(𝑥+2𝑦)
  ```

* 각 변수별로 편미분을 계산한 **그레디언트 벡터**를 이용하여 경사하강/경사상승법에 사용할 수 있다. 

  ![image-20220119135959609](https://user-images.githubusercontent.com/70505378/150077665-bb495cc7-cd9a-4f9a-8ed5-fa356d8916c5.png)

* 경사하강법: 알고리즘

```python
# Pseudo code
# Input: gradient, init, lr, eps, Output: var

var = init
grad = gradient(var)
while(norm(grad) > eps): # 벡터의 경우 절댓값 대신 노름(norm)을 계산해서 종료조건 설정
    var = var - lr * grad
    grad = gradient(var)
```

```python
# python code
def eval_(fun, val):
    val_x, val_y = val
    fun_eval = fun.subs(y, val_y)
    return fun_eval

def func_multi(val):
    x_, y_ = val
    func = sym.poly(x**2 + 2*y**2)
    return eval_(func, [x_, y_]), func

def func_gradient(fun, val):
    x_, y_ = val
    _, function = fun(val)
    diff_x = sym.diff(function, x)
    diff_y = sym.diff(function, y)
    grad_vec = np.array([eval_(diff_x, [x_, y_]), eval_(diff_y, [x_, y_])], dtype=float)
    return grad_vec, [diff_x, diff_y]

def gradient_descent(fun, init_point, lr_rate=1e-2, epsilon=1e-5):
    cnt = 0
    val = init_point
    diff, _ = func_gradient(fun, val)
    while np.linalg.norm(diff) > epsilon:
        val = val - lr_rate*diff
        diff, _ = func_gradient(fun, val)
        cnt += 1
        
    print(f"함수: {fun(val)[1]}, 연산횟수: {cnt}, 최소점: ({val},{fun(val)[0]})")
    
    
pt = [np.random.uniform(-2,2), np.random.uniform(-2,2)]
gradient_descent(fun=func_multi, init_point=pt)
```



<br>

### 4. 경사하강법 (매운맛)

**경사하강법을 이용한 선형 회귀**

앞서 **역행렬을 이용하면 선형회귀모델을 구할 수 있다**고 했다. 

**경사 하강법**을 이용하면 역행렬을 이용하지 않고 적절한 선형 모델을 찾을 수 있다. 

* 선형회귀의 목적식은 \|\|y − Xβ\|\|<sub>2</sub>이고 **이를 최소화하는 beta**를 찾아야 하므로 이에 대한 그레디언트 벡터를 구한다. 

  * 계산의 편의를 위해 목적식을 제곱한 항을 목적식으로 사용한다. 

  ![image-20220119141342983](https://user-images.githubusercontent.com/70505378/150077669-4d96609d-c9d5-49e7-b522-0e897bf3c9b5.png)

  * 이제 목적식을 최소화하는 beta를 구하는 경사하강법 알고리즘은 다음과 같다. 

  ![image-20220119141422702](https://user-images.githubusercontent.com/70505378/150077673-26e78fbc-0c86-4219-8216-586e450f312d.png)

* 경사하강법 기반 선형회귀 알고리즘

  * 종료 조건을 일정 횟수로 설정할 경우 **학습 횟수**와 **학습률**이 중요한 parameter가 된다. 두 값에 따라 적절한 모델을 찾을 수도, 찾지 못 할수도 있다. 

```python
# Pseudo code
# Input: X, y, lr, T, Output: beta

for t in range(T): # 종료조건을 일정 학습 횟수로 설정
    error = y - X * beta 
    grad = -transpose(X) @ error # 미분식
    beta = beta - lr * grad # beta 업데이트
```

```python
# Python code
X = np.array([[1,1], [1,2], [2,2], [2,3]])
y = np.dot(X, np.array([1,2])) + 3

beta_gd = [10.1, 15.1, -6.5] # [1,2,3]이 정답
X_ = np.array([np.append(x,[1]) for x in X]) # intercept 항 추가

for t in range(5000):
    error = y - X_ @ beta_gd
    # error = error / np.linalg.norm(error)
    grad = -np.transpose(X_) @ error
    beta_gd = beta_gd - 0.01*grad
    
print(beta_gd)
# [1.00000367 1.99999949 2.99999516]
```

**확률적 경사 하강법(Stochastic Gradient Descent, SGD)**

* 이론적으로 경사 하강법은 **미분가능하고 볼록한 함수**에 대해서는 **적절한 학습률과 학습 횟수 하에 수렴이 보장**된다. 

  * 특히 선형 회귀의 경우 목적식이 beta에 대해 볼록하기 때문에 수렴이 보장된다. 

* 하지만 **비선형회귀** 문제의 경우 목적식이 볼록하지 않을 수 있으므로 **수렴이 항상 보장되지는 않는다.**

  * 특히 딥러닝을 사용하는 경우 목적식은 대부분 볼록 함수가 아니다. 

* **확률적 경사 하강법**

  * 확률적 경사 하강법은 모든 데이터를 사용해서 업데이트 하는 대신, **데이터 한 개 또는 일부(미니 배치)를 활용하여 업데이트한다.**

  * SGD는 데이터의 일부를 가지고 파라미터를 업데이트 하기 때문에 연산자원을 좀 더 효율적으로 활용하는 데 도움이 된다. 

  * 미니 배치는 확률적으로 선택하므로 **목적식 모양이 바뀌게 된다.**

    * 따라서 최적화 과정에서 local minimum에 빠져서 grad = 0이 되더라도 탈출 할 수 있다. 

    ![image-20220119142539708](https://user-images.githubusercontent.com/70505378/150077675-d4f05fd0-8386-45ef-ba2a-0d1e2d6f8224.png)

  * SGD는 볼록이 아닌 목적식에서도 사용 가능하므로 경사하강법보다 **머신러닝 학습에 더 효율적**이다. 

  ![image-20220119142854277](https://user-images.githubusercontent.com/70505378/150077677-bb528f36-87ce-453d-8eb5-088bb450824b.png)







<br>

<br>

## 피어세션 정리

오늘 피어세션에서는 강의 내용에서 다룬 L1, L2 norm에 대한 이야기를 하였다. 

강의 상에서 두 노름을 사용하는 이유는 기하학적 특성이 다르고, 경우에 따라 서로 다른 것이 사용될 수 있다고 하였는데 그에 대한 자세한 용례는 소개해주지는 않으셨다. 

가중치 규제 시 Lasso에서는 L1 norm을, Ridge에서는 L2 norm을 사용한다는 것을 공유했으며, Lasso의 경우 가중치를 전체적으로 줄이는 효과가 있어 영향을 적게 주는 가중치가 먼저 소멸되어 feature selection의 효과가 있고 Ridge의 경우 영향이 큰 가중치가 더 빠르게 줄어들어 overfitting을 방지하는 효과가 있다는 것을 다시 한 번 remind했다. 

또한 과제 중 있었던 문자열 처리에 있어 애매한 부분에 대한 이야기를 나누었고, 애매함이 있다는 것에는 동의를 하였지만 다들 Testcase를 통과함에 있어서는 큰 어려움을 겪지 않아 정리하고 넘어갈 수 있었다. 

또한 평소와 같이 다음 날 강의와 퀴즈에 대한 진도를 조절하고 마쳤다. 

<br>

<br>

## 과제 수행 과정/결과물



<br>

<br>

## 학습 회고

3일차에 접어들었고, 조금이지만 점점 이 패턴에 익숙해지고 있는 듯한 느낌이 든다. 

강의를 듣고 다른 캠퍼 분들과 이야기를 나누는 것이 재밌고, 앞으로도 이와 같이 순조롭게 캠프가 진행되었으면 하는 바람이다. 

또한 처음으로 멘토링 타임이 있었는데, 멘토 분께서 좋은 말씀들을 많이 해주시고 질문에 대한 답변도 성심성의껏 해주셔서 정말 많은 도움이 되었다. 앞으로도 많은 도움을 얻을 수 있었으면 좋겠다. 
