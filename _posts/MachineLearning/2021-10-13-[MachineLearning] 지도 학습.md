---
layout: single
title: "[Machine Learning] 지도 학습"
categories: ['AI', 'MachineLearning']
toc: true
toc_sticky: true
tag: ['SupervisedLearning', 'Classification', 'Regression']
---

<br>

## 기계학습의 종류

* `지도 학습`: 입력(**문제**) - 출력(**답**)의 데이터들로부터 새로운 입력에 대한 출력을 결정할 수 있는 패턴 추출
* `비지도 학습`: **출력**에 대한 정보가 **없는 데이터**로부터 필요한 패턴 추출
* `반지도 학습`: **일부 학습 데이터**만 **출력값**이 주어진 상태에서 일반화한 패턴 추출
* `강화 학습`: 출력에 대한 정확한 정보를 제공하지는 않지만, **평가 정보**(reward)는 주어지는 문제에 대해 **각 상태**에서의 **행동**(action)을 결정

<br>

## 분류

데이터들을 정해진 몇 개의 부류(class)로 대응시키는 문제

![image-20211013212115841](https://user-images.githubusercontent.com/70505378/137133925-6eb97ffc-5bb6-4c20-8e8c-3d1ac8d49780.png)

**분류 문제의 학습**

* **학습 데이터**를 잘 **분류**할 수 있는 **함수**를 찾는 것
* 함수의 형태는 **수학적 함수**일 수도 있고, **규칙**일 수도 있음

**분류기 (classifier)**

* 학습된 함수를 이용하여 데이터를 분류하는 프로그램

<br>

### 분류기 학습 알고리즘

* 결정트리 알고리즘
* K-근접 알고리즘
* 다층 퍼셉트론 신경망
* 딥러닝 알고리즘
* 서포트 벡터 머신
* 에이다부스트, 그래디언트 부스트
* 랜덤 포레스트
* 확률 그래프 모델

<br>

### 이상적인 분류기

`이상적인 분류기`란 학습에 사용되지 않은, 즉 테스트 데이터에 대해 좋은 성능을 보이는(분류를 잘 하는) 분류기를 말합니다. 

이런 분류기를 `일반화 능력이 좋다`고 합니다. 

<br>

### 데이터의 구분

* **학습 데이터**
  * 분류기를 학습하는데 사용하는 데이터 집합
  * 학습 데이터가 많을 수록 유리
* **테스트 데이터**
  * 학습된 모델의 성능을 평가하는데 사용하는 데이터 집합
  * 학습에 사용되지 않은 데이터여야 함
* **검증 데이터**
  * 학습 과정에서 **학습을 중단할 시점**을 결정하기 위해 사용하는 데이터 집합

<br>

### 과적합과 부적합

* **과적합** (과대적합)
  * **학습 데이터**에 대해서 **지나치게 잘 학습**된 상태
  * 데이터는 **오류**나 **잡음**을 포함할 수 있기 때문에, 학습 데이터에 대해 매우 높은 성능을 보이더라도 **학습되지 않은 데이터**에 대해 **좋지 않은 성능**을 보일 수 있음
* **부적합** (과소적합)
  * 학습 데이터를 충분히 학습하지 않은 상태
  * 모델의 복잡도가 너무 낮은 상태

![image-20211013212825846](https://user-images.githubusercontent.com/70505378/137133929-ba876f71-06af-4892-b3d3-84c3798b749c.png)

<br>

#### 과적합 회피 방법

* **학습 데이터**에 대한 **성능**
  * **학습**을 **진행**할 수록 오류 **개선** 경향
  * 지나치게 학습이 진행되면 과적합 발생
* 학습 과정에서 별도의 **검증 데이터** (validation data)에 대한 성능 평가
  * 검증 데이터에 대한 오류가 감소하다가 증가하는 시점에 학습 중단

<br>

### 분류기의 성능 평가

* **정확도**
  * 얼마나 정확하게 분류하는가
  * 정확도 = (옳게 분류한 데이터 개수) / (전체 데이터 개수)
  * **테스트 데이터**에 대한 정확도를 분류기의 정확도로 사용
* 정확도가 높은 분류기를 학습하기 위해서는 **많은 학습 데이터**를 사용하는 것이 유리
* **학습 데이터와 테스트 데이터는 겹치기 않도록 해야 함**

<br>

#### 데이터가 부족한 경우의 성능 평가

학습에 사용할 데이터가 부족한 경우, 별도로 테스트 데이터를 확보하면 비효율적입니다. 

따라서 이런 경우, 가능하면 많은 데이터를 학습에 사용하면서 성능을 평가하는 방법이 필요합니다. 

**K-겹 교차 검증 (K-fold cross-validation)**

* 전체 데이터를 K 등분
* **각 등분**을 한번씩 **테스트 데이터**로 사용하여, 성능 평가를 하고 **평균값** 선택

![image-20211013213350945](https://user-images.githubusercontent.com/70505378/137133933-8b1961fc-c849-4cb9-a423-86596b7090bb.png)

<br>

#### 이진 분류기의 성능 평가

`이진 분류기`란 두 개의 부류만을 갖는 데이터에 대한 분류기를 말합니다. 

##### 혼돈 행렬 (Confusion Matrix)

![image-20211014205944348](https://user-images.githubusercontent.com/70505378/137315435-7fd506b7-9cd6-49a2-9eb9-3946fa714833.png)

* 재현율(recall)/민감도(sensitivity)/진양성율(true positiive rate)
  * 양성 데이터 중 맞춘 비율
  * **TP / (TP + FN)**
* 특이도(specificity)/진음성율(true negative rate)
  * 음성 데이터 중 맞춘 비율
  * **TN / (FP + TN)**
* 정밀도(precision, positive predictive value)
  * 양성 예측 중 맞춘 비율
  * **TP / (TP + FP)**
* 음성 예측도(negative predictive value)
  * 음성 예측 중 맞춘 비율
  * **TN / (TN + FN)**
* 위양성율(false positive rate)
  * 음성 데이터 중 틀린 비율
  * **FP / (FP + TN)** = 1 - (specificity)
* 위발견율(false discovery rate)
  * 양성 예측 중 틀린 비율
  * **FP / (TP + FP)** = 1 - (precision)
* 정확도(accuracy)
  * 전체 데이터 중 맞춘 비율
  * **(TP + TN) / (TP + FP + TN + FN)**
* F1 측도(F1 Score)
  * 정밀도와 재현율의 조화 평균
  * **(2 * precision * recall) / (precision + recall)**

<br>

##### ROC와AUC

* `ROC 곡선` (Receiver Operating Characteristic Curve)
  * 부류 판정 임계 값에 따른 (위양성율, 재현율) 그래프
* `AUC 곡선` (Area Under the Curve)
  * ROC 곡선에서 곡선 아래 부분의 면적
  * 클수록 바람직

![image-20211014210935176](https://user-images.githubusercontent.com/70505378/137315437-03323233-aaa0-4f61-9949-c7970781a359.png)

**(a) - 성능: D > A > B > C**

**(b) - 성능: 1 > 2**

<br>

<br>

### 불균형 데이터 문제

* **특정 부류**에 속하는 **학습 데이터**의 개수가 다른 부류에 비하여 **지나치게 많은 경우**
* **정확도**에 의한 성능 평가는 **무의미**할 수 있음
  * 예. A 부류의 데이터가 전체의 99%인 경우, 분류기의 출력을 항상 A 분류로 하더라도 정확도는 99%가 됨. 

![image-20211014211140631](https://user-images.githubusercontent.com/70505378/137315439-dc7b0290-2e0f-4cb1-8ea9-ceaea9aaf016.png)

* **대응 방안**
  * 가중치를 고려한 정확도 척도 사용
  * 재현율, 정밀도 등의 다른 평가 지표 사용
  * 많은 학습데이터를 갖는 부류에서 재표본추출 (re-sampling, undersampling)
  * 적은 학습데이터를 갖는 부류에서 인공적인 데이터 생성 (undersampling)

<br>

#### SMOTE 알고리즘

`SMOTE (Synthetic Minority Over-sampling TEchnique)` 알고리즘은 **빈도가 낮은 부류의 학습 데이터를 인공적으로 생성**해내는 방법입니다. 

1. 임의로 낮은 빈도 부류의 학습 데이터 x 선택
2. x의 k-근접 이웃(k-nearest neighbor, KNN)인 같은 부류의 데이터 선택
3. k-근접 이웃 중에 무작위로 하나 y를 선택
4. x와 y를 연결하는 직선 상의 무작위 위치에 새로운 데이터 생성

![image-20211014211500127](https://user-images.githubusercontent.com/70505378/137315446-80ad6973-c3b0-42a3-8ed4-3b8c28c3582c.png)

<br>

<br>

## 회귀

`회귀 (Regression)` 문제는 **학습 데이터에 부합**되는 **출력 값**이 **실수**인 함수를 찾는 문제입니다. 

![image-20211014211942555](https://user-images.githubusercontent.com/70505378/137318180-81f969da-bb60-4d17-aa87-dd8c2f2e43a9.png)

<br>

### 회귀에서의 성능

회귀의 성능 지표로는 여러가지가 있는데, 그 중 가장 대표적으로 `MSE(Mean Squared Error)`를 사용합니다. 

![image-20211014212044866](https://user-images.githubusercontent.com/70505378/137318183-6ecfee27-2824-4d09-a216-1f295d51577a.png)

이 성능은 모델의 종류(함수의 종류)에 영향을 받습니다. 

<br>

### 회귀의 과적합과 부적합

* `과적합`(과대적합, 과잉적합): 지나치게 복잡한 모델(함수) 사용
* `부적합`(과소적합): 지나치게 단순한 모델 사용

![image-20211014212217022](https://user-images.githubusercontent.com/70505378/137318185-0bbad167-e89f-4040-8119-8062e28dc9fe.png)

#### 회귀의 과적합 대응 방법

회귀 문제에서 과적합에 대응하는 방법으로는 `가중치 규제` 방법이 있습니다. 

이는 모델의 복잡도를 성능 평가에 반영하는 것으로, 모델이 지나치게 복잡해지지 않도록 규제하는 것입니다. 

> <span style="color:blue">**목적 함수 = 손실 함수 + (가중치)\*(모델 복잡도)**</span>

**가중치 규제** 방법에는 크게 `L1 규제(Lasso)`, `L2 규제(Ridge)`, `엘라스틱넷 규제`가 있습니다.  

* L1 규제

![image-20211014212812407](https://user-images.githubusercontent.com/70505378/137318186-11173188-9d6f-47d2-87e1-b395eb0f8093.png)

* L2 규제

![image-20211014212829930](https://user-images.githubusercontent.com/70505378/137318187-98651528-205e-47a9-a7e6-85192d98e08c.png)

* 엘라스틱 넷 규제

![image-20211014212854706](https://user-images.githubusercontent.com/70505378/137318190-80e27844-e7b6-43e6-8593-b2da9f97da37.png)

<br>

<br>

### 로지스틱 회귀

로지스틱 회귀는 회귀의 출력 값에 `로지스틱 함수(시그모이드 함수)` 적용함으로써 점수((-INF, INF))를 확률([0, 1])로 변환합니다. 이 때 확률은 해당 데이터가 해당 클래스에 속할 확률입니다. 

즉, 로지스틱 회귀는 분류기로 사용될 수 있습니다. 

![image-20211014213155140](https://user-images.githubusercontent.com/70505378/137318192-49263fad-dbb6-4236-88cb-9deb5e1004d3.png)

<br>

로지스틱 회귀에서는 분류에 사용되는 손실 함수인 **크로스 엔트로피 손실 함수(Cross-Entropy Loss)**가 사용되며, 그 중 이진 분류에서는 **Binary Cross-Entropy**가 사용됩니다. 

![image-20211014213345192](https://user-images.githubusercontent.com/70505378/137318195-2ec96e5c-57a6-4ca1-810d-eb2ba0be3c76.png)

<br>















