---
layout: single
title: "[Machine Learning] 분류"
categories: ['AI', 'MachineLearning']
toc: true
toc_sticky: true
tag: ['Classification']
---

<br>

## 기계학습의 종류

* `지도 학습`: 입력(**문제**) - 출력(**답**)의 데이터들로부터 새로운 입력에 대한 출력을 결정할 수 있는 패턴 추출
* `비지도 학습`: **출력**에 대한 정보가 **없는 데이터**로부터 필요한 패턴 추출
* `반지도 학습`: **일부 학습 데이터**만 **출력값**이 주어진 상태에서 일반화한 패턴 추출
* `강화 학습`: 출력에 대한 정확한 정보를 제공하지는 않지만, **평가 정보**(reward)는 주어지는 문제에 대해 **각 상태**에서의 **행동**(action)을 결정

<br>

## 분류

데이터들을 정해진 몇 개의 부류(class)로 대응시키는 문제

![image-20211013212115841](https://user-images.githubusercontent.com/70505378/137133925-6eb97ffc-5bb6-4c20-8e8c-3d1ac8d49780.png)

**분류 문제의 학습**

* **학습 데이터**를 잘 **분류**할 수 있는 **함수**를 찾는 것
* 함수의 형태는 **수학적 함수**일 수도 있고, **규칙**일 수도 있음

**분류기 (classifier)**

* 학습된 함수를 이용하여 데이터를 분류하는 프로그램

<br>

### 분류기 학습 알고리즘

* 결정트리 알고리즘
* K-근접 알고리즘
* 다층 퍼셉트론 신경망
* 딥러닝 알고리즘
* 서포트 벡터 머신
* 에이다부스트, 그래디언트 부스트
* 랜덤 포레스트
* 확률 그래프 모델

<br>

### 이상적인 분류기

`이상적인 분류기`란 학습에 사용되지 않은, 즉 테스트 데이터에 대해 좋은 성능을 보이는(분류를 잘 하는) 분류기를 말합니다. 

이런 분류기를 `일반화 능력이 좋다`고 합니다. 

<br>

### 데이터의 구분

* **학습 데이터**
  * 분류기를 학습하는데 사용하는 데이터 집합
  * 학습 데이터가 많을 수록 유리
* **테스트 데이터**
  * 학습된 모델의 성능을 평가하는데 사용하는 데이터 집합
  * 학습에 사용되지 않은 데이터여야 함
* **검증 데이터**
  * 학습 과정에서 **학습을 중단할 시점**을 결정하기 위해 사용하는 데이터 집합

<br>

### 과적합과 부적합

* **과적합** (과대적합)
  * **학습 데이터**에 대해서 **지나치게 잘 학습**된 상태
  * 데이터는 **오류**나 **잡음**을 포함할 수 있기 때문에, 학습 데이터에 대해 매우 높은 성능을 보이더라도 **학습되지 않은 데이터**에 대해 **좋지 않은 성능**을 보일 수 있음
* **부적합** (과소적합)
  * 학습 데이터를 충분히 학습하지 않은 상태
  * 모델의 복잡도가 너무 낮은 상태

![image-20211013212825846](https://user-images.githubusercontent.com/70505378/137133929-ba876f71-06af-4892-b3d3-84c3798b749c.png)

<br>

#### 과적합 회피 방법

* **학습 데이터**에 대한 **성능**
  * **학습**을 **진행**할 수록 오류 **개선** 경향
  * 지나치게 학습이 진행되면 과적합 발생
* 학습 과정에서 별도의 **검증 데이터** (validation data)에 대한 성능 평가
  * 검증 데이터에 대한 오류가 감소하다가 증가하는 시점에 학습 중단

<br>

### 분류기의 성능 평가

* **정확도**
  * 얼마나 정확하게 분류하는가
  * 정확도 = (옳게 분류한 데이터 개수) / (전체 데이터 개수)
  * **테스트 데이터**에 대한 정확도를 분류기의 정확도로 사용
* 정확도가 높은 분류기를 학습하기 위해서는 **많은 학습 데이터**를 사용하는 것이 유리
* **학습 데이터와 테스트 데이터는 겹치기 않도록 해야 함**

<br>

#### 데이터가 부족한 경우의 성능 평가

학습에 사용할 데이터가 부족한 경우, 별도로 테스트 데이터를 확보하면 비효율적입니다. 

따라서 이런 경우, 가능하면 많은 데이터를 학습에 사용하면서 성능을 평가하는 방법이 필요합니다. 

**K-겹 교차 검증 (K-fold cross-validation)**

* 전체 데이터를 K 등분
* **각 등분**을 한번씩 **테스트 데이터**로 사용하여, 성능 평가를 하고 **평균값** 선택

![image-20211013213350945](https://user-images.githubusercontent.com/70505378/137133933-8b1961fc-c849-4cb9-a423-86596b7090bb.png)

<br>

#### 이진 분류기의 성능 평가



<br>

### 불균형 데이터 문제

















