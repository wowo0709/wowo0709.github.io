---
layout: single
title: "[AITech] 2022ë…„ 1ì›” 27ì¼ í•™ìŠµ ë‚´ìš© ì •ë¦¬"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['íŒŒì´í† ì¹˜','MultiGPU','HyperparameterTuning', 'TrobleShooting']
---



<br>

## í•™ìŠµ ë‚´ìš© ì •ë¦¬

### Multi-GPU í•™ìŠµ

#### ê°œë… ì •ë¦¬

* `Single VS Multi`: 1ê°œ VS 2ê°œ ì´ìƒ
* `GPU VS Node`: GPU VS ì»´í“¨í„°
* `Single Node Single GPU`: ì»´í“¨í„° 1ëŒ€ì— GPU 1ê°œ
* `Single Node Multi GPU`: ì»´í“¨í„° 1ëŒ€ì— GPU ì—¬ëŸ¬ ê°œ
* `Multi Node Multi GPU`: ì»´í“¨í„° ì—¬ëŸ¬ ëŒ€ì— GPU ì—¬ëŸ¬ ëŒ€

#### Model Parallel

ë‹¤ì¤‘ GPUì— í•™ìŠµì„ ë¶„ì‚°í•˜ëŠ” ë°©ë²•ì—ëŠ” **ëª¨ë¸ì„ ë‚˜ëˆ„ëŠ” ë°©ë²•**ê³¼ **ë°ì´í„°ë¥¼ ë‚˜ëˆ„ëŠ” ë°©ë²•**ì´ ìˆë‹¤. 

ëª¨ë¸ì„ ë‚˜ëˆ„ëŠ” ê²ƒì€ ë¹„êµì  ì˜ˆì „ë¶€í„° ì‚¬ìš©í•´ì˜¨ ê¸°ë²•(AlexNet)ì´ì§€ë§Œ, ëª¨ë¸ì˜ ë³‘ëª©ì´ë‚˜ íŒŒì´í”„ë¼ì¸ì˜ ì–´ë ¤ì›€ìœ¼ë¡œ ì¸í•´ ëª¨ë¸ ë³‘ë ¬í™”ëŠ” ê³¡ë‚œì´ë„ ê³¼ì œì´ë‹¤. 

![image-20220128111218264](https://user-images.githubusercontent.com/70505378/151489744-cbbf842e-76e7-4dec-9281-932bcd8e3764.png)

* ì˜ˆì‹œ ì½”ë“œ

```python
class ModelParallelResNet50(ResNet):
    def __init__(self, *args, **kwargs):
        super(ModelParallelResNet50, self).__init__(
        	Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs)
        
        self.seq1 = nn.Sequential(
        	self.conv1, self.bn1, self.relu, self.maxpool, self.layer1, self.layer2
        ).to('cuda:0')
        
        self.seq2 = nn.Sequential(
        	self.layer3, self.layer4, self.avgpool,
        ).to('cuda:1')
        
        self.fc.to('cuda:1')
        
    def forward(self, x):
        x = self.seq2(self.seq1(x).to('cuda:1'))
        return self.fc(x.view(x.size(0), -1))
```





#### Data Parallel

Data Parallel ê¸°ë²•ì€ ë°ì´í„°ë¥¼ ë‚˜ëˆ  GPUì— í• ë‹¹í•œ í›„ ê²°ê³¼ì˜ í‰ê· ì„ ì·¨í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. 

![image-20220128112840914](https://user-images.githubusercontent.com/70505378/151489746-44d3d6e0-0f29-449f-b502-ed1e06867d4b.png)

ìœ„ ê·¸ë¦¼ì„ ë³´ë©´ 'Forward ì‹œ ë¶„ë°°ê°€ ì¼ì–´ë‚˜ê³  Backwardê°€ ì™„ë£Œëœ í›„ ì·¨í•©'í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ì¤‘ê°„ì— Forwardì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ GPUê°€ ì·¨í•©í•œ í›„ gradientë¥¼ ê³„ì‚°í•˜ê³ , ë‹¤ì‹œ ë¶„ë°°í•˜ëŠ” ê³¼ì •**ì´ ì¼ì–´ë‚˜ê²Œ ë©ë‹ˆë‹¤. 

ì´ëŠ” **Global Interpreter Lock**ì´ë¼ê³  í•˜ëŠ” íŒŒì´ì¬ì˜ ë©€í‹° í”„ë¡œì„¸ì‹± ìƒì˜ ì œì•½ ì‚¬í•­ ë•Œë¬¸ì´ë¼ê³  í•©ë‹ˆë‹¤. 

ìœ„ì™€ ê°™ì€ Data Parallel ê¸°ë²•ì€ íŒŒì´í† ì¹˜ì—ì„œ ì œê³µí•˜ëŠ” DataParallel í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨íˆ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
parallel_model = torch.nn.DataParallel(model) # ì´ê²Œ ì „ë¶€!!

# Forward ~ Loss Computation
predictions = parallel_model(inputs) # Forward pass on multi-GPUs
loss = loss_function(predictions, labels) # Compute loss function

# Gradient Backward propagation
loss.mean().backward() # Average GPU-losses + backward pass
optimizer.step() # Optimizer step

predictions = parallel_model(inputs) # Forward pass with new parameters
```

ê·¸ëŸ°ë° `DataParallel` í´ë˜ìŠ¤ëŠ” ìœ„ì—ì„œ ë§í–ˆë“¯ì´, ë‹¨ìˆœíˆ ë°ì´í„°ë¥¼ ë¶„ë°°í•œ í›„ í‰ê· ì„ ì·¨í•˜ê³  ë‹¤ì‹œ ë¶„ë°°ë¥¼ í•´ì£¼ëŠ” ë™ì‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 

ì´ëŠ” **GPU ì‚¬ìš© ë¶ˆê· í˜• ë¬¸ì œ**ë‚˜ **Batch ì‚¬ì´ì¦ˆ ê°ì†Œ(ì·¨í•©í•˜ëŠ” í•˜ë‚˜ì˜ GPUì˜ ë³‘ëª©)** ë“±ì˜ ë¬¸ì œë¥¼ ì•¼ê¸°í•©ë‹ˆë‹¤. 

<br>

ì´ë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ `DistributedDataParallel` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê³ , í•´ë‹¹ í´ë˜ìŠ¤ëŠ” **ê° CPUë§ˆë‹¤ ê°œë³„ processë¥¼ ìƒì„±í•˜ì—¬ GPUì— í• ë‹¹**í•¨ìœ¼ë¡œì¨ **ì¤‘ê°„ì— ì·¨í•©í•˜ëŠ” ê³¼ì •ì„ ì—†ì•¨ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ì¡°ê¸ˆ ë” ë³µì¡í•˜ì§€ë§Œ ë›°ì–´ë‚œ ë³‘ë ¬í™” íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
train_sampler = torch.utils.data.distributed.DistributedSampler(train_data)
shuffle = False
pin_memory = True

trainloader = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=True
										pin_memory=pin_memory, num_workers=3,
										shuffle=shuffle, sampler=train_sampler)

def main():
    n_gpus = torch.cuda.device_count()
    torch.multiprocessing.spawn(main_worker, nprocs=n_gpus, args=(n_gpus, ))
    
def main_worker(gpu, n_gpus):
    image_size = 224
    batch_size = 512
    num_worker = 8
    epochs = ...
    
    batch_size = int(batch_size / n_gpus)
    num_worker = int(num_worker / n_gpus)
    # ë©€í‹° í”„ë¡œì„¸ì‹± í†µì‹  ê·œì•½ ì •ì˜
    torch.distributed.init_process_group(
    		backend='ncclâ€™ , init_method='tcp://127.0.0.1:2568â€™ , world_size=n_gpus, rank=gpu)
    
    model = MODEL
    # Distributed data parallel ì •ì˜
    torch.cuda.set_device(gpu)
    model = model.cuda(gpu)
    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu])
```

 âœ‹ íŒŒì´ì¬ì˜ ë©€í‹°í”„ë¡œì„¸ì‹± ì½”ë“œ

```python
from multiprocessing import Pool

def f(x):
	return x*x

if __name__ == '__main__':
    with Pool(5) as p:
        print(p.map(f, [1, 2, 3]))
```

<br>

### Hyperparameter Tuning

ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°ì—ëŠ” í¬ê²Œ ë‹¤ìŒì˜ 3ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. 

1. ëª¨ë¸ì˜ êµ¬ì¡° ê°œì„ : í˜„ì‹¤ì ìœ¼ë¡œ í° ë³€í™”ë¥¼ ë§Œë“¤ê¸° ì–´ë µë‹¤. 
2. ë°ì´í„° ì¦ê°•/ë³´ê°•: ê°€ì¥ ì¤‘ìš”í•˜ë©´ì„œ í° íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤. 
3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹: ì•„ì£¼ í° ì°¨ì´ë¥¼ ì¼ìœ¼í‚¤ì§€ëŠ” ì•Šì§€ë§Œ ì‹œë„í•´ ë³¼ ë§Œ í•˜ë‹¤. 

ì´ ì¤‘ **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**ì€ ì‚¬ì‹¤ ì´ì „ì—ëŠ” ê·¸ ê°’ì— ì˜í•´ ì„±ëŠ¥ì´ í¬ê²Œ ì¢Œìš°ë  ë•Œë„ ìˆì—ˆì§€ë§Œ, ìš”ì¦˜ì€ ê·¸ë ‡ì§€ëŠ” ì•Šë‹¤ê³  í•©ë‹ˆë‹¤. 

í•˜ì§€ë§Œ learning rate, ëª¨ë¸ì˜ í¬ê¸°, batch size, optimizer ë“± ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ íŠœë‹í•˜ëŠ” ë°©ë²•ì€ **ë§ˆì§€ë§‰ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¡°ê¸ˆ ë” ëŒì–´ì˜¬ë¦¬ê³  ì‹¶ì„ ë•Œ** ì‚¬ìš©í•´ ë³¼ ë§Œí•œ ë°©ë²•ì…ë‹ˆë‹¤. 

í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ ë°©ë²•ì—ëŠ” ì „í†µì ìœ¼ë¡œ ì‚¬ìš©ë˜ì–´ ì˜¨ **grid search**ì™€ **random search**ê°€ ìˆìœ¼ë©°, ë³´í†µ random searchë¡œ íŠœë‹ì„ í•˜ë‹¤ê°€ ì„±ëŠ¥ì´ ì¢‹ì€ ë¶€ë¶„ì´ ë°œê²¬ë˜ë©´ ê·¸ ë¶€ë¶„ ë¶€ê·¼ì—ì„œ grid searchë¥¼ ìˆ˜í–‰í•˜ëŠ” ì‹ìœ¼ë¡œ ìˆ˜í–‰ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. 

![image-20220128115041782](https://user-images.githubusercontent.com/70505378/151489753-b580ccda-42df-428a-b598-dbe863baa8ec.png)

ìµœê·¼ì—ëŠ” ë‘ ë°©ë²• ì™¸ì— **ë² ì´ì§€ì•ˆ ê¸°ë²•**ë“¤ì´ ì£¼ë„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ì— ëŒ€í•´ `BOHB(Baesian Optimization Hyper Band) 2018`ì´ë¼ëŠ” ë…¼ë¬¸ì„ ì½ì–´ë³´ë©´ ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤. 

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ì´ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê³¼ì •ì„ ê°„ì†Œí™” ì‹œì¼œì£¼ëŠ” **Ray**ë¼ëŠ” ëª¨ë“ˆì— ëŒ€í•´ ì†Œê°œí•˜ê³  ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ë ¤í•©ë‹ˆë‹¤. 

#### Ray

* Multi-node multi processingë¥¼ ì§€ì›í•˜ë©° ML/DLì˜ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê°œë°œëœ ëª¨ë“ˆ
* ê¸°ë³¸ì ìœ¼ë¡œ í˜„ì¬ì˜ ë¶„ì‚° ë³‘ë ¬ ML/DL ëª¨ë“ˆì˜ í‘œì¤€
* Hyperparameter searchë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ëª¨ë“ˆ ì œê³µ

```python
data_dir = os.path.abspath("./data")
load_data(data_dir)
# 1. configì— search space ì§€ì •
config = {
    "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
    "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
    "lr": tune.loguniform(1e-4, 1e-1),
    "batch_size": tune.choice([2, 4, 8, 16])
}
# 2. í•™ìŠµ ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜ ì§€ì •
scheduler = ASHAScheduler(
                metric="loss", mode="min", max_t=max_num_epochs, grace_period=1,
                reduction_factor=2)
# 3. ê²°ê³¼ ì¶œë ¥ ì–‘ì‹ ì§€ì •
reporter = CLIReporter(metric_columns=["loss", "accuracy", "training_iteration"])
# 4. ë³‘ë ¬ ì²˜ë¦¬ ì–‘ì‹ìœ¼ë¡œ í•™ìŠµ ìˆ˜í–‰
result = tune.run(partial(train_cifar, data_dir=data_dir),
                resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
                config=config, num_samples=num_samples,
                scheduler=scheduler,
                progress_reporter=reporter)
```

Ray ëª¨ë“ˆì€ hyperparameter searchë¥¼ ìˆ˜í–‰í•  ë•Œ ì²˜ìŒì—ëŠ” ëª¨ë“  ê²½ìš°ë¡œ í•™ìŠµì„ ì‹œí–‰í•˜ë‹¤ê°€ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ ê²½ìš°ëŠ” ë” ì´ìƒ í•™ìŠµì„ ì‹œí–‰í•˜ì§€ ì•Šê³ , ì„±ëŠ¥ì´ ì¢‹ì€ ê²½ìš°ë“¤ë¡œë§Œ í•™ìŠµì„ ê³„ì† ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ ì ˆì•½í•©ë‹ˆë‹¤. 

![image-20220128115742600](https://user-images.githubusercontent.com/70505378/151489755-8a135c5e-865f-4a99-98c1-4c29fdab9608.png)



ë˜í•œ ì§€ë‚œ í¬ìŠ¤íŒ…ì—ì„œ ì†Œê°œí•œ wandb ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ê·¸ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê¸° ë”ìš± ì¢‹ê¸° ë•Œë¬¸ì— ë‘ ëª¨ë“ˆì„ í•¨ê»˜ í™œìš©í•˜ë©´ ì–´ë µì§€ ì•Šê²Œ hyperparameter tuningì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€í•©ë‹ˆë‹¤. 

<br>

### PyTorch Troubleshooting

ì´ ì„¹ì…˜ì—ì„œëŠ” ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ê°€ì¥ ë§ì´ ë§Œë‚˜ê²Œ ë˜ëŠ” ì—ëŸ¬ì´ì, í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ `OOM(Out of Memory)` ì—ëŸ¬ì— ëŒ€í•´ ì–˜ê¸°í•´ë³´ê³ ì í•©ë‹ˆë‹¤. 

**OOMì´ í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ ì´ìœ **

* ì™œ, ì–´ë””ì„œ ë°œìƒí–ˆëŠ”ì§€ ì•Œê¸° ì–´ë µë‹¤. 
* Error backtrackingì´ ì´ìƒí•œ ë°ë¡œ ê°„ë‹¤. 
* ë©”ëª¨ë¦¬ì˜ ì´ì „ ìƒí™©ì˜ íŒŒì•…ì´ ì–´ë µë‹¤. 

OOMì„ í•´ê²°í•˜ê¸° ìœ„í•´ ê°€ì¥ ì‰½ê²Œ ì‹œë„í•´ ë³¼ ìˆ˜ ìˆëŠ” ë°©ë²•ìœ¼ë¡œëŠ” **Batch sizeë¥¼ ì¤„ì´ëŠ” ì‹œë„**ê°€ ìˆìŠµë‹ˆë‹¤. ì•„, ê·¸ë¦¬ê³  batch sizeë¥¼ ì¡°ì •í•œ í›„ì—ëŠ” GPU clean(kernel restart) ê³¼ì •ì„ í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”!

#### OOM í•´ê²°ì„ ìœ„í•œ ë°©ë²•ë“¤

**torch.cuda.empty_cache()**

empty_cache() í•¨ìˆ˜ëŠ” ì‚¬ìš©ë˜ì§€ ì•Šê³  ìˆëŠ” GPU ìƒ cacheë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. (ê°€ë¹„ì§€ ì»¬ë ‰í„°ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)

ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ ê°€ìš© ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë©”ëª¨ë¦¬ ì£¼ì†Œì˜ ì°¸ì¡°ë¥¼ ëŠëŠ” del ê³¼ëŠ” êµ¬ë¶„ë©ë‹ˆë‹¤)

empty_cache() í•¨ìˆ˜ëŠ” í•™ìŠµ ì‹œì‘ ì „ì— í•œ ë²ˆ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤ê³  í•©ë‹ˆë‹¤ ^_^

```python
import torch
from GPUtil import showUtilization as gpu_usage

print("Initial GPU Usage")
gpu_usage()
'''
Initial GPU Usage
| ID | GPU | MEM |
------------------
| 0 | 0% | 0% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
GPU Usage after allcoating a bunch of Tensors
'''
tensorList = []
for x in range(10):
	tensorList.append(torch.randn(10000000,10).cuda())
print("GPU Usage after allcoating a bunch of Tensors")
gpu_usage()
'''
GPU Usage after allcoating a bunch of Tensors
| ID | GPU | MEM |
------------------
| 0 | 0% | 40% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
'''
del tensorList
print("GPU Usage after deleting the Tensors")
gpu_usage()
'''
GPU Usage after deleting the Tensors
| ID | GPU | MEM |
------------------
| 0 | 0% | 40% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
'''
torch.cuda.empty_cache()
print("GPU Usage after emptying the cache")
gpu_usage()
'''
GPU Usage after emptying the cache
| ID | GPU | MEM |
------------------
| 0 | 0% | 5% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
'''
```

**training loopì— tensorë¡œ ì¶•ì ë˜ëŠ” ë³€ìˆ˜ í™•ì¸**

tensorë¡œ ì²˜ë¦¬ë˜ëŠ” ë³€ìˆ˜ë“¤ì€ GPU ìƒì—ì„œ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ê³ , í•´ë‹¹ ë³€ìˆ˜ loop ì•ˆì— ì—°ì‚°ì´ ìˆì„ ë•Œ GPUì— computational graphë¥¼ ìƒì„±í•˜ë©´ì„œ ë©”ëª¨ë¦¬ë¥¼ ì ì‹í•´ê°‘ë‹ˆë‹¤. 

ë”°ë¼ì„œ ì´ëŸ° ê²½ìš°ì—ëŠ” 1-d tensorì˜ ê²½ìš° íŒŒì´ì¬ì˜ ê¸°ë³¸ ê°ì²´(int, float, list ë“±)ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬í•  ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤. 

```python
total_loss = 0

for x in range(10):
    # assume loss is computed
    iter_loss = torch.randn(3,4).mean()
    iter_loss.requires_grad = True
    # total_loss += iter_loss ëŒ€ì‹ , 
    iter_loss += iter_loss.item # ë˜ëŠ” float(iter_loss)
```

**del ëª…ë ¹ì–´ì˜ ì ì ˆí•œ ì‚¬ìš©**

í•„ìš”ê°€ ì—†ì–´ì§„ ë³€ìˆ˜ë¥¼ ì ì ˆíˆ ì‚­ì œí•˜ëŠ” ê²ƒë„ ë°©ë²•ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
for i in range(5):
    intermediate = f(input[i])
    result += g(intermediate)
    
del intermediate # del
output = h(result)
del result # del
return output
```

**ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì—¬ë³´ê¸°(1ë¡œ í•´ë³´ê¸°)**

**torch.no_grad()**

ëª¨ë¸ ì¶”ë¡  ì‹œì ì—ëŠ” ì—­ì „íŒŒ ê³¼ì •ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ, `torch.no_grad()` contextë¥¼ ì‚¬ìš©í•˜ì—¬ backward ê³¼ì •ìœ¼ë¡œ ì¸í•´ ì‚¬ìš©ë˜ëŠ” ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
with torch.no_grad(): # torch.no_grad()
    for data, target in test_loader:
        output = network(data)
        test_loss += F.nll_loss(output, target, size_average=False).item()
        pred = output.data.max(1, keepdim=True)[1]
        correct += pred.eq(target.data.view_as(pred)).sum()
```

**tensorì˜ precision ì¤„ì´ê¸°**

tensorì˜ float precisionì„ 8, 16bit ìˆ˜ì¤€ìœ¼ë¡œ ì¤„ì´ëŠ” ê²ƒë„ í•˜ë‚˜ì˜ ë°©ë²•ì…ë‹ˆë‹¤. 

ê·¸ëŸ¬ë‚˜ ì´ ë°©ë²•ì€ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆê³ , ë§¤ìš° í° ëª¨ë¸ì„ ëŒë¦¬ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ë©´ ê¶Œì¥ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— 'ìµœí›„ì˜ ìˆ˜ë‹¨' ì •ë„ë¡œ ìƒê°í•´ ë‘ëŠ” ê²ƒì´ ì¢‹ì„ ë“¯ í•©ë‹ˆë‹¤. 

<br>

ì´ì™¸ì—ë„ **CUDNN_STATUS_NOT_INIT**ì´ë‚˜ **device-side-assert** ë“±ì˜ ì—ëŸ¬ë„ cudaì™€ ê´€ë ¨í•˜ì—¬ OOMì˜ ì¼ì¢…ì´ë¼ê³  í•  ìˆ˜ ìˆê³ , ì—­ì‹œ ì ì ˆí•œ ì½”ë“œì˜ ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ì— ëŒ€í•´ ì°¸ê³ í•  ë§Œí•œ ë‚´ìš©ì€ ì•„ë˜ ì°¸ê³ ìë£Œ _GPU ì—ëŸ¬ ì •ë¦¬_ ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 





<br>

<br>

## ì°¸ê³  ìë£Œ

* **Multi-GPU**
  * [PyTorch Lightning Multi GPU í•™ìŠµ](https://pytorch-lightning.readthedocs.io/en/stable/advanced/multi_gpu.html)
  * [DDP Tutorial](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
* **Hyperparameter Tuning**
  * [Hyperparameter Tuning with Ray Tune](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)
* **PyTorch Troubleshooting**
  * [Pytorchì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” ì—ëŸ¬ ì§ˆë¬¸ë“¤](https://pytorch.org/docs/stable/notes/faq.html)
  * [OOMì‹œì— GPU ë©”ëª¨ë¦¬ flushí•˜ê¸°](https://discuss.pytorch.org/t/how-to-clean-gpu-memory-after-a-runtimeerror/28781)
  * [GPU ì—ëŸ¬ ì •ë¦¬](https://brstar96.github.io/shoveling/device_error_summary/)





<br>

<br>

## íšŒê³ 

ì˜¤ëŠ˜ë¡œì¨ í•œ ì£¼ ë™ì•ˆì˜ PyTorchì— ëŒ€í•œ í•™ìŠµì´ ëì´ ë‚¬ìŠµë‹ˆë‹¤. 

íŒŒì´í† ì¹˜ ê°œìš”ë¶€í„° ê¸°ë³¸ì  ì—°ì‚°ë“¤, nn.Module, Datasetê³¼ DataLoader, Transfer learningê³¼ Hyperparameter tuning, Multi-GPU, Trouble shooting ë“± ë‹¤ì–‘í•œ ë‚´ìš©ë“¤ì„ ë‹¤ë£¨ëŠ” ê²ƒì´ ì‰½ì§€ëŠ” ì•Šì•˜ì§€ë§Œ, ì ì ˆí•œ ì‹¤ìŠµê³¼ ê°œë… ë¬¸ì œë“¤ì´ ë³‘í–‰ëœ ê²ƒ ê°™ì•„ ë§ì€ ê²ƒì„ ë°°ìš¸ ìˆ˜ ìˆì—ˆë˜ í•œ ì£¼ì˜€ìŠµë‹ˆë‹¤. 

ì´ì „ê¹Œì§€ëŠ” íŒŒì´í† ì¹˜ë¥¼ ê±°ì˜ ì‚¬ìš©í•´ ë³¸ ê²½í—˜ì´ ì—†ê¸° ë•Œë¬¸ì— í•œ ì£¼ ë™ì•ˆì˜ í•™ìŠµë§Œìœ¼ë¡œëŠ” ë§ì€ ë¶€ë¶„ì„ ì»¤ë²„í•˜ê¸°ëŠ” ì–´ë µê² ì§€ë§Œ, ì•ìœ¼ë¡œ ì§ì ‘ ëª¨ë¸ì„ ë§Œë“¤ê³  í•™ìŠµ ì‹œí‚¤ê³ , ì„±ëŠ¥ì„ ê°œì„ í•˜ë ¤ëŠ” ì¼ë ¨ì˜ ê³¼ì •ê³¼ ë…¸ë ¥ì„ í†µí•´ ì•ìœ¼ë¡œ ë”ìš± ë” ìµìˆ™í•´ì§€ë¦¬ë¼ ìƒê°í•©ë‹ˆë‹¤. 

ë¬´ì—‡ë³´ë‹¤ ê° ë‚´ìš©ë“¤ì„ ì‚°ë°œì ìœ¼ë¡œ ë°°ìš°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ëª¨ë¸ì„ ë§Œë“¤ê³  í•™ìŠµì‹œí‚¤ëŠ” ì¼ë ¨ì˜ ê³¼ì •ì— ë”°ë¼ ìˆœì„œëŒ€ë¡œ í•œ ë¶€ë¶„ ì”© ë°°ìš°ëŠ” ê²ƒì´ ì „ì²´ íë¦„ì„ ì´í•´í•˜ëŠ” ë°ì—ë„ ë§ì€ ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤!!ğŸ˜ğŸ˜

í•œ ì£¼ ê°„ì˜ íŒŒì´í† ì¹˜ ëª¨ë¸ë§ ê³¼ì •ì„ ë°°ìš°ë©´ì„œ ê·¸ ê°„ì˜ íë¦„ì„ ê°„ë‹¨íˆ ì•„ë˜ì™€ ê°™ì´ ì •ë¦¬í•´ë³´ì•˜ìŠµë‹ˆë‹¤. 

* **ë°ì´í„° ì „ì²˜ë¦¬(Dataset, Transform, Compose)**
* **ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°(DataLoader, Sampler)**
* **ì‹ ê²½ë§ êµ¬ì„±(nn.Module, pretrained model)**
* **ì˜¤ì°¨í•¨ìˆ˜ ë° ìµœì í™” ê¸°ë²• ì„ íƒ(Loss, Optimizer, metrics)**
* **í•™ìŠµ ë° ì¶”ë¡  ì˜µì…˜ ì„¤ì •(transfer learning, hyperparameter tuning, multi-gpu, monitoring)**
* **í›ˆë ¨, ê²€ì¦(training, validating, troubleshooting)**

ë‹¤ìŒ ì£¼ë¶€í„° ì§„í–‰ë  ë‚´ìš©ë“¤ë„ ê¸°ëŒ€ê°€ ë§ì´ ë©ë‹ˆë‹¤ ğŸ˜Š

ì•ìœ¼ë¡œ ê³„ì† ì§€ì¹˜ì§€ ì•Šê³  ì˜ ë‚˜ì•„ê°”ìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤ ã…ã…

<br>

<br>
