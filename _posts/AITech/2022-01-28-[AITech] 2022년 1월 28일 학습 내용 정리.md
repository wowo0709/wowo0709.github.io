---
layout: single
title: "[AITech] 2022년 1월 27일 학습 내용 정리"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['파이토치','MultiGPU','HyperparameterTuning', 'TrobleShooting']
---



<br>

## 학습 내용 정리

### Multi-GPU 학습

#### 개념 정리

* `Single VS Multi`: 1개 VS 2개 이상
* `GPU VS Node`: GPU VS 컴퓨터
* `Single Node Single GPU`: 컴퓨터 1대에 GPU 1개
* `Single Node Multi GPU`: 컴퓨터 1대에 GPU 여러 개
* `Multi Node Multi GPU`: 컴퓨터 여러 대에 GPU 여러 대

#### Model Parallel

다중 GPU에 학습을 분산하는 방법에는 **모델을 나누는 방법**과 **데이터를 나누는 방법**이 있다. 

모델을 나누는 것은 비교적 예전부터 사용해온 기법(AlexNet)이지만, 모델의 병목이나 파이프라인의 어려움으로 인해 모델 병렬화는 곡난이도 과제이다. 

![image-20220128111218264](https://user-images.githubusercontent.com/70505378/151489744-cbbf842e-76e7-4dec-9281-932bcd8e3764.png)

* 예시 코드

```python
class ModelParallelResNet50(ResNet):
    def __init__(self, *args, **kwargs):
        super(ModelParallelResNet50, self).__init__(
        	Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs)
        
        self.seq1 = nn.Sequential(
        	self.conv1, self.bn1, self.relu, self.maxpool, self.layer1, self.layer2
        ).to('cuda:0')
        
        self.seq2 = nn.Sequential(
        	self.layer3, self.layer4, self.avgpool,
        ).to('cuda:1')
        
        self.fc.to('cuda:1')
        
    def forward(self, x):
        x = self.seq2(self.seq1(x).to('cuda:1'))
        return self.fc(x.view(x.size(0), -1))
```





#### Data Parallel

Data Parallel 기법은 데이터를 나눠 GPU에 할당한 후 결과의 평균을 취하는 방법입니다. 

![image-20220128112840914](https://user-images.githubusercontent.com/70505378/151489746-44d3d6e0-0f29-449f-b502-ed1e06867d4b.png)

위 그림을 보면 'Forward 시 분배가 일어나고 Backward가 완료된 후 취합'하는 것이 아니라, **중간에 Forward의 결과를 하나의 GPU가 취합한 후 gradient를 계산하고, 다시 분배하는 과정**이 일어나게 됩니다. 

이는 **Global Interpreter Lock**이라고 하는 파이썬의 멀티 프로세싱 상의 제약 사항 때문이라고 합니다. 

위와 같은 Data Parallel 기법은 파이토치에서 제공하는 DataParallel 클래스를 사용하여 간단히 구현할 수 있습니다. 

```python
parallel_model = torch.nn.DataParallel(model) # 이게 전부!!

# Forward ~ Loss Computation
predictions = parallel_model(inputs) # Forward pass on multi-GPUs
loss = loss_function(predictions, labels) # Compute loss function

# Gradient Backward propagation
loss.mean().backward() # Average GPU-losses + backward pass
optimizer.step() # Optimizer step

predictions = parallel_model(inputs) # Forward pass with new parameters
```

그런데 `DataParallel` 클래스는 위에서 말했듯이, 단순히 데이터를 분배한 후 평균을 취하고 다시 분배를 해주는 동작을 수행합니다. 

이는 **GPU 사용 불균형 문제**나 **Batch 사이즈 감소(취합하는 하나의 GPU의 병목)** 등의 문제를 야기합니다. 

<br>

이를 해결하는 방법으로 `DistributedDataParallel` 클래스를 사용할 수 있고, 해당 클래스는 **각 CPU마다 개별 process를 생성하여 GPU에 할당**함으로써 **중간에 취합하는 과정을 없앨 수 있습니다.**

사용하는 방법은 조금 더 복잡하지만 뛰어난 병렬화 효과를 볼 수 있습니다. 

```python
train_sampler = torch.utils.data.distributed.DistributedSampler(train_data)
shuffle = False
pin_memory = True

trainloader = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=True
										pin_memory=pin_memory, num_workers=3,
										shuffle=shuffle, sampler=train_sampler)

def main():
    n_gpus = torch.cuda.device_count()
    torch.multiprocessing.spawn(main_worker, nprocs=n_gpus, args=(n_gpus, ))
    
def main_worker(gpu, n_gpus):
    image_size = 224
    batch_size = 512
    num_worker = 8
    epochs = ...
    
    batch_size = int(batch_size / n_gpus)
    num_worker = int(num_worker / n_gpus)
    # 멀티 프로세싱 통신 규약 정의
    torch.distributed.init_process_group(
    		backend='nccl’ , init_method='tcp://127.0.0.1:2568’ , world_size=n_gpus, rank=gpu)
    
    model = MODEL
    # Distributed data parallel 정의
    torch.cuda.set_device(gpu)
    model = model.cuda(gpu)
    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu])
```

 ✋ 파이썬의 멀티프로세싱 코드

```python
from multiprocessing import Pool

def f(x):
	return x*x

if __name__ == '__main__':
    with Pool(5) as p:
        print(p.map(f, [1, 2, 3]))
```

<br>

### Hyperparameter Tuning

모델의 성능을 높이는 데에는 크게 다음의 3가지 방법이 있습니다. 

1. 모델의 구조 개선: 현실적으로 큰 변화를 만들기 어렵다. 
2. 데이터 증강/보강: 가장 중요하면서 큰 효과를 볼 수 있다. 
3. 하이퍼파라미터 튜닝: 아주 큰 차이를 일으키지는 않지만 시도해 볼 만 하다. 

이 중 **하이퍼파라미터 튜닝**은 사실 이전에는 그 값에 의해 성능이 크게 좌우될 때도 있었지만, 요즘은 그렇지는 않다고 합니다. 

하지만 learning rate, 모델의 크기, batch size, optimizer 등 여러 하이퍼파라미터들을 튜닝하는 방법은 **마지막으로 모델의 성능을 조금 더 끌어올리고 싶을 때** 사용해 볼 만한 방법입니다. 

하이퍼 파라미터 튜닝 방법에는 전통적으로 사용되어 온 **grid search**와 **random search**가 있으며, 보통 random search로 튜닝을 하다가 성능이 좋은 부분이 발견되면 그 부분 부근에서 grid search를 수행하는 식으로 수행되었다고 합니다. 

![image-20220128115041782](https://user-images.githubusercontent.com/70505378/151489753-b580ccda-42df-428a-b598-dbe863baa8ec.png)

최근에는 두 방법 외에 **베이지안 기법**들이 주도하고 있습니다. 이에 대해 `BOHB(Baesian Optimization Hyper Band) 2018`이라는 논문을 읽어보면 도움이 될 것입니다. 

이번 포스팅에서는 이 하이퍼파라미터 튜닝 과정을 간소화 시켜주는 **Ray**라는 모듈에 대해 소개하고 사용하는 방법을 보려합니다. 

#### Ray

* Multi-node multi processing를 지원하며 ML/DL의 병렬 처리를 위해 개발된 모듈
* 기본적으로 현재의 분산 병렬 ML/DL 모듈의 표준
* Hyperparameter search를 위한 다양한 모듈 제공

```python
data_dir = os.path.abspath("./data")
load_data(data_dir)
# 1. config에 search space 지정
config = {
    "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
    "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
    "lr": tune.loguniform(1e-4, 1e-1),
    "batch_size": tune.choice([2, 4, 8, 16])
}
# 2. 학습 스케줄링 알고리즘 지정
scheduler = ASHAScheduler(
                metric="loss", mode="min", max_t=max_num_epochs, grace_period=1,
                reduction_factor=2)
# 3. 결과 출력 양식 지정
reporter = CLIReporter(metric_columns=["loss", "accuracy", "training_iteration"])
# 4. 병렬 처리 양식으로 학습 수행
result = tune.run(partial(train_cifar, data_dir=data_dir),
                resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
                config=config, num_samples=num_samples,
                scheduler=scheduler,
                progress_reporter=reporter)
```

Ray 모듈은 hyperparameter search를 수행할 때 처음에는 모든 경우로 학습을 시행하다가 성능이 좋지 않으면 해당 경우는 더 이상 학습을 시행하지 않고, 성능이 좋은 경우들로만 학습을 계속 수행하는 방식으로 리소스를 절약합니다. 

![image-20220128115742600](https://user-images.githubusercontent.com/70505378/151489755-8a135c5e-865f-4a99-98c1-4c29fdab9608.png)



또한 지난 포스팅에서 소개한 wandb 와 함께 사용하면 그 결과를 확인하기 더욱 좋기 때문에 두 모듈을 함께 활용하면 어렵지 않게 hyperparameter tuning을 수행할 수 있을 것으로 기대합니다. 

<br>

### PyTorch Troubleshooting

이 섹션에서는 모델 학습 과정에서 가장 많이 만나게 되는 에러이자, 해결하기 어려운 `OOM(Out of Memory)` 에러에 대해 얘기해보고자 합니다. 

**OOM이 해결하기 어려운 이유**

* 왜, 어디서 발생했는지 알기 어렵다. 
* Error backtracking이 이상한 데로 간다. 
* 메모리의 이전 상황의 파악이 어렵다. 

OOM을 해결하기 위해 가장 쉽게 시도해 볼 수 있는 방법으로는 **Batch size를 줄이는 시도**가 있습니다. 아, 그리고 batch size를 조정한 후에는 GPU clean(kernel restart) 과정을 해야 한다는 것을 잊지 마세요!

#### OOM 해결을 위한 방법들

**torch.cuda.empty_cache()**

empty_cache() 함수는 사용되지 않고 있는 GPU 상 cache를 정리합니다. (가비지 컬렉터를 호출하는 것으로 볼 수 있습니다)

이렇게 함으로써 가용 메모리를 확보할 수 있습니다. (메모리 주소의 참조를 끊는 del 과는 구분됩니다)

empty_cache() 함수는 학습 시작 전에 한 번 호출하는 것이 좋다고 합니다 ^_^

```python
import torch
from GPUtil import showUtilization as gpu_usage

print("Initial GPU Usage")
gpu_usage()
'''
Initial GPU Usage
| ID | GPU | MEM |
------------------
| 0 | 0% | 0% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
GPU Usage after allcoating a bunch of Tensors
'''
tensorList = []
for x in range(10):
	tensorList.append(torch.randn(10000000,10).cuda())
print("GPU Usage after allcoating a bunch of Tensors")
gpu_usage()
'''
GPU Usage after allcoating a bunch of Tensors
| ID | GPU | MEM |
------------------
| 0 | 0% | 40% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
'''
del tensorList
print("GPU Usage after deleting the Tensors")
gpu_usage()
'''
GPU Usage after deleting the Tensors
| ID | GPU | MEM |
------------------
| 0 | 0% | 40% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
'''
torch.cuda.empty_cache()
print("GPU Usage after emptying the cache")
gpu_usage()
'''
GPU Usage after emptying the cache
| ID | GPU | MEM |
------------------
| 0 | 0% | 5% |
| 1 | 0% | 0% |
| 2 | 0% | 0% |
| 3 | 0% | 0% |
'''
```

**training loop에 tensor로 축적되는 변수 확인**

tensor로 처리되는 변수들은 GPU 상에서 메모리를 사용하고, 해당 변수 loop 안에 연산이 있을 때 GPU에 computational graph를 생성하면서 메모리를 잠식해갑니다. 

따라서 이런 경우에는 1-d tensor의 경우 파이썬의 기본 객체(int, float, list 등)로 변환하여 처리할 것이 권장됩니다. 

```python
total_loss = 0

for x in range(10):
    # assume loss is computed
    iter_loss = torch.randn(3,4).mean()
    iter_loss.requires_grad = True
    # total_loss += iter_loss 대신, 
    iter_loss += iter_loss.item # 또는 float(iter_loss)
```

**del 명령어의 적절한 사용**

필요가 없어진 변수를 적절히 삭제하는 것도 방법이 될 수 있습니다. 

```python
for i in range(5):
    intermediate = f(input[i])
    result += g(intermediate)
    
del intermediate # del
output = h(result)
del result # del
return output
```

**배치 사이즈를 줄여보기(1로 해보기)**

**torch.no_grad()**

모델 추론 시점에는 역전파 과정이 필요 없으므로, `torch.no_grad()` context를 사용하여 backward 과정으로 인해 사용되는 메모리를 확보할 수 있습니다. 

```python
with torch.no_grad(): # torch.no_grad()
    for data, target in test_loader:
        output = network(data)
        test_loss += F.nll_loss(output, target, size_average=False).item()
        pred = output.data.max(1, keepdim=True)[1]
        correct += pred.eq(target.data.view_as(pred)).sum()
```

**tensor의 precision 줄이기**

tensor의 float precision을 8, 16bit 수준으로 줄이는 것도 하나의 방법입니다. 

그러나 이 방법은 모델의 성능에 직접적인 영향을 줄 수 있고, 매우 큰 모델을 돌리는 것이 아니라면 권장되지 않기 때문에 '최후의 수단' 정도로 생각해 두는 것이 좋을 듯 합니다. 

<br>

이외에도 **CUDNN_STATUS_NOT_INIT**이나 **device-side-assert** 등의 에러도 cuda와 관련하여 OOM의 일종이라고 할 수 있고, 역시 적절한 코드의 처리가 필요합니다. 이에 대해 참고할 만한 내용은 아래 참고자료 _GPU 에러 정리_ 에서 확인하실 수 있습니다. 





<br>

<br>

## 참고 자료

* **Multi-GPU**
  * [PyTorch Lightning Multi GPU 학습](https://pytorch-lightning.readthedocs.io/en/stable/advanced/multi_gpu.html)
  * [DDP Tutorial](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
* **Hyperparameter Tuning**
  * [Hyperparameter Tuning with Ray Tune](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)
* **PyTorch Troubleshooting**
  * [Pytorch에서 자주 발생하는 에러 질문들](https://pytorch.org/docs/stable/notes/faq.html)
  * [OOM시에 GPU 메모리 flush하기](https://discuss.pytorch.org/t/how-to-clean-gpu-memory-after-a-runtimeerror/28781)
  * [GPU 에러 정리](https://brstar96.github.io/shoveling/device_error_summary/)





<br>

<br>

## 회고

오늘로써 한 주 동안의 PyTorch에 대한 학습이 끝이 났습니다. 

파이토치 개요부터 기본적 연산들, nn.Module, Dataset과 DataLoader, Transfer learning과 Hyperparameter tuning, Multi-GPU, Trouble shooting 등 다양한 내용들을 다루는 것이 쉽지는 않았지만, 적절한 실습과 개념 문제들이 병행된 것 같아 많은 것을 배울 수 있었던 한 주였습니다. 

이전까지는 파이토치를 거의 사용해 본 경험이 없기 때문에 한 주 동안의 학습만으로는 많은 부분을 커버하기는 어렵겠지만, 앞으로 직접 모델을 만들고 학습 시키고, 성능을 개선하려는 일련의 과정과 노력을 통해 앞으로 더욱 더 익숙해지리라 생각합니다. 

무엇보다 각 내용들을 산발적으로 배우는 것이 아니라, 모델을 만들고 학습시키는 일련의 과정에 따라 순서대로 한 부분 씩 배우는 것이 전체 흐름을 이해하는 데에도 많은 도움이 되었습니다!!😁😁

한 주 간의 파이토치 모델링 과정을 배우면서 그 간의 흐름을 간단히 아래와 같이 정리해보았습니다. 

* **데이터 전처리(Dataset, Transform, Compose)**
* **데이터 불러오기(DataLoader, Sampler)**
* **신경망 구성(nn.Module, pretrained model)**
* **오차함수 및 최적화 기법 선택(Loss, Optimizer, metrics)**
* **학습 및 추론 옵션 설정(transfer learning, hyperparameter tuning, multi-gpu, monitoring)**
* **훈련, 검증(training, validating, troubleshooting)**

다음 주부터 진행될 내용들도 기대가 많이 됩니다 😊

앞으로 계속 지치지 않고 잘 나아갔으면 좋겠습니다 ㅎㅎ

<br>

<br>
