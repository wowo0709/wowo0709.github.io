---
layout: single
title: "[AITech] 2022ë…„ 1ì›” 26ì¼ í•™ìŠµ ë‚´ìš© ì •ë¦¬"
categories: ['AI', 'AITech']
toc: true
toc_sticky: true
tag: ['íŒŒì´í† ì¹˜','BasicOperations','nn.Module', 'Dataset', 'DataLoader']
---



<br>

## í•™ìŠµ ë‚´ìš© ì •ë¦¬

### ê³¼ì œ 1: Custom Model ê°œë°œí•˜ê¸°

#### Basic Operations

* torch.tensorì™€ torch.Tensorì˜ ì°¨ì´

* í…ì„œ ì¸ë±ì‹±

  * [index_select(tensor, axis, indices: 1D tensor)](https://pytorch.org/docs/stable/generated/torch.index_select.html#torch.index_select)

    * axis(dim)ì€ ì´ë™í•˜ëŠ” ë°©í–¥ì´ ì•„ë‹ˆë¼ ì„ íƒ í›„ë³´ì˜ ë°©í–¥ì´ë‹¤!

    ```python
    A = torch.Tensor([[1, 2],
                      [3, 4]])
    
    indices = torch.tensor([0])
    output = torch.squeeze(torch.index_select(A, 1, indices))
    print(output)
    # tensor([1., 3.])
    ```

    

  * numpy style indexing

* í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ê°’ ëª¨ìœ¼ê¸°

  * [gather(tensor, axis, indices_tensor: index-value tensor)](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)

    * ì˜ˆ

    > A = torch.Tensor([[1,2], [3,4]])
    >
    > torch.gather(A, dim=0, index=torch.tensor([[0,1], [1,1]])) ì´ë¼ë©´, 
    >
    > ê° ì¸ë±ìŠ¤ì— ëŒ€í•´ ì°¨ë¡€ë¡œ
    >
    > \[0\]\[0\] => A\[index\[0\]\[0\]\]\[0\] = A\[0\]\[0\] = 1
    >
    > \[0\]\[1\] => A\[index\[0\]\[1\]\]\[1\] = A\[1\]\[1\] = 4
    >
    > \[1\]\[0\] => A\[index\[1\]\[0\]\]\[0\] = A\[1\]\[0\] = 3
    >
    > \[1\]\[1\] => A\[index\[1\]\[1\]\]\[1\] = A\[1\]\[1\] = 4
    >
    > <br>
    >
    > ì¦‰, dimì— í•´ë‹¹í•˜ëŠ” ì°¨ì›ì˜ ì¸ë±ìŠ¤ ê°’ì€ indexë¡œ ì „ë‹¬ëœ í…ì„œì˜ ê°’ìœ¼ë¡œ ëŒ€ì²´ë˜ê³ , ë‚˜ë¨¸ì§€ ì¸ë±ìŠ¤ ê°’ì€ indexì˜ ìœ„ì¹˜ê°’ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤. 

    

* ìë£Œêµ¬ì¡° í™•ì¸

  * is_tensor, is_storage, is_complex, ...
  * numel(tensor) :ì›ì†Œì˜ ê°œìˆ˜ ë°˜í™˜

* Tensor í•¨ìˆ˜

  * Creating
    * from_numpy(ndarray)
    * zeros(*shape)
    * zeros_like(tensor)
    * full(shape, value)
    * [Tensor.expand(*size)](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html?highlight=expand)
      * ì…€í”„ broadcastingì„ ì‹œì¼œì£¼ëŠ” í•¨ìˆ˜ë¡œ ë³¼ ìˆ˜ ìˆìŒ. 
  * Indexing, Slicing, Joining, Mutating
    * [chunk(input, chunks, dim=0)](https://pytorch.org/docs/stable/generated/torch.chunk.html#torch.chunk)
    * [tensor_split(input, indices_or_sections, dim=0)](https://pytorch.org/docs/stable/generated/torch.tensor_split.html#torch.tensor_split)
    * [swapdims(input, dim0, dim1)](https://pytorch.org/docs/stable/generated/torch.swapdims.html#torch.swapdims)
    * [tensor.scatter_(dim, index, src, reduce=None)](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_)
  * Random sampling
    * [normal(mean: tensor, std: tensor)/ normal(mean: float, std: float, size)](https://pytorch.org/docs/stable/generated/torch.normal.html#torch.normal)
      * mean, stdë¥¼ tensor íƒ€ì…ìœ¼ë¡œ ì „ë‹¬í•  ê²½ìš° output tensorì˜ ê° ì›ì†Œì˜ mean, stdë¥¼ ê°ê° ì§€ì •
      * mean, stdë¥¼ float íƒ€ì…ìœ¼ë¡œ ì „ë‹¬í•  ê²½ìš° output tensorì˜ ì „ì²´ ì›ì†Œì˜ mean, stdë¥¼ ì§€ì •í•˜ê³  sizeë¥¼ ì „ë‹¬
    * [rand(*size)](https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand)
      * 0~1 ì‚¬ì´ ëœë¤í•œ ê°’ì„ uniform distributionìœ¼ë¡œ ìƒì„±
    * [randint(low, high, size)](https://pytorch.org/docs/stable/generated/torch.randint.html#torch.randint)
      * low~high ì‚¬ì´ ëœë¤í•œ ì •ìˆ˜ ê°’ì„ ìƒì„±
    * [randn(*size)](https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn)
      * mean=0, std=1 ì¸ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ëœë¤í•œ ê°’ì„ ìƒì„±
  * Math operations - Pointwise ops
    * abs(tensor)
    * add(input: tensor, other: tensor or number, alpha: number)
    * [addcdiv(input, tensor1, tensor2, value)](https://pytorch.org/docs/stable/generated/torch.addcdiv.html#torch.addcdiv)
    * [addcmul(input, tensor1, tensor2, value)](https://pytorch.org/docs/stable/generated/torch.addcmul.html#torch.addcmul)
  * Reduction ops
    * [argmax(input, dim)](https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax), [argmin(input, dim)](https://pytorch.org/docs/stable/generated/torch.argmin.html#torch.argmin)
    * [amax(input, dim)](https://pytorch.org/docs/stable/generated/torch.amax.html#torch.amax), [amin(input, dim)](https://pytorch.org/docs/stable/generated/torch.amin.html#torch.amin)
    * [all(input, dim)](https://pytorch.org/docs/stable/generated/torch.all.html#torch.all), [any(input, dim)](https://pytorch.org/docs/stable/generated/torch.any.html#torch.any)
  * Math operations - Comparison ops
    * [allclose(input, other, rtol, atol)](https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose)
    * [argsort(input, dim, descending=False)](https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort)
    * [eq(input, other)](https://pytorch.org/docs/stable/generated/torch.eq.html#torch.eq), [equal(input, other)](https://pytorch.org/docs/stable/generated/torch.equal.html#torch.equal)
      * elementwise equality: tensor VS tensor equality: bool
  * Math operations - Other ops
    * [einsum(equation, *operands)](https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum)
      * einstein summationì˜ ì•½ì
    * atleast_1d(input: tensor or a list of tensors), atleast_2d(input: tensor or a list of tensors), atleast_3d(input: tensor or a list of tensors)
    * [broadcast_tensors(*tensors)](https://pytorch.org/docs/stable/generated/torch.broadcast_tensors.html#torch.broadcast_tensors), [broadcast_to(input: tensor, shape)](https://pytorch.org/docs/stable/generated/torch.broadcast_to.html#torch.broadcast_to)
  * Math operations - BLAS and LAPACK ops
    * ì„ í˜•ëŒ€ìˆ˜í•™ê³¼ ì—°ê´€ëœ í•¨ìˆ˜
    * BLAS: Basic Linear Algebra Subprograms
    * LAPACK: Linear Algebra PACKage
    * í˜„ì¬ëŠ” torch.linalg ëª¨ë“ˆì˜ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•  ê²ƒì´ ê¶Œì¥ë¨

* [torch.linalg](https://pytorch.org/docs/stable/linalg.html#)

  * ì„ í˜•ëŒ€ìˆ˜í•™ ê´€ë ¨ í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ ëª¨ë“ˆ

* [torch.nn](https://pytorch.org/docs/stable/nn.html)

  * ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•œ Basic Building Blockë“¤ì„ ë¯¸ë¦¬ ë§Œë“¤ì–´ ë†“ì€ ëª¨ë“ˆ
  * Linearì™€ LazyLinearì˜ ì°¨ì´ëŠ”?
    * LazyLinearëŠ” ì•„ì§ in_featuresê°€ ê²°ì •ë˜ì§€ ì•Šì€ Linear layerì…ë‹ˆë‹¤. ìµœì´ˆ ì‹¤í–‰ ì‹œ in_featuresê°€ ê²°ì •ë˜ë©´ì„œ Linearì™€ ë™ì¼í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤. 

<br>

#### nn.Module

íŒŒì´í† ì¹˜ì˜ [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) í´ë˜ìŠ¤ëŠ” ì—¬ëŸ¬ ê¸°ëŠ¥ë“¤ì„ í•œ ê³³ì— ëª¨ì•„ë†“ëŠ” ìƒìì˜ ì—­í• ì„ í•©ë‹ˆë‹¤. 

nn.Module ì´ë¼ëŠ” ìƒìëŠ” ë˜ ë‹¤ë¥¸ nn.Module ìƒìë¥¼ í¬í•¨í•  ìˆ˜ë„ ìˆìœ¼ë©°, ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠëƒì— ë”°ë¼ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤. 

- `nn.Module`ì´ë¼ëŠ” ìƒìì— `ê¸°ëŠ¥`ë“¤ì„ ê°€ë“ ëª¨ì•„ë†“ì€ ê²½ìš° `basic building block`
- `nn.Module`ì´ë¼ëŠ” ìƒìì— `basic building block`ì¸ `nn.Module`ë“¤ì„ ê°€ë“ ëª¨ì•„ë†“ì€ ê²½ìš° `ë”¥ëŸ¬ë‹ ëª¨ë¸`
- `nn.Module`ì´ë¼ëŠ” ìƒìì— `ë”¥ëŸ¬ë‹ ëª¨ë¸`ì¸ `nn.Module`ë“¤ì„ ê°€ë“ ëª¨ì•„ë†“ì€ ê²½ìš° `ë”ìš± í° ë”¥ëŸ¬ë‹ ëª¨ë¸`

<br>

* **Containers**

  * nn.Module ë¸”ë¡ë“¤ì„ ë¬¶ì–´ì„œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ë“¤

  * [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)

    * ìˆœì°¨ì ìœ¼ë¡œ forwardë¥¼ ì‹¤í–‰í•  ë•Œ ì‚¬ìš©

    ```python
    class Add(nn.Module):
        def __init__(self, value):
            super().__init__()
            self.value = value
    
        def forward(self, x):
            return x + self.value
    
    #        y = x + 3 + 2 + 5
    from collections import OrderedDict
    calculator = nn.Sequential(OrderedDict([
                                     ('plus1', Add(3)),
                                     ('plus2', Add(2)),
                                     ('plus3', Add(5))
    ]))
    
    
    x = torch.tensor([1])
    
    output = calculator(x)
    ```

  * [nn.ModuleList](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)

    * ëª¨ë“ˆë“¤ì„ ëª¨ì•„ë†“ê³  ì‚¬ìš©í•˜ê³  ì‹¶ì€ ëª¨ë“ˆë§Œ ì„ íƒí•´ì„œ ì‚¬ìš©
    * ì¸ë±ìŠ¤ë¡œ ê´€ë¦¬

    ```python
    class Add(nn.Module):
        def __init__(self, value):
            super().__init__()
            self.value = value
    
        def forward(self, x):
            return x + self.value
    
    
    class Calculator(nn.Module):
        def __init__(self):
            super().__init__()
            self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])
    
        def forward(self, x):
            #        y = ((x + 3) + 2) + 5 
            x = self.add_list[1](x)
            x = self.add_list[0](x)
            x = self.add_list[2](x)
            return x
    
    
    x = torch.tensor([1])
    
    calculator = Calculator()
    output = calculator(x)
    ```

    

  * [nn.ModuleDict](https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict)

    * key ê°’ì„ ì´ìš©í•´ ëª¨ë“ˆë“¤ì„ ê´€ë¦¬í•  ë•Œ ì‚¬ìš©

    ```python
    class Add(nn.Module):
        def __init__(self, value):
            super().__init__()
            self.value = value
    
        def forward(self, x):
            return x + self.value
    
    
    class Calculator(nn.Module):
        def __init__(self):
            super().__init__()
            self.add_dict = nn.ModuleDict({'add2': Add(2),
                                           'add3': Add(3),
                                           'add5': Add(5)})
    
        def forward(self, x):
            #        y = ((x + 3) + 2) + 5 
            x = self.add_dict['add3'](x)
            x = self.add_dict['add2'](x)
            x = self.add_dict['add5'](x)
            return x
    
    
    x = torch.tensor([1])
    
    calculator = Calculator()
    output = calculator(x)
    ```

* **Parameters**: [nn.parameter.Parameter](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html?highlight=parameter)

  * nn.parameter.Parameter(data, requires_grad=True)
  * [self.register_parameter(name, tensor)](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_parameter#torch.nn.Module.register_parameter): ëª¨ë“ˆì— ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„° ë“±ë¡
  
  ```python
  class Linear(nn.Module):
      def __init__(self, in_features, out_features):
          super().__init__()
  
          self.W = Parameter(torch.ones(out_features, in_features))
          self.b = Parameter(torch.ones(out_features))
  
      def forward(self, x):
          output = torch.addmm(self.b, x, self.W.T)
  
          return output
  ```
  
  * **Tensor** ëŒ€ì‹  **Parameter**ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ !!
  
    * TensorëŠ” ëª¨ë¸ ì €ì¥ ì‹œ ì €ì¥ë˜ì§€ ì•ŠëŠ”ë‹¤!
  
    * Gradientê°€ ê³„ì‚°ë˜ì§€ ì•ŠëŠ”ë‹¤!
  
    * í˜¹ì‹œ ê°±ì‹ ë˜ì§€ëŠ” ì•Šì§€ë§Œ ì €ì¥í•˜ê³  ì‹¶ì€ Tensor ê°’ì´ ìˆë‹¤ë©´, **buffer**ì— tensorë¥¼ ë“±ë¡í•œë‹¤!
      * [self.register_buffer(name, tensor, persistent=True)](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_buffer#torch.nn.Module.register_buffer)
      * ìœ„ì—ì„œ selfëŠ” nn.Moduleì„ ìƒì†ë°›ì€ ì»¤ìŠ¤í…€ ëª¨ë¸ í´ë˜ìŠ¤

**nn.Module ë¶„ì„í•˜ê¸°**

* **SubModule**

  * SubModule í‘œì‹œí•˜ê¸°: named_modules() VS named_children()
    * [named_modules()](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named#torch.nn.Module.named_modules): ìì‹ ì— ì†í•˜ëŠ” ì „ì²´ í•˜ìœ„ ëª¨ë“ˆì„ í‘œì‹œ
    * [named_children()](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=child#torch.nn.Module.named_children): í•˜ë‚˜ ì•„ë˜ ë‹¨ê³„ì˜ í•˜ìœ„ ëª¨ë“ˆê¹Œì§€ë§Œ í‘œì‹œ
    * ì´ë¦„ ì—†ì´ ê·¸ëƒ¥ ëª¨ë“ˆë§Œ ê°€ì ¸ì˜¬ ê²½ìš° modules(), children() ì‚¬ìš©
  * SubModule ê°€ì ¸ì˜¤ê¸°: [get_submodule(target_name)](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get_submodule#torch.nn.Module.get_submodule)

* **Parameter**

  * Parameter í‘œì‹œí•˜ê¸°: parameters(), named_parameters()
  * Parameter ê°€ì ¸ì˜¤ê¸°: get_parameter(target_name)

* **Buffer**

  * Buffer í‘œì‹œí•˜ê¸°: buffers(), named_buffers()
  * Buffer ê°€ì ¸ì˜¤ê¸°: get_buffer(target_name)

* ê°™ì€ ë ˆë²¨(í•¨ìˆ˜ ë ˆë²¨, basic block ë ˆë²¨ ë“±)ì—ì„œëŠ” ì„œë¡œì˜ ì°¸ì¡°ë¥¼ í—ˆìš©í•˜ì§€ ì•ŠëŠ”ë‹¤!!!

  ```python
  class Function_C(nn.Module):
      def __init__(self):
          super().__init__()
          self.register_buffer('duck', torch.Tensor([7]), persistent=True)
  
      def forward(self, x):
          x = x * self.duck
          
          return x
  
  class Function_D(nn.Module):
      def __init__(self):
          super().__init__()
          self.W1 = Parameter(torch.Tensor([3]))
          self.W2 = Parameter(torch.Tensor([5]))
          # self.c = Function_C()
  
      def forward(self, x):
          x = x + self.W1
          x = Function_C().forward(x) # self.c(x)
          x = x / self.W2
  
          return x
  ```

* ëª¨ë“ˆì˜ ì´ë¦„(ì´ë¥¼ **repr**ì´ë¼ í•¨)ì„ ì¬ì„¤ì • í•´ì£¼ê³  ì‹¶ë‹¤ë©´, í•´ë‹¹ ëª¨ë“ˆ ë‚´ì—ì„œ `extra_repr(self): return ' '`ì„ ì˜¤ë²„ë¼ì´ë”© í•´ì¤€ë‹¤. 

* [Docstring](https://www.datacamp.com/community/tutorials/docstrings-python)

  * Docstringì€ í•¨ìˆ˜ ë˜ëŠ” í´ë˜ìŠ¤ì˜ ë§¨ ìœ„ì— í•´ë‹¹ í•¨ìˆ˜/í´ë˜ìŠ¤ì— ëŒ€í•œ ì •ë³´(íŒŒë¼ë¯¸í„°, ë°˜í™˜ê°’ ë“±)ë¥¼ ì ì‹œí•˜ëŠ” ê²ƒìœ¼ë¡œ, ì½”ë©˜íŠ¸(ì£¼ì„)ì™€ëŠ” ë‹¤ë¥´ë‹¤. 
  * `__doc__` í”„ë¡œí¼í‹°ë¡œ moduleì— ëŒ€í•œ docstringì„ ë³¼ ìˆ˜ ìˆë‹¤. 
  * `help(module)`ë¡œ moduleì— ëŒ€í•œ ë” ìì„¸í•œ ì„¤ëª…(ë©”ì„œë“œ, í”„ë¡œí¼í‹° ë“±)ì„ ë³¼ ìˆ˜ ìˆë‹¤. 
  * Documentationì´ ì—†ëŠ” ëª¨ë¸ì´ë¼ë©´ Docstringì„ Documentationì²˜ëŸ¼ ì—¬ê¸°ê³  ê¼¼ê¼¼íˆ ë³´ì•„ì•¼ í•œë‹¤. 

  ```python
  def string_reverse(str1):
      '''
      Returns the reversed String.
  
      Parameters:
          str1 (str):The string which is to be reversed.
  
      Returns:
          reverse(str1):The string which gets reversed.   
      '''
  
      reverse_str1 = ''
      i = len(str1)
      while i > 0:
          reverse_str1 += str1[i - 1]
          i = i- 1
      return reverse_str1
  ```

**nn.Module ë” ì•Œì•„ë³´ê¸°**

* **hook**

  * hookì€ íŒ¨í‚¤ì§€í™”ëœ ë‹¤ë¥¸ ì½”ë“œì—ì„œ ë‹¤ë¥¸ í”„ë¡œê·¸ë˜ë¨¸ê°€ custom ì½”ë“œë¥¼ ì¤‘ê°„ì— ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ë†“ì€ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤. 
    * í”„ë¡œê·¸ë¨ì˜ ì‹¤í–‰ ë¡œì§ì„ ë¶„ì„í•˜ê±°ë‚˜, 
    * í”„ë¡œê·¸ë¨ì— ì¶”ê°€ì ì¸ ê¸°ëŠ¥ì„ ì œê³µí•˜ê³  ì‹¶ì„ ë•Œ
  * ì‚¬ìš©í•©ë‹ˆë‹¤. 
  * ê¸°ë³¸ì ìœ¼ë¡œ hookì€ ì•„ë˜ì™€ ê°™ì´ ë™ì‘í•©ë‹ˆë‹¤. 

  ```python
  class Package(object):
      """í”„ë¡œê·¸ë¨ Aì™€ Bë¥¼ ë¬¶ì–´ë†“ì€ íŒ¨í‚¤ì§€ ì½”ë“œ"""
      def __init__(self):
          self.programs = [program_A, program_B]
          self.hooks = []
  
      def __call__(self, x):
          for program in self.programs:
              x = program(x)
  
              # Packageë¥¼ ì‚¬ìš©í•˜ëŠ” ì‚¬ëŒì´ ìì‹ ë§Œì˜ custom programì„
              # ë“±ë¡í•  ìˆ˜ ìˆë„ë¡ ë¯¸ë¦¬ ë§Œë“¤ì–´ë†“ì€ ì¸í„°í˜ì´ìŠ¤ hook
              if self.hooks:
                  for hook in self.hooks:
                      output = hook(x)
  
                      # return ê°’ì´ ìˆëŠ” hookì˜ ê²½ìš°ì—ë§Œ xë¥¼ ì—…ë°ì´íŠ¸ í•œë‹¤
                      if output:
                          x = output
  
          return x
  ```

  * hookì„ ì–´ë””ì— ì‹¬ì–´ë†“ì„ ì§€ëŠ” packageë¥¼ ì„¤ê³„í•˜ëŠ” ì„¤ê³„ìì—ê²Œ ë‹¬ë ¤ìˆìŠµë‹ˆë‹¤. 
  * Tensorì˜ hook
    * Tensorì˜ hookì—ëŠ” `tensor._backward_hooks` ë§Œì´ ì¡´ì¬í•˜ê³ , ë“±ë¡ì€ [tensor.register_hook(hook)](https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook)ì„ ì‚¬ìš©í•˜ì—¬ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
  * Moduleì˜ hook
    * [register_forward_pre_hook(hook)](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_pre_hook)
    * [register_forward_hook(hook)](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_hook)
    * [register_full_backward_hook(hook)](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_full#torch.nn.Module.register_full_backward_hook)
    * moduleì˜ `__dict__` attributeì—ì„œ parameter, hook ë“±ì„ ëª¨ë‘ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
      * backward_hooksì˜ ê²½ìš° full_backward_hooksì˜ ì „ì‹ ìœ¼ë¡œ í˜„ì¬ deprecated ìƒíƒœì´ê³ , state_dict_hooksì˜ ê²½ìš° ëª¨ë“ˆì´ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” hookì…ë‹ˆë‹¤. 
  * [PyTorch hooks ì‚¬ìš© ì‚¬ë¡€ ë³´ê¸°](https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904)
    * gradientì˜ ê°’ì˜ ë³€í™”ë¥¼ ì‹œê°í™”
    * gradientê°’ì´ íŠ¹ì • ì„ê³—ê°’ì„ ë„˜ìœ¼ë©´ gradient exploding ê²½ê³  ì•Œë¦¼
    * íŠ¹ì • tensorì˜ gradient ê°’ì´ ë„ˆë¬´ ì»¤ì§€ê±°ë‚˜ ì‘ì•„ì§€ëŠ” í˜„ìƒì´ ê´€ì¸¡ë˜ë©´ í•´ë‹¹ tensor í•œì •ìœ¼ë¡œ gradient clipping

* **[apply](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=apply#torch.nn.Module.apply) -> applied module**

  * ëª¨ë¸ì— custom í•¨ìˆ˜ë¥¼ ì ìš©ì‹œì¼œ ê·¸ í•˜ìœ„ ëª¨ë“ˆë“¤ì—ë„ ëª¨ë‘ ì ìš©ë˜ë„ë¡ í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. 

  * applyë¥¼ í†µí•´ì„œ ì ìš©í•˜ëŠ” í•¨ìˆ˜ëŠ” moduleì„ ì…ë ¥ìœ¼ë¡œ ë°›ìœ¼ë©°, ëª¨ë¸ì˜ ëª¨ë“  moduleë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ë°›ì•„ ì²˜ë¦¬í•©ë‹ˆë‹¤. 

  * ì£¼ë¡œ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ì— ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. 

  * applyëŠ” Postorder Traversal ë°©ì‹(í›„ìœ„íƒìƒ‰)ìœ¼ë¡œ í•¨ìˆ˜ë¥¼ moduleì— ì ìš©í•©ë‹ˆë‹¤. 

    ![image-20220126215452221](https://user-images.githubusercontent.com/70505378/151172647-561ff86e-4871-4bdc-8c10-4c1090269758.png)

  * [How to initialize weights in PyTorch?](https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch)

    ```python
    def init_weights(m):
        if isinstance(m, nn.Linear):
            torch.nn.init.xavier_uniform(m.weight)
            m.bias.data.fill_(0.01)
    
    net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))
    net.apply(init_weights)
    ```

    

<br>

### ê³¼ì œ 2: Custom Dataset ë° Custom DataLoader

#### Dataset

* Dataset ê´€ë ¨ ëª¨ë“ˆ
  * torch.utils.data
    * ë°ì´í„°ì…‹ì˜ í‘œì¤€ì„ ì •ì˜í•˜ê³  ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê³  ìë¥´ê³  ì„ëŠ”ë° ì“°ëŠ” ë„êµ¬ë“¤ì´ ëª¨ì—¬ìˆëŠ” ëª¨ë“ˆ
    * torch.utils.data.Dataset: ë°ì´í„°ì˜ ì…ë ¥ í‘œì¤€ì„ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤
    * torch.utils.data.DataLoader: ë°ì´í„°ì˜ ë°°ì¹˜ë¥¼ ìƒì„±í•˜ê³  í•™ìŠµ ì§ì „ í…ì„œë¡œ ë³€í™˜í•˜ëŠ” ë“± ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ëŠ” í´ë˜ìŠ¤
  * torchvision.dataset: torch.utils.data.Datasetì„ ìƒì†í•˜ëŠ” ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ëª¨ìŒ
  * torchtext.dataset: torch.utils.data.Datasetì„ ìƒì†í•˜ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ëª¨ìŒ
  * torchvision.transforms: ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì— ì“¸ ìˆ˜ ìˆëŠ” Tensor ë³€í™˜, resizing, cropping, rotating ë“±ì˜ ë³€í™˜ í•„í„°ë¥¼ ê°–ëŠ” ëª¨ë“ˆ
  * torchvision.utils: ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë“¤ì„ ê°–ëŠ” ëª¨ë“ˆ
* ì»¤ìŠ¤í…€ Dataset ì •ì˜
  * torch.utils.data.Datasetì„ ìƒì†
  * `__init__()`, `__len()__`, `__getitem__()` ë©”ì„œë“œ ì •ì˜(map-style dataset)
    * `__init__()`: ë°ì´í„°ì˜ ìœ„ì¹˜ë‚˜ íŒŒì¼ëª…ì„ ì§€ì •í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒê³¼ ê°™ì€ ì´ˆê¸°í™” ì‘ì—…ì„ ìˆ˜í–‰. ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  transformsë“¤ì„ composeí•´ì„œ ì •ì˜
    * `__len()__`: datasetì˜ ìš”ì†Œ ìˆ˜ë¥¼ ë°˜í™˜
    * `__getitem__()`: ë°ì´í„°ì…‹ì˜ idx ë²ˆì§¸ ë°ì´í„°ì˜ ë°˜í™˜ í˜•ì‹ì„ ì •ì˜. ì›ë³¸ ë°ì´í„°ì˜ ì „ì²˜ë¦¬, ì¦ê°• ë“±ì„ ìˆ˜í–‰. 

<br>

#### DataLoader

* DataLoader ì¸í„°í˜ì´ìŠ¤

  > DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,
  >
  > â€‹      				batch_sampler=None, num_workers=0, collate_fn=None,
  >
  > â€‹      				pin_memory=False, drop_last=False, timeout=0,
  >
  > â€‹      				worker_init_fn=None)
  * batch_size: ë°°ì¹˜ì˜ ì‚¬ì´ì¦ˆ
  
  * shuffle: ë°ì´í„°ë¥¼ ì„ì–´ì„œ ì‚¬ìš©í•˜ëŠ” ì§€ ì—¬ë¶€
  
  * sampler/batch_sampler: ë°ì´í„°ì˜ ì¸ë±ìŠ¤ë¥¼ ì»¨íŠ¸ë¡¤
    * map-styleì—ì„œ `__len__()`ê³¼ `__iter__()`ë¥¼ êµ¬í˜„
    * [document](https://pytorch.org/docs/stable/data.html) or [others](https://towardsdatascience.com/pytorch-basics-sampling-samplers-2a0f29f0bf2a)
      * SequentialSampler : í•­ìƒ ê°™ì€ ìˆœì„œ
      * RandomSampler : ëœë¤, replacemetn ì—¬ë¶€ ì„ íƒ ê°€ëŠ¥, ê°œìˆ˜ ì„ íƒ ê°€ëŠ¥
      * SubsetRandomSampler : ëœë¤ ë¦¬ìŠ¤íŠ¸, ìœ„ì™€ ë‘ ì¡°ê±´ ë¶ˆê°€ëŠ¥
      * WeigthRandomSampler : ê°€ì¤‘ì¹˜ì— ë”°ë¥¸ í™•ë¥ 
      * BatchSampler : batchë‹¨ìœ„ë¡œ sampling ê°€ëŠ¥
      * DistributedSampler : ë¶„ì‚°ì²˜ë¦¬ (torch.nn.parallel.DistributedDataParallelê³¼ í•¨ê»˜ ì‚¬ìš©)
    
  * num_workers: ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ ì‚¬ìš©í•˜ëŠ” ì„œë¸Œ í”„ë¡œì„¸ìŠ¤ ê°œìˆ˜
    * ê°œìˆ˜ë¥¼ í¬ê²Œ ì„¤ì •í•´ë„ CPU-GPU ì‚¬ì´ì˜ ë³‘ëª© í˜„ìƒìœ¼ë¡œ ì¸í•´ ì˜¤íˆë ¤ ì†ë„ê°€ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ
    
  * collate_fn: ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ í•©ì¹  ëŒ€ ì¼ê´„ì ìœ¼ë¡œ ì ìš©í•´ì£¼ëŠ” í•¨ìˆ˜
    * ë³´í†µ í…ìŠ¤íŠ¸ ì²˜ë¦¬ì—ì„œ paddingì„ í•˜ëŠ” ë“± ë°ì´í„°ì˜ ì‚¬ì´ì¦ˆë¥¼ ì¼ì •í•˜ê²Œ ë§Œë“¤ì–´ì¤„ ë•Œ ì£¼ë¡œ ì‚¬ìš©
    
  * pin_memory: Trueë¡œ ì§€ì • ì‹œ Tensorë¥¼ CUDA ë©”ëª¨ë¦¬ì— í• ë‹¹, ë°ì´í„° ì „ì†¡ì´ í›¨ì”¬ ë¹ ë¥´ê²Œ ì´ë£¨ì–´ì§. 
  
    ![image-20220127215148720](https://user-images.githubusercontent.com/70505378/151489742-3ca86d6d-e1e0-4246-b81e-02d4ddc1cbe5.png)
  
  * drop_last: batch_sizeì— ë”°ë¼ í¬ê¸°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆëŠ” ë§ˆì§€ë§‰ batchë¥¼ ì‚¬ìš©í•  ì§€ ì—¬ë¶€
  
  * time_out: ì–‘ìˆ˜ë¡œ ì§€ì •í•  ê²½ìš°, DataLoaderê°€ dataë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì œí•œ ì‹œê°„
  
  * worker_init_fn: ì–´ë–¤ worker(í”„ë¡œì„¸ìŠ¤)ë¥¼ ë¶ˆëŸ¬ì˜¬ ê²ƒì¸ê°€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
  
* **[torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)**

  * torchvisionì€ í•­ìƒ ì…ë ¥ ì´ë¯¸ì§€ë¡œ PIL ê°ì²´ë¥¼ ìš”êµ¬í•©ë‹ˆë‹¤. 

  * transformers

    * Resize

    ```python
    torchvision.transforms.Resize(size, 
                                  interpolation=<InterpolationMode.BILINEAR: 'bilinear'>, 
                                  max_size=None, 
                                  antialias=None)
    ```

    * RandomCrop

    ```python
    torchvision.transforms.RandomCrop(size, 
                                      padding=None,
                                      pad_if_needed=False,
                                      fill=0, 
                                      padding_mode='constant')
    ```

    

    * RandomRotation

    ```python
    torchvision.transforms.RandomRotation(degrees,
                                          interpolation=<InterpolationMode.NEAREST: 'nearest'>, 
                                          expand=False,
                                          center=None,
                                          fill=0, 
                                          resample=None)
    ```

    * ì´ì™¸ì—ë„ ìˆ˜ë§ì€ transform í´ë˜ìŠ¤ë“¤ì´ ìˆìŠµë‹ˆë‹¤. 

  * PIL/Tensor(Array) ë³€í™˜

    * transforms.ToTensor()(image): PIL ê°ì²´ë¥¼ Tensor ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 
    * transforms.ToPILImage()(image): í…ì„œ ë˜ëŠ” ë°°ì—´ í˜•íƒœì˜ ê°ì²´ë¥¼ PIL ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 

  * Compose

    * ì—¬ëŸ¬ transformerë“¤ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì„œ ì²˜ë¦¬í•˜ëŠ” ê°ì²´

    ```python
    transforms.Compose([transforms.Resize((224,224)),
                        transforms.RandomHorizontalFlip(0.5),
                        transforms.CenterCrop(150)])(im)
    ```

  * datasets

    * torchvision.datasets ì—ëŠ” CIFAR10, MNIST ë“± ëŒ€í‘œì ì¸ ì´ë¯¸ì§€ ë°ì´í„°ë“¤ì„ dataset ê°ì²´ë¡œ ì‰½ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ê°€ ë§ˆë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 
    * `dir(torchvision.datasets)`ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. 

  * **torchvisionì—ì„œ ì œê³µí•˜ëŠ” transform ì™¸ì—ë„ [albumentations](https://github.com/albumentations-team/albumentations)ê³¼ ê°™ì´ ë‹¤ì–‘í•œ transformerë“¤ì„ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë§ìŠµë‹ˆë‹¤.**

  * **ë•Œë¡œëŠ” transformationì— ì˜í•´ì„œ inputì´ ë³€í•˜ë©´ GTê°’ì´ ë³€í•˜ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ì˜ˆì»¨ëŒ€ ê°ì²´ ì¸ì‹(Object detection)ì˜ ê²½ìš°, ë¬¼ì²´ì˜ ìœ„ì¹˜ ì •ë³´ì¸ ë°”ìš´ë”© ë°•ìŠ¤(Bounding box)ê°€ ê·¸ë ‡ìŠµë‹ˆë‹¤. ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë’¤ì§‘ê±°ë‚˜ íšŒì „ì‹œí‚¤ë©´ ê·¸ì— ë”°ë¼ì„œ ë°”ìš´ë”© ë°•ìŠ¤ë„ ì¢Œí‘œê°€ ë³€í™˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ´ ê²½ìš° ì‚¬ìš©í•˜ëŠ” ì…ì¥ì—ì„œëŠ” ë§¤ìš° ê³¤ë€í•œë°ìš”. ì´ëŸ° ê³¨ì¹˜ ì•„í”ˆ ìƒí™©ì„ í•´ê²°í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë„ ìˆìŠµë‹ˆë‹¤. ë°”ë¡œ [imgaug](https://github.com/aleju/imgaug)ì…ë‹ˆë‹¤.**

<br>

### ì „ì²´ì ì¸ í•™ìŠµ êµ¬ì¡°(train.py)

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader 
from network import CustomNet
from dataset import ExampleDataset
from loss import ExampleLoss

###############################
#  ì²«ë²ˆì§¸ ê³¼ì œ Custom modeling  #
###############################

# ëª¨ë¸ ìƒì„±
model = CustomNet()
model.train()

# ì˜µí‹°ë§ˆì´ì € ì •ì˜
params = [param for param in model.parameters() if param.requires_grad]
optimizer = optim.Example(params, lr=lr)

# ì†ì‹¤í•¨ìˆ˜ ì •ì˜
loss_fn = ExampleLoss()

###########################################
#  ë‘ë²ˆì§¸ ê³¼ì œ Custom Dataset & DataLoader  # 
###########################################

# í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ ìƒì„±
dataset_example = ExampleDataset()

# í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ë¡œë” ìƒì„±
dataloader_example = DataLoader(dataset_example)

##########################################################
#  ì„¸ë²ˆì§¸ ê³¼ì œ Transfer Learning & Hyper Parameter Tuning  # 
##########################################################
for e in range(epochs):
    for X,y in dataloader_example:
        output = model(X)
        loss = loss_fn(output, y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```



<br>

<br>

## ì°¸ê³  ìë£Œ

* [Tensor padding](https://hichoe95.tistory.com/116)
* [functools.partial](https://hamait.tistory.com/823)
* [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)







<br>

<br>

## íšŒê³ 

ì˜¤ëŠ˜ì€ ê°•ì˜ëŠ” ì ì‹œ ì‰¬ê³ , íŒŒì´í† ì¹˜ì˜ **Basic Operations & nn.Module**ê³¼ **Dataset & DataLoader**ì— ê´€í•œ ê³¼ì œ í’€ì´ì— ì§‘ì¤‘í•˜ì˜€ë‹¤. 

ì „ë°˜ì ì¸ ëŠë‚Œì€, ì–´ë µê³  ì˜¤ë˜ ê±¸ë¦¬ëŠ” ê³¼ì œì˜€ì§€ë§Œ ê·¸ë§Œí¼ ë‚´ìš©ì„ ì´í•´í•˜ê³  ìµíˆëŠ” ë° í° ë„ì›€ì´ ë˜ì—ˆë‹¤ëŠ” ê²ƒì´ë‹¤. 

ì–¸ì–´ë‚˜ í”„ë ˆì„ì›Œí¬ì— ëŒ€í•œ ê³µë¶€ëŠ” ì§ì ‘ ì‹¤ìŠµì„ í•´ë³´ì§€ ì•Šìœ¼ë©´ í•™ìŠµí•´ë„ ê¸ˆë°© ìŠì–´ë²„ë¦°ë‹¤ê³  ìƒê°í•˜ëŠ”ë°, ë†’ì€ ìˆ˜ì¤€ì˜ ê³¼ì œë¥¼ ì´ìš©í•´ ë°”ë¡œ ì‹¤ìŠµì„ ì§„í–‰í•˜ë‹ˆ í•œ ì¸µ ë” ì´í•´ë„ê°€ ë†’ì•„ì§€ê³  ë‚´ê°€ ë¬´ì—‡ì„ ëª°ëëŠ”ì§€, ë¬´ì—‡ì„ ì•Œì•„ì•¼ í•  ì§€ì— ëŒ€í•œ ê¸¸ì„ ì¡ì„ ìˆ˜ ìˆì—ˆë‹¤. 

ë‹¤ë§Œ, ì•ìœ¼ë¡œëŠ” ê³¼ì œë¥¼ ì¡°ê¸ˆ ë” ë¯¸ë¦¬ë¯¸ë¦¬ í•˜ìëŠ” êµí›ˆê³¼ ë°˜ì„±ë„ í•¨ê»˜ í–ˆë˜ í•˜ë£¨ì˜€ë‹¤ ğŸ˜‚ğŸ˜‚

<br>

<br>
