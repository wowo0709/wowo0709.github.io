---
layout: single
title: "[Computer Vision] 9(1). 계산 및 디스크 용량 최적화"
categories: ['AI', 'ComputerVision']
---

# 계산 및 디스크 용량 최적화

컴퓨터 비전에 있어 모델의 주요 특성으로는 **속도, 정확도, 크기**를 뽑을 수 있다. 

이번 포스팅에서는 모델 추론 속도를 개선하고 모델 크기를 줄이는 방법들에 대해 소개한다. 

<br>

### 추론 속도 측정하기

---

실시간 상황에서 활용되는 모델의 경우 하나의 이미지에 대한 예측을 계산하는 것이 중요하고 이를 **지연 시간(latency)**이라고 한다. 모델은 초당 5~30개 이미지를 실행해야 실시간으로 간주된다. 

실시간 애플리케이션이 아니라면 필요한 만큼 많은 추론 프로세스를 병렬로 실행할 수 있다. 프레임을 병렬로 처리하려면 더 많은 하드웨어가 필요하므로 재무 비용 측면에서만 영향을 미친다. 

<br>

#### 지연 시간 측정

지연 시간은 '단일 이미지'를 처리하는 데 걸리는 시간을 의미하지만, 실제로 이를 측정할 때는 측정 오류를 최소화하기 위해 여러 이미지를 처리하는 시간을 측정하여 처리된 이미지의 수로 나누는 방식을 사용한다. 

✋ 추론 시간을 측정할 때는 데이터 적재, 전처리, 사후 처리 시간을 포함하는 것 또한 매우 중요하다. 

<br>

#### 트레이싱 도구를 사용해 계산 성능 이해하기

추론 시간에 대한 자세한 성능 보고를 위해 **트레이싱 도구(tracing tool)**를 사용할 수 있다. 

트레이싱 도구를 사용하기 위해서는 trace_on을 호출하고 profiler를 True로 설정하면 된다. 그런 다음 트레이싱 결과를 폴더로 내보낸다. 

```python
logdir = "./logs/model"
writer = tf.summary.create_flie_writer(logdir)

tf.summary.trace_on(profiler=True)
model.predict(train_images)
with writer.as_default():
    tf.summary.trace_export('trace-model', profiler_outdir=logdir)
```

<br>

트레이싱이 활성화된 상태에서 모델이 실행되면 명령줄에서 다음 명령어를 실행해 텐서보드가 이 폴더를 가리키게 할 수 있다. 

```
$ tensorboard --logdir logs
```

<br>

트레이싱은 다음을 알아낸다. 

* 어느 계층이 가장 많은 컴퓨팅 시간을 쓰고 있는지
* 아키텍처를 수정한 후에 평소보다 시간이 더 걸리는 이유
* 텐서플로가 항상 숫자를 계산하는지, 아니면 데이터를 기다리는 지 여부. 전처리에 시간이 너무 걸리거나 CPU 사이를 너무 많이 왔다갔다 하면 데이터를 기다리는 일이 발생할 수 있다. 

계산 성능을 더 잘 이해하기 위해 사용 중인 모델을 트레이싱해 볼 것을 권한다. 

<br>

<br>

### 모델 추론 속도 개선하기

---

추론 속도를 개선하는 방법에는 하드웨어를 변경하는 방법과 모델 아키텍처 자체를 변경하는 방법이 있다. 

<br>

#### 하드웨어 최적화

추론에 어떤 하드웨어를 사용하는 지는 속도에 있어 매우 중요하다. 

* **CPU**: 속도는 느리지만 대체로 가장 저렴하다. 
* **GPU**: 더 빠르지만 그만큼 더 비싸다. 대부분의 스마트폰에는 실시간 애플리케이션을 사용할 수 있게 GPU가 통합돼 있다. 
* **특수 하드웨어**: 예를 들어 구글 'TPU'(서버용), 애플 'Neural Engine'(모바일용), 'NVIDIA Jetson'(휴대용 하드웨어용)이 있다. 이것들은 딥러닝 연산을 실행하기 위해 특별히 제작된 칩이다. 

애플리케이션에서 속도가 중요한 경우 가능한 하드웨어 중 가장 빠른 것을 사용하고 코드를 그에 맞춰 조정하는 것이 중요하다. 

<br>

#### 입력 최적화

컴퓨터 비전 모델의 추론 속도는 입력 이미지 크기에 정비례하기 때문에 사용하는 이미지의 크기가 작아질수록 추론 속도가 빨라진다. 

'속도와 정확도 사이에 적절한 균형'을 찾으려면 이미지 크기를 가지고 실험해야 한다. 

<br>

#### 사후처리 최적화

대부분의 모델에는 사후처리 연산이 필요하다. 잘못된 도구를 사용해 구현하면 사후처리에 시간이 많이 소요될 수 있다. 

대부분의 사후 처리는 CPU에서 일어나지만 경우에 따라 GPU에서 일부 연산을 실행할 수 있다. 

<br>

<br>

### 모델이 여전히 느린 경우

---

모델 속도가 최적화되었더라도 여전히 느리다면, 사용자가 실시간으로 느끼도록 하면서 이러한 속도 저하를 해결할 수 있는 몇 가지 기술들이 있다. 

<br>

#### 보간과 추적

객체 탐지 모델에 있어 동영상의 모든 프레임을 실행하는 것은 때로는 비현실적이다. 일반적으로는 몇 프레임 단위로 한 번씩 모델을 사용하며 그 사이 프레임에는 추적된 객체를 따라가기 위해서 선형 보간법을 사용한다. 

이 기술은 실시간 애플리케이션에서 작동하지 않지만, 또 다른 기술은 **객체 추적(object tracking)**은 일반적으로 사용된다. 딥러닝 모델로 객체가 탐지되고 나면 더 단순한 모델로 객체의 경계를 따라간다. 

객체 추적 알고리즘은 많으며, 그 중 OpenCV의 트래커 모듈을 아래 주소에서 확인할 수 있다. 

> https://docs.opencv.org/master/d9/df8/group__tracking.html

<br>

####  모델 증류

**모델 증류**의 개념은 더 큰 모델의 출력을 학습하기 위해 작은 모델을 훈련시키는 것이다. 작은 모델은 원시 레이블을 학습하는 대신(이를 위해 데이터를 사용할 수 있다) 더 큰 모델의 출력을 학습하게 훈련된다. 

더 작은 모델은 데이터 자체에서 추상 관계(이미지 사이의 유사성 등)를 학습할 능력은 없지만 다른 네트워크의 안내를 받을 수 있다. 

<br>

<br>

### 모델 크기 축소

---

브라우저나 모바일에서 딥러닝을 사용하는 경우 모델을 해당 기기에 내려받아야 한다. 다음과 같은 이유로 이 모델은 가능한 가벼워야 한다. 

* 사용자는 종종 사용량에 따라 비용이 부과되는 무선 통신망에서 휴대전화를 사용한다. 
* 연결이 느릴 수도 있다. 
* 모델이 자주 업데이트 될 수 있다. 
* 경우에 따라 휴대용 기기의 디스크 공간이 제한적이다. 

<br>

#### 양자화

가장 보편적으로 사용되는 기술은 매개변수의 정밀도를 낮추는 것이다. 매개변수를 32비트 부동소수점으로 저장하는 대신 16비트나 8비트 부동소수점으로 저장할 수 있다. 

**양자화(Quantization)**는 주로 훈련이 끝나고 나서 모델을 기기에서 사용할 수 있게 전환할 때 수행된다(학습 후 양자화). 이렇게 모델을 전환하면 정확도에 영향을 주기 때문에 양자화한 다음 모델을 평가하는 것이 매우 중요하다. 

모든 압축 기술 중에서 양자화가 대체로 크기에 미치는 영향은 가장 크고 성능에 미치는 영향은 가장 작다. 또한 구현하기도 매우 쉽다. 

<br>

#### 채널 가지치기와 가중치 희소화

이 밖에도 사용할 수 있는 기술들이 있지만 구현하기가 더 어려울 수 있다. 이 기술들은 대체로 시행착오에 의존하므로 간단하게 적용할 수 있는 방법은 없다. 

**채널 가지치기**

채널 가지치기(channel pruning)는 학습에 크게 사용되지 않는 일부 합성곱 필터나 일부 채널을 제거하는 것이다. 

그 필터들을 제거함으로써 모델 성능에 도움이 되지 않는 가중치를 저장하는 일을 피할 수 있다. 

<br>

**가중치 희소화**

가중치 희소화(weight sparsification)는 전체 행렬에 대한 가중치를 저장하는 대신 중요하거나 0에 가깝지 않은 가중치만 저장하는 것이다. 

이에 따르면 [0.1, 0.9, 0.05, 0.01, 0.7, 0.001]은 [(1, 0.9), (4, 0.7)]과 같이 표현될 수 있다. 



















