---
layout: single
title: "[TFLite] 텐서플로 개발 환경 구축"
---





## 본 포스팅은 2021/08/02 를 기준으로 작성되었습니다. 

<br>

# 텐서플로 개발 환경 구축

텐서플로 2의 초기버전인 2.0.0 은 텐서플로 1.0과 마찬가지로 CPU 버전과 GPU 버전으로 나뉘어 있어 각자 개발 환경에 맞는 버전을 설치해야 했지만, 텐서플로 2.1.0 부터는 CPU 버전과 GPU 버전이 통합되었습니다. 따라서 CPU만 사용하는 경우 CPU only 버전을 설치하면 GPU 버전에서만 사용되는 라이브러리를 설치하지 않을 수 있습니다. 

텐서플로 설치 패키지의 변화는 아래와 같습니다. 

| 구분            | 특징               | 설치 패키지                                                  |
| --------------- | ------------------ | ------------------------------------------------------------ |
| 2.0.0 버전      | CPU, GPU 버전 분리 | CPU 버전: tensorflow<br />GPU 버전: tensorflow-gpu           |
| 2.1.0 버전 이후 | CPU, GPU 버전 통합 | CPU/GPU 통합 버전: tensorflow<br />CPU only 버전: tensorflow-cpu |

<br>

### 아나콘다 가상환경 만들기

---

**가상 환경 목록 확인**

처음에는 base 환경만 있습니다. 

```assembly
conda env list
```

<br>

**가상 환경 생성**

파이썬 3.8 버전을 사용하는 가상 환경을 생성합니다. (여기서는 가상 환경명을 tf2로 합니다.)

```assembly
conda create -n 가상환경명 python=3.8
```

중간에 [y/n] 을 선택하라는 문구가 나오면 y를 입력해 패키지 설치를 진행합니다. 

<br>

**아나콘다 가상 환경 활성화**

아나콘다 가상환경 위에 텐서플로를 설치할 것이므로 가상 환경을 활성화합니다. 

```assembly
conda activate 가상환경명
```

<br>

<br>

### 텐서플로 CPU only 버전 설치

---

CPU only 버전의 텐서플로 설치는 매우 간단합니다. 

<br>

**텐서플로 CPU 패키지 설치**

다음 명령어로 텐서플로 CPU 버전을 설치합니다. 기본적으로 최신 버전이 설치되며 (**현재 2021/08/02 기준 2.5.0**), 뒤에 '==버전명'을 붙이면 해당하는 버전이 설치됩니다. 

```assembly
pip install tensorflow-cpu
```

<br>

**설치 확인**

파이썬을 실행하고 간단히 텐서플로의 버전을 출력하는 코드를 실행하여 제대로 설치되었는지 확인합니다. 

```python
import tensorflow as tf
print(tf.__version__)
```

텐서플로의 버전이 출력되면 제대로 설치된 것입니다. 

<br>

<br>

### 텐서플로 GPU 버전 설치

---

NVIDIA의 그래픽 카드가 설치된 개발 환경이라면 통합 버전을 설치하여 GPU를 이용할 수 있는 환경을 구축합니다. 통합 버전 설치는 텐서플로 라이브러리 설치, 그래픽 드라이버 설치, CUDA Toolkit 설치, cuDNN 설치 순으로 진행됩니다. 

<br>

**텐서플로 GPU 패키지 설치**

```assembly
pip install tensorflow
```

<br>

**NVIDIA 그래픽 드라이버 설치**

윈도우 커맨드 창(cmd)을 **관리자 권한으로 실행**하여 'nvidia-smi' 를 입력하면 현재 설치된 NVIDIA 그래픽 카드의 정보가 출력됩니다. 

```assembly
nvidia-smi
```

<img src="https://user-images.githubusercontent.com/70505378/127870043-987bfd25-6142-4ce8-a11d-3360dc1dbae7.png" alt="image-20210802220242126" style="zoom: 50%;" />

텐서플로에서 GPU를 사용하려면 최소 418.x 버전 이상의 드라이버가 필요하기 때문에, 드라이버가 설치되지 않았거나 418.x 보다 낮은 버전이라면 아래 주소에서 그래픽 카드에 맞는 드라이버를 설치합니다. 

[NVIDIA 그래픽 드라이버 설치](https://www.nvidia.com/download/index.aspx?lang=kr)

<br>

✋ 본인의 그래픽 카드는 [장치 관리자] - [디스플레이 어댑터] 에서 확인할 수 있습니다. 

<br>

**CUDA Toolkit 설치**

현재 CUDA의 최신 버전은 11.4 입니다. 앞에서 **pip install tensorflow** 명령어로 버전을 명시하지 않고 텐서플로를 설치했다면 버전 2.5.0 이 설치되었을 것입니다. 

> _**텐서플로 2.5.0 버전은 CUDA 11.2 및 cuDNN 8.1을 기준으로 구성되었기 때문에 2.5.0 버전을 설치한 분들은 기준치 이상의 버전으로 설치하셔야 합니다. **_

여기서는 CUDA 11.2.0 버전, cuDNN 8.1.1 버전을 설치하도록 하겠습니다. 

우선 CUDA를 설치합니다. 

[CUDA Toolkit 설치](https://developer/nvidia.com/cuda-toolkit-archive)

<img src="https://user-images.githubusercontent.com/70505378/127870080-7600db84-03e4-47e8-b017-bd953f82db0c.png" alt="image-20210802221502775" style="zoom:67%;" />

<br>

설치를 모두 완료했으면 환경 변수에 CUDA_PATH 항목이 제대로 생성되어 있는 지 확인합니다. 설치한 경로와 동일한 경로로 설정되어 있어야 합니다. 

<img src="https://user-images.githubusercontent.com/70505378/127870111-61ebf7e2-6ebb-42f7-8ee0-2e9c2d764b84.png" alt="image-20210802221643473" style="zoom:67%;" />

<br>

**cuDNN 설치**

cuDNN은 아래 주소에서 8.1.1 버전을 설치합니다. 

[cuDNN 설치](https://developer.nvidia.com/rdp/cudnn-archive)

<img src="https://user-images.githubusercontent.com/70505378/127870158-c55387db-9420-42f0-8f1a-0a1339a3023d.png" alt="image-20210802221932275" style="zoom:67%;" />

<br>

다운로드하여 압축을 풀면 CUDA 폴더가 있고 그 아래에 bin, include, lib 폴더가 있습니다. 이 세 폴더를 CUDA Toolkit 설치 경로인 _C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2_ 아래에 있는 bin, include, lib 폴더 대신 복사해서 붙여넣습니다. 

<br>

<br>

### 텐서플로 설치 확인

---

이제 텐서플로가 올바르게 설치되었는지, 그리고 설치된 버전과 GPU 사용 여부를 확인하기 위해 Anaconda Prompt에서 'python'을 입력한 뒤 다음 코드를 입력합니다. 

```python
import tensorflow as tf
print(tf.__version__) # 2.5.0
tf.config.list_physical_devices('GPU')
```

다음과 같이 사용 가능한 GPU 목록이 출력됩니다. device _type이 GPU인 장치가 출력되면 제대로 설치된 것입니다. 

![image-20210802222534898](https://user-images.githubusercontent.com/70505378/127870195-cb050153-978b-499f-980a-416428117c93.png)

<br>

tf.config.list_physical_devices 함수 대신에 tf.test.is_gpu_available 함수를 사용하여 GPU 사용 여부를 True/False 로 알 수도 있습니다. 

![image-20210802222807831](https://user-images.githubusercontent.com/70505378/127870263-377ffbda-c0aa-463d-9502-6dce17fd84dc.png)

