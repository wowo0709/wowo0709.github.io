---
layout: single
title: "[TFLite] 텐서플로 라이트 모델 개발 워크플로"
---







<br>

# 텐서플로 모델 개발 워크플로

텐서플로를 이용하여 개발한 모델을 안드로이드에서 활용하려면 텐서플로 라이트 모델로 변환하여 배포해야 합니다. 모델 전체를 직접 개발할 필요는 없으며, 사전 학습된 다양한 모델을 이용하면 생산성을 높일 수 있습니다. 

텐서플로 라이트 모델 개발 워크플로는 **모델 선택 ➡ 모델 변환 ➡ 기기 배포 ➡ 모델 최적화** 순으로 진행됩니다. 

<br>

### 모델 선택

---

해결하고자 하는 문제나 개발하고자 하는 서비스 등에 적합한 모델을 선택해야 합니다. 

모델은 텐서플로를 이용하여 직접 개발할 수도 있고, 이미 개발된 모델을 사용할 수도 있습니다. 모델 개발에는 텐서플로를 이용하고 모델 변환 및 최적화에는 텐서플로 라이트를 이용합니다. 또한 이미 개발된 모델을 텐서플로나 텐서플로 허브에서 찾아볼 수 있습니다. 

<br>

### 모델 변환

---

개발한 모델은 텐서플로 라이트 모델로 변환해야 합니다. 

텐서플로 라이트는 모델을 저장할 때 **.tflite** 라는 별도의 포맷을 사용합니다. 텐서플로 모델을 tflite로 변환하는 과정에서 자동으로 최적화를 하는데, 이 때 정확도 손실을 최소한으로 하면서 모델의 크기를 줄입니다. 

Tensorflow Lite Converter에 의해 변환이 완료되면 tflite 파일이 생성되고, 이를 안드로이드 프로젝트에 배포하여 사용합니다. 

<br>

### 기기 배포

---

기기 배포는 tflite 파일을 안드로이드 스튜디오의 프로젝트에 배포하고, 이를 이용하여 안드로이드 앱을 만들어 기기에 배포하는 프로세스입니다. 

앱에서 모델을 활용하기 위해서는 간단히 앱 개발 단계에서 안드로이드 스튜디오에 모델을 포함하기만 하면 됩니다. 

네트워킹 기능을 이용해 실행 시간에 기기에 모델을 배포할 수도 있지만, 이는 백엔드 구현이 필요합니다. 

<br>

### 모델 최적화

---

모델 최적화는 모델이 안드로이드 기기에서 최적의 성능을 발휘하도록 튜닝하는 프로세스입니다. 

최적화를 거치면 모델의 정확도 손실을 최소화하면서 모델의 크기를 줄일 수 있는데, 정확도 손실과 크기 간에 균형을 잘 맞춰야 합니다. 

최적화는 모델 변환 단계에서 텐서플로 라이트가 자동으로 수행해주지만, 실행 속도나 정확도를 더욱 개선하기 위해 직접 최적화를 할 수도 있습니다. 모델을 기기에 배포한 뒤 성능을 측정하고, 이를 바탕으로 모델을 다시 최적화하고 변환하여 기기에 배포하는 과정의 반복을 통해 점진적으로 최적의 모델로 발전시킬 수 있습니다. 

<br>

다음 포스팅에서 각 모델의 선택과 개발 과정에 대해 살펴보겠습니다. 





























