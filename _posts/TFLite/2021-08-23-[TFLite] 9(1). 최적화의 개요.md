---
layout: single
title: "[TFLite] 9(1). 최적화의 개요"
categories: ['TFLite']
---

<br>

# 최적화의 개요

<br>

**최적화**란 모델이 제한된 컴퓨팅 자원 안에서 최고의 성능을 낼 수 있도록 사용 기기에 가장 적합한 상태를 만드는 기법을 말합니다. 텐서플로는 최적화 기법으로 **양자화^Quantization^**, **가지치기^Prunning^**, **가중치 클러스터링^Weight\ Clustering^**을 지원합니다. 

<br>

### 양자화

---

양자화는 데이터 집합을 더 작고 계측 가능한 범위에 할당하는 기법입니다. 예를 들어 신호 처리에서는 연속적인 아날로그 데이터를 이산적인 디지털 데이터로 근사시키는 방법으로 양자화를 적용합니다. 

텐서플로는 모델에서 사용되는 매개변수의 정밀도를 줄이는 방식으로 양자화를 적용합니다. 32비트 부동 소수점 값을 사용하는 매개변수를 8비트 고정 소수점 범위에서 대응되는 값에 할당하는 방식으로 양자화를 적용할 수 있습니다. 

<br>

양자화 기법에는 **양자화 인식 학습**과 **학습 후 양자화**가 있습니다. 

양자화 인식 학습은 모델을 학습하는 단계에서 양자화를 적용하기 때문에 학습 데이터가 필요합니다. 학습 과정에서 양자화로 인한 오류가 보정될 수 있으므로 양자화된 모델의 정확도 손실을 최소화할 수 있습니다. 

학습 후 양자화는 학습이 완료된 모델에 적용하기 때문에 학습 데이터가 필요하지 않으며, 양자화를 적용하기도 쉽고 모델 크기 감소 효과도 뛰어납니다. 

따라서 양자화를 적용할 때는 학습 후 양자화를 먼저 적용하고 추가적인 개선이 필요한 경우에 양자화 인식 학습을 고려합니다. 

| 모델               | 상위 1개 정확성(원본) | 상위 1개 정확성(훈련 후 양자화됨) | 상위 1개 정확성(양자화 인식 교육) | 지연 시간 (원본)(ms) | 지연 시간(훈련 후 양자화됨)(ms) | 지연 시간(양자화 인식 훈련)(ms) | 크기(원본)(MB) | 크기(최적화됨)(MB) |
| :----------------- | :-------------------- | :-------------------------------- | :-------------------------------- | :------------------- | :------------------------------ | :------------------------------ | :------------- | :----------------- |
| Mobilenet-v1-1-224 | 0.709                 | 0.657                             | 0.70                              | 124                  | 112                             | 64                              | 16.9           | 4.3                |
| Mobilenet-v2-1-224 | 0.719                 | 0.637                             | 0.709                             | 89                   | 98                              | 54                              | 14             | 3.6                |
| Inception_v3       | 0.78                  | 0.772                             | 0.775                             | 1130                 | 845                             | 543                             | 95.7           | 23.9               |
| Resnet_v2_101      | 0.770                 | 0.768                             | 해당 없음                         | 3973                 | 2868                            | 해당 없음                       | 178.3          | 44.9               |

출처: https://www.tensorflow.org/lite/performance/model_optimization

<br>

<br>

### 가지치기

---

가지치기는 모델에서 추론 결과에 영향이 거의 없는 매개변수를 제거하는 최적화 기법입니다. 

가지치기된 모델이 디스크에서 차지하는 용량과 추론 소요 시간은 원본 모델과 같지만 압축률이 더 높습니다. 

따라서 모델의 다운로드 크기를 줄일 수 있습니다. 

<br>

<br>

### 가중치 클러스터링

---

가중치 클러스터링은 각 레이어의 가중치를 미리 정의된 수의 클러스터로 그룹화한 다음 각각의 클러스터에 속하는 가중치의 중심 값을 공유하는 방식입니다. 

모델의 고유한 가중치 값의 수가 줄어들기 때문에 모델의 복잡성이 저하됩니다. 

따라서 압축률이 개선되어 모델의 다운로드 크기를 줄일 수 있습니다. 

<br>

<br>

### 정리

---

최적화에는 양자화(양자화 인식 학습/학습 후 양자화), 가지치기, 가중치 클러스터링이 있습니다. 

양자화 인식 학습, 가지치기, 가중치 클러스터링은 모두 모델 설계 학습 시에 적용되는 최적화 기법들이고 학습 후 양자화는 모델 저장/변환 시에 적용되는 최적화 기법입니다. 

<br>

모델을 최적화하면 모델 사이즈가 줄어들고 추론에 소요되는 시간이 단축됩니다. 그러나 모델의 정확도가 낮아지기 때문에 최적화한 모델의 정확도 감소 정도가 용인할 만한 범위 내인지 반드시 확인해야 합니다. 

가지치기와 가중치 클러스터링 기법은 TFLite 모델로 변환했을 때 개선 효과가 미미합니다. 그러므로 다음 포스팅부터는 양자화 기법인 양자화 인식 학습과 학습 후 양자화에 대해서 다룰 것입니다. 
